{
  "answer_type": "normal",
  "author": {
    "avatar_url": "https://picx.zhimg.com/v2-f958f2b875b0cf4d7ee853e4446ba2d1_l.jpg?source=2c26e567",
    "avatar_url_template": "https://picx.zhimg.com/v2-f958f2b875b0cf4d7ee853e4446ba2d1.jpg?source=2c26e567",
    "badge": [
      {
        "description": "信息技术行业 算法工程师",
        "topics": [],
        "type": "identity"
      }
    ],
    "badge_v2": {
      "detail_badges": [
        {
          "description": "知势榜教育校园领域影响力榜答主",
          "detail_type": "super_activity",
          "icon": "https://pic1.zhimg.com/v2-4a07bc69c4bb04444721f35b32125c75_l.png?source=32738c0c",
          "night_icon": "https://picx.zhimg.com/v2-4a07bc69c4bb04444721f35b32125c75_l.png?source=32738c0c",
          "sources": [
            {
              "avatar_path": "",
              "avatar_url": "",
              "description": "",
              "id": "27",
              "name": "知势榜8月",
              "priority": 27,
              "token": "",
              "type": "content_potential_category",
              "url": ""
            }
          ],
          "title": "社区成就",
          "type": "reward",
          "url": ""
        },
        {
          "description": "信息技术行业 算法工程师",
          "detail_type": "identity_people",
          "icon": "https://pic1.zhimg.com/v2-2ddc5cc683982648f6f123616fb4ec09_l.png?source=32738c0c",
          "night_icon": "https://picx.zhimg.com/v2-2ddc5cc683982648f6f123616fb4ec09_l.png?source=32738c0c",
          "sources": [],
          "title": "已认证的个人",
          "type": "identity",
          "url": "https://zhuanlan.zhihu.com/p/96956163"
        }
      ],
      "icon": "https://picx.zhimg.com/v2-27bfcba90e66db79ce8768ab807e017e_l.png?source=32738c0c",
      "merged_badges": [
        {
          "description": "知势榜教育校园领域影响力榜答主",
          "detail_type": "best",
          "icon": "",
          "night_icon": "",
          "sources": [],
          "title": "社区成就",
          "type": "best",
          "url": ""
        },
        {
          "description": "信息技术行业 算法工程师",
          "detail_type": "identity",
          "icon": "",
          "night_icon": "",
          "sources": [],
          "title": "认证",
          "type": "identity",
          "url": "https://zhuanlan.zhihu.com/p/96956163"
        }
      ],
      "night_icon": "https://pica.zhimg.com/v2-27bfcba90e66db79ce8768ab807e017e_l.png?source=32738c0c",
      "title": "知势榜教育校园领域影响力榜答主"
    },
    "gender": 1,
    "headline": "学校≠教育≠技能；文凭溢价=80%信号传递+20%人力资本",
    "id": "4c592f496dc33822b560b382907ff1d0",
    "is_advertiser": false,
    "is_org": false,
    "is_privacy": false,
    "name": "Thoughts Memo",
    "type": "people",
    "url": "https://api.zhihu.com/people/4c592f496dc33822b560b382907ff1d0",
    "url_token": "L.M.Sherlock",
    "user_type": "people"
  },
  "biz_ext": {},
  "comment_count": 2,
  "content": "<p data-pid=\"RjKlkbCZ\">Python 有一个词义消歧的库，用到了 WordNet：</p><a data-draft-node=\"block\" data-draft-type=\"link-card\" href=\"https://link.zhihu.com/?target=https%3A//github.com/alvations/pywsd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">alvations/pywsd: Python Implementations of Word Sense Disambiguation (WSD) Technologies. (github.com)</a><p data-pid=\"nUMmAwUX\">这个库的原理很简单，就是将多义词的上下文和该多义词在 WordNet 中的释义（英英释义）计算相似度，然后给出相似度最高的释义项。这个相似度有不同的算法，最简单的就是将上下文的单词作为集合 A，释义项中的单词作为集合 B，然后用 A B 交集的元素数量作为相似度。</p><p data-pid=\"FhqlbMyG\">不过这个方法有点原始，并不能很精确地给出一些生僻释义。另外 WordNet 里的释义项和单词的应用语境在绝大多数情况下并不匹配。若要计算相似度，应当是在该释义下的相关例句与多义词的上下文之间进行。</p><p data-pid=\"kJFRPpge\">当然，好处也是有的，那就是上述算法不需要训练模型，只需要有 WordNet 这样的语料就行了。</p><hr/><p data-pid=\"obvP5Bi4\">若要更进一步，那么可以考虑一下词向量了。词向量就是用一个向量表示一个单词。那么每个单词之间就可以计算余弦相似度。代入多义词消歧义的场景中，我们关心的是计算特定上下文中的多义词，与该单词在词典中的多个释义项中哪一项最相似。用词向量的角度来考虑，就是如何计算特定上下文中的单词对应的词向量，和词典中每个释义项对应的词向量。</p><p data-pid=\"KaTd6xxC\">其实还挺简单的，调 BERT 就可以了：</p><a data-draft-node=\"block\" data-draft-type=\"link-card\" href=\"https://link.zhihu.com/?target=https%3A//mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">BERT Word Embeddings Tutorial · Chris McCormick (mccormickml.com)</a><p data-pid=\"dk36k0J3\">给 BERT 输入一个句子，它会输出整个句子中每个单词的词向量，该词向量是上下文相关的，可以代表单词的语境含义。</p><p data-pid=\"PNEZAaIa\">至于释义项的词向量，则可以用相关例句来作为上下文输入 BERT 得到。如果有多条例句，把每条例句中对应的多义词的上下文词向量取平均即可。</p><p data-pid=\"xnn9bCKv\">效果展示：</p><figure data-size=\"normal\"><noscript><img src=\"https://picx.zhimg.com/50/v2-a686e48b7afd049f4c142b84c49a9174_720w.jpg?source=2c26e567\" data-rawwidth=\"448\" data-rawheight=\"168\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-a686e48b7afd049f4c142b84c49a9174\" data-default-watermark-src=\"https://pic1.zhimg.com/50/v2-ce49995076dbed08264ad2174ad0e66e_720w.jpg?source=2c26e567\" class=\"origin_image zh-lightbox-thumb\" width=\"448\" data-original=\"https://pic1.zhimg.com/v2-a686e48b7afd049f4c142b84c49a9174_r.jpg?source=2c26e567\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;448&#39; height=&#39;168&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"448\" data-rawheight=\"168\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-a686e48b7afd049f4c142b84c49a9174\" data-default-watermark-src=\"https://pic1.zhimg.com/50/v2-ce49995076dbed08264ad2174ad0e66e_720w.jpg?source=2c26e567\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"448\" data-original=\"https://pic1.zhimg.com/v2-a686e48b7afd049f4c142b84c49a9174_r.jpg?source=2c26e567\" data-actualsrc=\"https://picx.zhimg.com/50/v2-a686e48b7afd049f4c142b84c49a9174_720w.jpg?source=2c26e567\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://picx.zhimg.com/50/v2-6a424a94bcc59929050941682ccdae89_720w.jpg?source=2c26e567\" data-rawwidth=\"448\" data-rawheight=\"168\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-6a424a94bcc59929050941682ccdae89\" data-default-watermark-src=\"https://picx.zhimg.com/50/v2-b721eb090e6b027e6673d69656d238a4_720w.jpg?source=2c26e567\" class=\"origin_image zh-lightbox-thumb\" width=\"448\" data-original=\"https://picx.zhimg.com/v2-6a424a94bcc59929050941682ccdae89_r.jpg?source=2c26e567\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;448&#39; height=&#39;168&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"448\" data-rawheight=\"168\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-6a424a94bcc59929050941682ccdae89\" data-default-watermark-src=\"https://picx.zhimg.com/50/v2-b721eb090e6b027e6673d69656d238a4_720w.jpg?source=2c26e567\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"448\" data-original=\"https://picx.zhimg.com/v2-6a424a94bcc59929050941682ccdae89_r.jpg?source=2c26e567\" data-actualsrc=\"https://picx.zhimg.com/50/v2-6a424a94bcc59929050941682ccdae89_720w.jpg?source=2c26e567\"/></figure><p data-pid=\"DK11mW7v\">差不多就是一个更准确的查词工具。</p><p data-pid=\"uzP7N79H\">另外这个效果也只是用了 BERT 的预训练模型，并没有 fine-tune，所以应该还有提升空间。</p><hr/><p data-pid=\"LnOiCUlc\">另外，GPL-3 也会词义消歧任务：</p><figure data-size=\"normal\"><noscript><img src=\"https://picx.zhimg.com/50/v2-a297e6e0bded9e22f1b77b4b21669f0f_720w.jpg?source=2c26e567\" data-rawwidth=\"1544\" data-rawheight=\"360\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-a297e6e0bded9e22f1b77b4b21669f0f\" data-default-watermark-src=\"https://pic1.zhimg.com/50/v2-21dfe6d62f8ff615bf0a0a6c5bfd01d6_720w.jpg?source=2c26e567\" class=\"origin_image zh-lightbox-thumb\" width=\"1544\" data-original=\"https://picx.zhimg.com/v2-a297e6e0bded9e22f1b77b4b21669f0f_r.jpg?source=2c26e567\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1544&#39; height=&#39;360&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"1544\" data-rawheight=\"360\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-a297e6e0bded9e22f1b77b4b21669f0f\" data-default-watermark-src=\"https://pic1.zhimg.com/50/v2-21dfe6d62f8ff615bf0a0a6c5bfd01d6_720w.jpg?source=2c26e567\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1544\" data-original=\"https://picx.zhimg.com/v2-a297e6e0bded9e22f1b77b4b21669f0f_r.jpg?source=2c26e567\" data-actualsrc=\"https://picx.zhimg.com/50/v2-a297e6e0bded9e22f1b77b4b21669f0f_720w.jpg?source=2c26e567\"/></figure><figure data-size=\"normal\"><noscript><img src=\"https://picx.zhimg.com/50/v2-0fa211e12210fd2dda3814f26f5ad739_720w.jpg?source=2c26e567\" data-rawwidth=\"1834\" data-rawheight=\"390\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-0fa211e12210fd2dda3814f26f5ad739\" data-default-watermark-src=\"https://pica.zhimg.com/50/v2-234e8435d399488bbc483c74886983cf_720w.jpg?source=2c26e567\" class=\"origin_image zh-lightbox-thumb\" width=\"1834\" data-original=\"https://picx.zhimg.com/v2-0fa211e12210fd2dda3814f26f5ad739_r.jpg?source=2c26e567\"/></noscript><img src=\"data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1834&#39; height=&#39;390&#39;&gt;&lt;/svg&gt;\" data-rawwidth=\"1834\" data-rawheight=\"390\" data-size=\"normal\" data-caption=\"\" data-original-token=\"v2-0fa211e12210fd2dda3814f26f5ad739\" data-default-watermark-src=\"https://pica.zhimg.com/50/v2-234e8435d399488bbc483c74886983cf_720w.jpg?source=2c26e567\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1834\" data-original=\"https://picx.zhimg.com/v2-0fa211e12210fd2dda3814f26f5ad739_r.jpg?source=2c26e567\" data-actualsrc=\"https://picx.zhimg.com/50/v2-0fa211e12210fd2dda3814f26f5ad739_720w.jpg?source=2c26e567\"/></figure><p data-pid=\"hILLKVaD\">另外我在 Hugging Face 上也找到了一个做类似任务的模型：</p><a data-draft-node=\"block\" data-draft-type=\"link-card\" href=\"https://link.zhihu.com/?target=https%3A//huggingface.co/jpwahle/t5-word-sense-disambiguation\" data-image=\"https://pica.zhimg.com/v2-b6d2484bbe15ba0dac08e70a59b83884_ipico.jpg\" data-image-width=\"200\" data-image-height=\"200\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">huggingface.co/jpwahle/</span><span class=\"invisible\">t5-word-sense-disambiguation</span><span class=\"ellipsis\"></span></a><p data-pid=\"d-pOUXCg\">希望以上内容对你有所帮助。</p>",
  "content_need_truncated": false,
  "created_time": 1668646554,
  "excerpt": "Python 有一个词义消歧的库，用到了 WordNet： alvations/pywsd: Python Implementations of Word Sense Disambiguation (WSD) Technologies. (github.com) 这个库的原理很简单，就是将多义词的上下文和该多义词在 WordNet 中的释义（英英释义）计算相似度，然后给出相似度最高的释义项。这个相似度有不同的算法，最简单的就是将上下文的单词作为集合 A，释义项中的单词作为集合 B，然后用 A B 交集的元素数量作为相似度。 不过这…",
  "id": 2762043029,
  "is_jump_native": false,
  "question": {
    "created": 1562574216,
    "detail": "<p>最近要做多义词消歧，最好利用到wordnet或hownet。有没有什么推荐的论文呢</p>",
    "id": 333909480,
    "question_type": "normal",
    "relationship": {},
    "title": "有什么多义词消歧义的方法?",
    "type": "question",
    "updated_time": 1562574216,
    "url": "https://api.zhihu.com/questions/333909480"
  },
  "relationship": {
    "upvoted_followees": []
  },
  "type": "answer",
  "voteup_count": 46
}