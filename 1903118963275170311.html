<!DOCTYPE html>
<html lang="zh">
<head>
<title>时间序列预测方向有什么好水文章的领域吗，研一，感觉预测都被做的差不多了，创新点完全想不出来。？ - @Thoughts Memo | ZhiHu Archive</title>
<meta charset="UTF-8">
<meta property="og:type" content="website">
<meta property="og:title" content="时间序列预测方向有什么好水文章的领域吗，研一，感觉预测都被做的差不多了，创新点完全想不出来。？ - @Thoughts Memo | ZhiHu Archive">
<meta property="og:site_name" content="ZhiHu Archive for Thoughts Memo">
<meta property="og:description" itemprop="description" content="求求你们来做点新数据集、新任务上的工作吧！（顺带 sell 一下我的 work） 在间隔重复领域对学生记忆的时间序列预测任务项目地址： open-spaced-repetition/srs-benchmark: A benchmark for spaced repetition schedulers/algorithms 引言间隔重复算法（Spaced Repetition Algorithms）是一种计算机程序，旨在帮助人们规划抽认卡（flashcards）的复习安排。优秀的间隔重复算法能助你更高效地记忆。它并非让用户进行一次性的突击记…">
<meta property="og:url" content="https://www.zhihu.com/question/1891054381262169131/answer/1903118963275170311">
<meta name="description" content="求求你们来做点新数据集、新任务上的工作吧！（顺带 sell 一下我的 work） 在间隔重复领域对学生记忆的时间序列预测任务项目地址： open-spaced-repetition/srs-benchmark: A benchmark for spaced repetition schedulers/algorithms 引言间隔重复算法（Spaced Repetition Algorithms）是一种计算机程序，旨在帮助人们规划抽认卡（flashcards）的复习安排。优秀的间隔重复算法能助你更高效地记忆。它并非让用户进行一次性的突击记…">
<meta data-pagefind-meta="title" content="时间序列预测方向有什么好水文章的领域吗，研一，感觉预测都被做的差不多了，创新点完全想不出来。？">
<link rel="stylesheet" href="https://gcore.jsdelivr.net/npm/yue.css@0.4.0/yue.css">
<meta property="twitter:card" content="summary">
<meta name="twitter:title" content="时间序列预测方向有什么好水文章的领域吗，研一，感觉预测都被做的差不多了，创新点完全想不出来。？ - @Thoughts Memo | ZhiHu Archive">
<meta name="twitter:description" content="求求你们来做点新数据集、新任务上的工作吧！（顺带 sell 一下我的 work） 在间隔重复领域对学生记忆的时间序列预测任务项目地址： open-spaced-repetition/srs-benchmark: A benchmark for spaced repetition schedulers/algorithms 引言间隔重复算法（Spaced Repetition Algorithms）是一种计算机程序，旨在帮助人们规划抽认卡（flashcards）的复习安排。优秀的间隔重复算法能助你更高效地记忆。它并非让用户进行一次性的突击记…">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no">
<meta name="google-site-verification" content="U7ZAFUgGNK60mmMqaRygg5vy-k8pwbPbDFXNjDCu7Xk" />
<link rel="alternate" type="application/rss+xml" title="ZhiHu Archive for Thoughts Memo" href="https://l-m-sherlock.github.io/ZhiHuArchive/feed.xml">
<script>
const redirect = false;
if (redirect) {
window.location.replace("https://www.zhihu.com/question/1891054381262169131/answer/1903118963275170311");
}
</script>
<style>
img {
vertical-align: middle;
}
figure img {
width: 100%;
}
figure {
margin: 1.4em 0;
}
.author {
display: flex;
gap: 1em;
align-items: center;
}
#avatar {
width: 100px;
height: 100px;
}
.author > div {
flex: 1;
}
a {
color: #2563eb;
text-decoration: none;
border-bottom: 1px solid rgba(37, 99, 235, 0.3);
border-radius: 4px;
padding: 0 0.1em;
transition: color 0.2s ease, border-color 0.2s ease, background-color 0.2s ease;
}
a:hover,
a:focus-visible {
color: #1d4ed8;
border-bottom-color: rgba(29, 78, 216, 0.6);
background-color: rgba(37, 99, 235, 0.08);
}
a:focus-visible {
outline: none;
box-shadow: 0 0 0 2px rgba(37, 99, 235, 0.25);
}
a[data-draft-type="link-card"] {
   display: block;
   border-bottom: none;
   padding: 0;
   background: none;
}
.references {
font-size: 0.85em;
}
.formula-display {
display: block;
text-align: center;
}
</style>
</head>
<body style="max-width: 1000px; margin: 0 auto; padding: 0 1em 0 1em;" class="yue">
<p data-pagefind-ignore><a href="./">← 返回目录</a></p>
<hr>
<header>
<h1><a href="https://www.zhihu.com/question/1891054381262169131/answer/1903118963275170311" target="_blank" rel="noopener noreferrer">时间序列预测方向有什么好水文章的领域吗，研一，感觉预测都被做的差不多了，创新点完全想不出来。？</a></h1>
<div class="author">
<img class="avatar" id="avatar" src="https://picx.zhimg.com/v2-d571786b77078321f5f6ef92f4967877_l.jpg?source=2c26e567" />
<div>
<h2 rel="author">
<a href="https://www.zhihu.com/people/4c592f496dc33822b560b382907ff1d0" target="_blank" rel="noopener noreferrer">@Thoughts Memo</a>
</h2>
<p>学校≠教育≠技能；文凭溢价=80%信号传递+20%人力资本</p>
</div>
</div>
<time datetime="2025-05-06T08:08:39">发表于 2025年05月06日</time>
<p rel="stats"style="color: #999; font-size: 0.9em;">37 👍 / 8 💬</p>
</header>
<article data-pagefind-body>

<p data-pid="wsNrllXB">求求你们来做点新数据集、新任务上的工作吧！（顺带 sell 一下我的 work）</p><h2>在间隔重复领域对学生记忆的时间序列预测任务</h2><p data-pid="MGVm9g5G">项目地址：<a class="wrap external" href="https://github.com/open-spaced-repetition/srs-benchmark" rel="nofollow noreferrer noopener" target="_blank">open-spaced-repetition/srs-benchmark: A benchmark for spaced repetition schedulers/algorithms</a></p><h2><b>引言</b></h2><p data-pid="tL1NhHXp">间隔重复算法（Spaced Repetition Algorithms）是一种计算机程序，旨在帮助人们规划抽认卡（flashcards）的复习安排。优秀的间隔重复算法能助你更高效地记忆。它并非让用户进行一次性的突击记忆（cramming），而是将复习活动分散到不同的时间点。为了实现高效复习，这些算法试图理解人类记忆的运作机制，旨在预测你可能遗忘某个知识点的时间点，以便据此安排下一次复习。</p><p data-pid="UkxMPGQH">本基准测试旨在评估各种算法的预测准确性。我们评估了多种算法，以期找出能提供最准确预测的算法。</p><h2><b>数据集</b></h2><p data-pid="b09W1jdh">SRS 基准的数据集来自 1 万名使用 Anki（一个开源的抽认卡应用）的用户。该数据集包含约 7.27 亿次复习记录。完整数据集托管在 Hugging Face Datasets 上：</p><a class="wrap external" data-draft-node="block" data-draft-type="link-card" href="https://huggingface.co/datasets/open-spaced-repetition/anki-revlogs-10k" rel="nofollow noreferrer noopener" target="_blank">open-spaced-repetition/anki-revlogs-10k · Datasets at Hugging Face</a><h2><b>评估</b></h2><h3><b>数据划分</b></h3><p data-pid="tYPS_XuK">在间隔重复系统（SRS）基准测试中，我们使用了一个名为 <code>TimeSeriesSplit</code> 的工具，它是机器学习库 <a class="wrap external" href="https://scikit-learn.org/" rel="nofollow noreferrer noopener" target="_blank">sklearn</a> 的一部分。该工具帮助我们按时间顺序划分数据：较早的复习记录用于训练模型，较新的复习记录用于测试模型。这样，我们就能避免通过让算法获取本不应得到的未来信息而「作弊」。实践中，我们正是利用过去的的学习记录来预测未来的学习表现，因此 <code>TimeSeriesSplit</code> 非常适合我们的基准测试需求。</p><p data-pid="qO1VsbqB">注意：<code>TimeSeriesSplit</code> 在评估时会排除第一个数据分割。这是因为第一个分割用于训练，我们不希望在训练数据上评估模型的性能。</p><h3><b>评估指标</b></h3><p data-pid="FLQE1nf8">我们在 SRS 基准测试中使用三个指标来评估算法性能：对数损失（Log Loss）、曲线下面积（AUC）以及一个我们称为「分箱均方根误差」（RMSE (bins)）的自定义指标。</p><ul><li data-pid="K5kuc8Gk"><b>对数损失 (Log Loss)</b>（亦称二元交叉熵）：主要用于二元分类问题，对数损失衡量的是预测回忆概率与实际复习结果（1 或 0）之间的偏差。它量化了算法对真实回忆概率的拟合优度。对数损失的取值范围为 0 到无穷大，值越低表示性能越好。<br/><br/></li><li data-pid="PWvD0fje"><b>分箱均方根误差 (RMSE (bins))</b>：这是专为 SRS 基准测试设计的指标。该方法将预测结果和实际复习结果依据三个特征（复习间隔时长、复习次数、（记忆）中断次数）划分到不同的「箱」中。在每个箱内，计算平均预测回忆概率与平均实际回忆率之间的平方差。然后，根据每个箱内的样本数量对这些平方差进行加权，最终计算出加权均方根误差。该指标能够提供对算法在不同概率区间性能表现的更细致的理解。更多详情，请参阅<a class="wrap external" href="https://github.com/open-spaced-repetition/fsrs4anki/wiki/The-Metric" rel="nofollow noreferrer noopener" target="_blank">该指标说明</a>。RMSE (bins) 的取值范围为 0 到 1，值越低表示性能越好。<br/><br/></li><li data-pid="XmcOcKf-"><b>AUC (ROC 曲线下面积)</b>：该指标衡量算法区分不同类别（在此场景下指回忆成功与失败）的能力。AUC 的取值范围为 0 到 1，但在实践中几乎总是大于 0.5；值越高表示性能越好。</li></ul><p data-pid="tfbBS-fE">对数损失和 RMSE (bins) 主要衡量<b>校准度 (calibration)</b>：即预测的回忆概率与实际观测数据的一致性。AUC 主要衡量<b>区分度 (discrimination)</b>：即算法区分两个（或更广义地说，多个）类别的能力。即使对数损失和 RMSE 指标表现不佳，AUC 也可能很高。</p><h3><b>算法及算法家族</b></h3><ul><li data-pid="rwb4dTMR"><b>双组件或三组件*记忆模型</b>：<br/></li><ul><li data-pid="eyPjvk3y">FSRS v1 和 v2：FSRS 的早期实验版本。</li><li data-pid="3FFcv1-c">FSRS v3：FSRS 算法的首个正式发布版本，以自定义调度脚本的形式提供。</li><li data-pid="RdFfHOrz">FSRS v4：FSRS 的升级版，在社区的帮助下进行了改进。</li><li data-pid="T70C5wum">FSRS-4.5：基于 FSRS v4 的微幅改进版，主要调整了遗忘曲线的形状。</li><li data-pid="5Z80-zxu">FSRS-5：FSRS 的升级版。与先前版本不同，它利用了当日复习数据。当日复习数据仅用于训练，不用于评估。</li><li data-pid="FhZdk-A_">FSRS-6：FSRS 的最新版本。改进了处理当日复习数据的公式。更重要的是，FSRS-6 引入了一个可优化的参数来控制遗忘曲线的平坦程度，这意味着不同用户的遗忘曲线形状可以不同。</li><ul><li data-pid="7RWMBloI">FSRS-6 default param.：使用默认参数的 FSRS-6。这些默认参数是通过在数据集中全部一万个用户数据集上运行 FSRS-6 并计算每个参数的中位数得到的。</li><li data-pid="NV_5RgHM">FSRS-6 pretrain：仅优化前 4 个参数（首次复习后的初始稳定性值），其余参数设为默认值的 FSRS-6。</li><li data-pid="1vlZu-9s">FSRS-6 binary：将「困难」和「简单」两种评级均视为「良好」的 FSRS-6。</li><li data-pid="BC3n-NII">FSRS-6 preset：每个预设配置使用不同的参数。在 Anki 中，最少可以有一个预设配置，一个预设可以应用于多个牌组。</li><li data-pid="z4ZKHyh-">FSRS-6 deck：每个牌组使用不同的参数。</li><li data-pid="eYWt1ek1">FSRS-6 recency：训练时根据复习记录的新近度进行加权的 FSRS-6，使得较早的复习记录对损失函数的影响更小，较新的记录影响更大。</li></ul><li data-pid="6GIe5j-a">FSRS-rs：FSRS-6 的 Rust 语言移植版。另见：<a class="external" href="https://github.com/open-spaced-repetition/fsrs-rs" rel="nofollow noreferrer noopener" target="_blank"><span class="invisible">https://</span><span class="visible">github.com/open-spaced-</span><span class="invisible">repetition/fsrs-rs</span><span class="ellipsis"></span></a></li><li data-pid="HwNJVRHg">HLR：由 Duolingo 提出的算法，全称为半衰期回归（Half-Life Regression）。更多信息请参阅<a class="wrap external" href="https://github.com/duolingo/halflife-regression" rel="nofollow noreferrer noopener" target="_blank">这篇论文</a>。</li><li data-pid="Lga3lB3D">Ebisu v2：<a class="wrap external" href="https://fasiha.github.io/ebisu/" rel="nofollow noreferrer noopener" target="_blank">一种利用贝叶斯统计</a>在每次复习后更新记忆半衰期估计值的算法。</li></ul></ul><p data-pid="5G6fddTi">*在长期记忆的双组件模型中，使用两个独立变量描述人脑中单个记忆项目的状态：<b>可提取性 (R)</b>，即检索强度或回忆概率；以及<b>稳定性 (S)</b>，即存储强度或记忆半衰期。扩展的三组件模型增加了第三个变量——<b>难度 (D)</b>。</p><ul><li data-pid="vt_7L6Um"><b>其他记忆模型</b>：</li><ul><li data-pid="LV-kbKIT">DASH：在<a class="wrap external" href="https://scholar.colorado.edu/concern/graduate_thesis_or_dissertations/zp38wc97m" rel="nofollow noreferrer noopener" target="_blank">这篇论文</a>中提出的算法，其名称代表难度（Difficulty）、能力（Ability）和学习历史（Study History）。在我们的基准测试中，由于难度部分不适用于我们的数据集，我们仅使用了能力和学习历史部分。我们还增加了该算法的两个变体：DASH[MCM] 和 DASH[ACT-R]。更多信息请参阅<a class="wrap external" href="https://www.politesi.polimi.it/retrieve/b39227dd-0963-40f2-a44b-624f205cb224/2022_4_Randazzo_01.pdf" rel="nofollow noreferrer noopener" target="_blank">这篇论文</a>。</li><li data-pid="FUB8mn_j">ACT-R：在<a class="wrap external" href="http://act-r.psy.cmu.edu/wordpress/wp-content/themes/ACT-R/workshops/2003/proceedings/46.pdf" rel="nofollow noreferrer noopener" target="_blank">这篇论文</a>中提出的算法。它包含一个基于激活的陈述性记忆系统，通过记忆痕迹的激活来解释间隔效应。</li></ul><li data-pid="V18A0pmd"><b>神经网络模型</b>：</li><ul><li data-pid="artJsq6i">GRU：一种循环神经网络，常用于基于数据序列进行预测。它是机器学习领域处理时间序列相关任务的经典模型之一。为使比较更公平，它采用了与 FSRS-4.5 和 FSRS-5 相同的幂律遗忘曲线。</li><ul><li data-pid="X0-WPvei">GRU-P：GRU 的一个变体，移除了固定的遗忘曲线，直接预测回忆概率。这使其比 GRU 更灵活，但也更容易产生奇怪的预测，例如预测回忆概率随时间<b>增加</b>。</li></ul><li data-pid="xBKRFOt9">LSTM：一种比 GRU 架构更复杂、更精密的循环神经网络。它使用 <a class="wrap external" href="https://openai.com/index/reptile/" rel="nofollow noreferrer noopener" target="_blank">Reptile 算法</a>进行训练，并将短期复习记录、小数间隔以及复习时长作为其输入的一部分。 上述三种神经网络首先在 100 个用户的数据上进行了预训练，然后针对每个用户的数据单独进行了进一步优化。</li><li data-pid="M7wB-ALE">NN-17：<a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer noopener" target="_blank">SM-17</a> 算法的神经网络近似。它具有数量相当的参数，根据我们的估计，其性能与 SM-17 相近。</li></ul><li data-pid="YUmFERqq"><b>基于 SM-2 的算法</b>：</li><ul><li data-pid="183ndxBo">SM-2：SuperMemo（首款间隔重复软件）早期使用的算法之一。它诞生于 30 多年前，至今仍广受欢迎。<a class="wrap external" href="https://faqs.ankiweb.net/what-spaced-repetition-algorithm.html" rel="nofollow noreferrer noopener" target="_blank">Anki 的默认算法基于 SM-2</a>，<a class="wrap external" href="https://mnemosyne-proj.org/principles.php" rel="nofollow noreferrer noopener" target="_blank">Mnemosyne</a> 也在使用它。该算法本身并不直接预测回忆概率；因此，为了进行基准测试，我们基于一些关于遗忘曲线的假设对其输出进行了修改。Piotr Wozniak <a class="wrap external" href="https://super-memory.com/english/ol/sm2.htm" rel="nofollow noreferrer noopener" target="_blank">在此</a>处描述了该算法。</li><ul><li data-pid="WKprVsrw">SM-2 trainable：具有可优化参数的 SM-2 算法。</li></ul><li data-pid="1tZ1jnQq">Anki-SM-2：Anki 中使用的 SM-2 算法变体。</li><ul><li data-pid="zC8FLJbV">Anki-SM-2 trainable：具有可优化参数的 Anki 算法。</li></ul></ul><li data-pid="rcALTATc"><b>其他</b>：</li><ul><li data-pid="xyWAPQE5">AVG：一个输出恒定值（等于用户平均记忆保持率）的「算法」。没有实际应用价值，仅用作性能基线。</li><li data-pid="Rm1ft7DC">RMSE-BINS-EXPLOIT：一种利用 RMSE (bins) 计算方式的算法，通过模拟分箱操作将误差项维持在接近 0 的水平。</li></ul></ul><p data-pid="mV2laafY">关于 FSRS 算法的进一步信息，请参阅以下维基页面：<a class="wrap external" href="https://github.com/open-spaced-repetition/fsrs4anki/wiki/The-Algorithm" rel="nofollow noreferrer noopener" target="_blank">该算法</a>。</p><h2><b>结果</b></h2><p data-pid="TdofRF1g">总用户数：9,999。</p><p data-pid="YOniMNHS">用于评估的总复习次数：349,923,850。 当日复习数据不用于评估，但部分算法会利用这些数据来优化对次日回忆概率的预测。部分复习记录会被过滤掉，例如：手动更改到期日所产生的复习日志条目，或在禁用「根据我在此牌组中的答案重新安排卡片」选项的筛选牌组中复习卡片所产生的记录。最后，还会应用异常值过滤器。这些是导致用于评估的复习次数远低于之前提到的 7.27 亿的原因。</p><p data-pid="POYLGB7f">下表展示了各项指标的均值和 99% 置信区间。最佳结果以<b>粗体</b>标出。「参数」列显示了可优化（可训练）参数的数量，恒定参数不计入。箭头指示指标值越低 (↓) 或越高 (↑) 越好。</p><p data-pid="yddWf85h">为简洁起见，「输入特征」列中使用了以下缩写：</p><p data-pid="Shm4vore"><b>IL</b> = <b>i</b>nterval <b>l</b>engths, in days</p><p data-pid="Vdg4FAQ2"><b>FIL</b> = <b>f</b>ractional (aka non-integer) <b>i</b>nterval <b>l</b>engths</p><p data-pid="7XAvi3vi"><b>G</b> = <b>g</b>rades (Again/Hard/Good/Easy)</p><p data-pid="jYZiRJyc"><b>SR</b> = <b>s</b>ame-day (or <b>s</b>hort-term) <b>r</b>eviews</p><p data-pid="ojgcKXXD"><b>AT</b> = <b>a</b>nswer <b>t</b>ime (duration of the review), in milliseconds</p><h3>根据复习数量加权</h3><table data-draft-node="block" data-draft-type="table" data-row-style="normal" data-size="normal"><tbody><tr><th>Algorithm</th><th>Parameters</th><th>Log Loss↓</th><th>RMSE (bins)↓</th><th>AUC↑</th><th>Input features</th></tr><tr><td>LSTM</td><td>8869</td><td>0.312±0.0078</td><td>0.035±0.0011</td><td>0.733±0.0038</td><td>FIL, G, SR, AT</td></tr><tr><td>GRU-P-short</td><td>297</td><td>0.320±0.0080</td><td>0.042±0.0013</td><td>0.710±0.0047</td><td>IL, G, SR</td></tr><tr><td>FSRS-6 recency</td><td>21</td><td>0.320±0.0081</td><td>0.044±0.0013</td><td>0.710±0.0040</td><td>IL, G, SR</td></tr><tr><td>FSRS-rs</td><td>21</td><td>0.320±0.0082</td><td>0.044±0.0012</td><td>0.709±0.0041</td><td>IL, G, SR</td></tr><tr><td>FSRS-6</td><td>21</td><td>0.321±0.0083</td><td>0.046±0.0013</td><td>0.706±0.0041</td><td>IL, G, SR</td></tr><tr><td>FSRS-6 preset</td><td>21</td><td>0.322±0.0081</td><td>0.046±0.0013</td><td>0.707±0.0041</td><td>IL, G, SR</td></tr><tr><td>GRU-P</td><td>297</td><td>0.325±0.0081</td><td>0.043±0.0013</td><td>0.699±0.0046</td><td>IL, G</td></tr><tr><td>FSRS-6 binary</td><td>17</td><td>0.326±0.0081</td><td>0.049±0.0013</td><td>0.686±0.0047</td><td>IL, G, SR</td></tr><tr><td>FSRS-5</td><td>19</td><td>0.327±0.0083</td><td>0.052±0.0015</td><td>0.702±0.0042</td><td>IL, G, SR</td></tr><tr><td>FSRS-6 deck</td><td>21</td><td>0.329±0.0082</td><td>0.052±0.0016</td><td>0.699±0.0041</td><td>IL, G, SR</td></tr><tr><td>FSRS-4.5</td><td>17</td><td>0.332±0.0083</td><td>0.054±0.0016</td><td>0.692±0.0041</td><td>IL, G</td></tr><tr><td>FSRS v4</td><td>17</td><td>0.338±0.0086</td><td>0.058±0.0017</td><td>0.689±0.0043</td><td>IL, G</td></tr><tr><td>DASH-short</td><td>9</td><td>0.339±0.0084</td><td>0.066±0.0019</td><td>0.636±0.0050</td><td>IL, G, SR</td></tr><tr><td>FSRS-6 pretrain</td><td>4</td><td>0.339±0.0084</td><td>0.070±0.0024</td><td>0.695±0.0039</td><td>IL, G, SR</td></tr><tr><td>DASH</td><td>9</td><td>0.340±0.0086</td><td>0.063±0.0017</td><td>0.639±0.0046</td><td>IL, G</td></tr><tr><td>DASH[MCM]</td><td>9</td><td>0.340±0.0085</td><td>0.064±0.0018</td><td>0.640±0.0051</td><td>IL, G</td></tr><tr><td>GRU</td><td>39</td><td>0.343±0.0088</td><td>0.063±0.0017</td><td>0.673±0.0039</td><td>IL, G</td></tr><tr><td>DASH[ACT-R]</td><td>5</td><td>0.343±0.0087</td><td>0.067±0.0019</td><td>0.629±0.0049</td><td>IL, G</td></tr><tr><td>FSRS-6 default param.</td><td>0</td><td>0.347±0.0087</td><td>0.079±0.0027</td><td>0.692±0.0041</td><td>IL, G, SR</td></tr><tr><td>ACT-R</td><td>5</td><td>0.362±0.0089</td><td>0.086±0.0024</td><td>0.534±0.0054</td><td>IL</td></tr><tr><td>AVG</td><td>0</td><td>0.363±0.0090</td><td>0.088±0.0025</td><td>0.508±0.0046</td><td>---</td></tr><tr><td>FSRS v3</td><td>13</td><td>0.371±0.0099</td><td>0.073±0.0021</td><td>0.667±0.0047</td><td>IL, G</td></tr><tr><td>FSRS v2</td><td>14</td><td>0.38±0.010</td><td>0.069±0.0021</td><td>0.667±0.0048</td><td>IL, G</td></tr><tr><td>NN-17</td><td>39</td><td>0.38±0.027</td><td>0.081±0.0038</td><td>0.611±0.0043</td><td>IL, G</td></tr><tr><td>FSRS v1</td><td>7</td><td>0.40±0.011</td><td>0.086±0.0024</td><td>0.633±0.0046</td><td>IL, G</td></tr><tr><td>Anki-SM-2 trainable</td><td>7</td><td>0.41±0.011</td><td>0.094±0.0030</td><td>0.616±0.0057</td><td>IL, G</td></tr><tr><td>HLR</td><td>3</td><td>0.41±0.012</td><td>0.105±0.0030</td><td>0.633±0.0050</td><td>IL, G</td></tr><tr><td>HLR-short</td><td>3</td><td>0.44±0.013</td><td>0.116±0.0036</td><td>0.615±0.0062</td><td>IL, G, SR</td></tr><tr><td>SM-2 trainable</td><td>6</td><td>0.44±0.012</td><td>0.119±0.0033</td><td>0.599±0.0050</td><td>IL, G</td></tr><tr><td>Ebisu v2</td><td>0</td><td>0.46±0.012</td><td>0.158±0.0038</td><td>0.594±0.0050</td><td>IL, G</td></tr><tr><td>Anki-SM-2</td><td>0</td><td>0.49±0.015</td><td>0.128±0.0037</td><td>0.597±0.0055</td><td>IL, G</td></tr><tr><td>SM-2-short</td><td>0</td><td>0.51±0.015</td><td>0.128±0.0038</td><td>0.593±0.0064</td><td>IL, G, SR</td></tr><tr><td>SM-2</td><td>0</td><td>0.55±0.017</td><td>0.148±0.0041</td><td>0.600±0.0051</td><td>IL, G</td></tr><tr><td>RMSE-BINS-EXPLOIT</td><td>0</td><td>4.5±0.13</td><td>0.0062±0.00022</td><td>0.638±0.0040</td><td>IL, G</td></tr></tbody></table><h3>未加权</h3><table data-draft-node="block" data-draft-type="table" data-row-style="normal" data-size="normal"><tbody><tr><th>Algorithm</th><th>Parameters</th><th>Log Loss↓</th><th>RMSE (bins)↓</th><th>AUC↑</th><th>Input features</th></tr><tr><td>LSTM</td><td>8869</td><td>0.333±0.0042</td><td>0.0538±0.00096</td><td>0.733±0.0021</td><td>FIL, G, SR, AT</td></tr><tr><td>FSRS-6 recency</td><td>21</td><td>0.344±0.0041</td><td>0.063±0.0010</td><td>0.710±0.0023</td><td>IL, G, SR</td></tr><tr><td>FSRS-rs</td><td>21</td><td>0.344±0.0041</td><td>0.063±0.0010</td><td>0.710±0.0022</td><td>IL, G, SR</td></tr><tr><td>FSRS-6</td><td>21</td><td>0.345±0.0042</td><td>0.066±0.0011</td><td>0.707±0.0023</td><td>IL, G, SR</td></tr><tr><td>GRU-P-short</td><td>297</td><td>0.346±0.0042</td><td>0.062±0.0011</td><td>0.699±0.0026</td><td>IL, G, SR</td></tr><tr><td>FSRS-6 preset</td><td>21</td><td>0.346±0.0042</td><td>0.065±0.0010</td><td>0.708±0.0023</td><td>IL, G, SR</td></tr><tr><td>FSRS-6 binary</td><td>17</td><td>0.351±0.0043</td><td>0.068±0.0011</td><td>0.685±0.0025</td><td>IL, G, SR</td></tr><tr><td>GRU-P</td><td>297</td><td>0.352±0.0042</td><td>0.063±0.0011</td><td>0.687±0.0025</td><td>IL, G</td></tr><tr><td>FSRS-6 deck</td><td>21</td><td>0.355±0.0045</td><td>0.074±0.0013</td><td>0.703±0.0023</td><td>IL, G, SR</td></tr><tr><td>FSRS-5</td><td>19</td><td>0.356±0.0043</td><td>0.074±0.0012</td><td>0.701±0.0023</td><td>IL, G, SR</td></tr><tr><td>FSRS-6 pretrain</td><td>4</td><td>0.359±0.0044</td><td>0.083±0.0013</td><td>0.702±0.0022</td><td>IL, G, SR</td></tr><tr><td>FSRS-4.5</td><td>17</td><td>0.362±0.0045</td><td>0.076±0.0013</td><td>0.689±0.0023</td><td>IL, G</td></tr><tr><td>DASH</td><td>9</td><td>0.368±0.0045</td><td>0.084±0.0013</td><td>0.631±0.0027</td><td>IL, G</td></tr><tr><td>DASH-short</td><td>9</td><td>0.368±0.0045</td><td>0.086±0.0014</td><td>0.622±0.0029</td><td>IL, G, SR</td></tr><tr><td>DASH[MCM]</td><td>9</td><td>0.369±0.0044</td><td>0.086±0.0014</td><td>0.634±0.0026</td><td>IL, G</td></tr><tr><td>FSRS-6 default param.</td><td>0</td><td>0.371±0.0046</td><td>0.097±0.0015</td><td>0.701±0.0022</td><td>IL, G, SR</td></tr><tr><td>FSRS v4</td><td>17</td><td>0.373±0.0048</td><td>0.084±0.0014</td><td>0.685±0.0023</td><td>IL, G</td></tr><tr><td>DASH[ACT-R]</td><td>5</td><td>0.373±0.0047</td><td>0.089±0.0016</td><td>0.624±0.0027</td><td>IL, G</td></tr><tr><td>GRU</td><td>39</td><td>0.375±0.0047</td><td>0.086±0.0014</td><td>0.668±0.0023</td><td>IL, G</td></tr><tr><td>AVG</td><td>0</td><td>0.394±0.0050</td><td>0.103±0.0016</td><td>0.500±0.0026</td><td>---</td></tr><tr><td>NN-17</td><td>39</td><td>0.398±0.0049</td><td>0.101±0.0013</td><td>0.624±0.0023</td><td>IL, G</td></tr><tr><td>ACT-R</td><td>5</td><td>0.403±0.0055</td><td>0.107±0.0017</td><td>0.522±0.0024</td><td>IL</td></tr><tr><td>FSRS v3</td><td>13</td><td>0.436±0.0067</td><td>0.110±0.0020</td><td>0.661±0.0024</td><td>IL, G</td></tr><tr><td>FSRS v2</td><td>14</td><td>0.453±0.0072</td><td>0.110±0.0020</td><td>0.651±0.0023</td><td>IL, G</td></tr><tr><td>HLR</td><td>3</td><td>0.469±0.0073</td><td>0.128±0.0019</td><td>0.637±0.0026</td><td>IL, G</td></tr><tr><td>FSRS v1</td><td>7</td><td>0.491±0.0080</td><td>0.132±0.0022</td><td>0.630±0.0025</td><td>IL, G</td></tr><tr><td>HLR-short</td><td>3</td><td>0.493±0.0079</td><td>0.140±0.0021</td><td>0.611±0.0029</td><td>IL, G, SR</td></tr><tr><td>Ebisu v2</td><td>0</td><td>0.499±0.0078</td><td>0.163±0.0021</td><td>0.605±0.0026</td><td>IL, G</td></tr><tr><td>Anki-SM-2 trainable</td><td>7</td><td>0.513±0.0089</td><td>0.140±0.0024</td><td>0.618±0.0023</td><td>IL, G</td></tr><tr><td>SM-2 trainable</td><td>6</td><td>0.58±0.012</td><td>0.170±0.0028</td><td>0.597±0.0025</td><td>IL, G</td></tr><tr><td>Anki-SM-2</td><td>0</td><td>0.62±0.011</td><td>0.172±0.0026</td><td>0.613±0.0022</td><td>IL, G</td></tr><tr><td>SM-2-short</td><td>0</td><td>0.65±0.015</td><td>0.170±0.0028</td><td>0.590±0.0027</td><td>IL, G, SR</td></tr><tr><td>SM-2</td><td>0</td><td>0.72±0.017</td><td>0.203±0.0030</td><td>0.603±0.0025</td><td>IL, G</td></tr><tr><td>RMSE-BINS-EXPLOIT</td><td>0</td><td>4.61±0.067</td><td>0.0135±0.00028</td><td>0.655±0.0021</td><td>IL, G</td></tr></tbody></table><p data-pid="wN3RSoDG">按复习次数加权的平均值更能代表在有充足数据可供学习时的「最佳情况」性能。由于几乎所有算法在学习数据充裕时表现更佳，因此按复习次数（n(reviews)）加权会使（代表误差的）平均指标值向更低（更优）的方向偏移。</p><p data-pid="z0pxar4G">未加权的平均值则更能反映「一般情况」下的性能。现实中，并非每个用户都拥有数十万条复习记录，因此算法并非总能完全发挥其潜力。</p><h3><b>优越性</b></h3><p data-pid="4UJb6BKC">上文呈现的各项指标或许难以直接解读。为了更清晰地展示各算法间的相对性能，下图显示了算法 A（行）的对数损失值低于算法 B（列）的用户所占百分比。例如，FSRS-6-recency 相较于 Anki SM-2 算法的默认参数版本，在 99.6% 的用户数据集上表现更优，这意味着对于本基准测试中 99.6% 的用户数据集，FSRS-6-recency 能够更准确地估计回忆概率。但请注意，SM-2 算法最初并非为预测概率而设计，其在本基准测试中之所以能预测概率，完全是因为我们为其额外添加了计算公式。</p><p data-pid="mIry9yRS">此图表基于 9,999 个用户数据集生成。为提高图表的可读性，并未包含所有参评算法。</p><figure data-size="normal"><noscript><img class="origin_image zh-lightbox-thumb" data-caption="" data-default-watermark-src="https://pic1.zhimg.com/50/v2-c9a45d861af68b8624e47b80e978f37f_720w.jpg?source=2c26e567" data-original="https://picx.zhimg.com/v2-a4168029fe23b58e4979bd6cdd4b02c2_r.jpg?source=2c26e567" data-original-token="v2-a4168029fe23b58e4979bd6cdd4b02c2" data-rawheight="2829" data-rawwidth="2790" data-size="normal" src="https://picx.zhimg.com/50/v2-a4168029fe23b58e4979bd6cdd4b02c2_720w.jpg?source=2c26e567" width="2790"/></noscript><img class="origin_image zh-lightbox-thumb lazy" data-caption="" data-default-watermark-src="https://pic1.zhimg.com/50/v2-c9a45d861af68b8624e47b80e978f37f_720w.jpg?source=2c26e567" data-original="https://picx.zhimg.com/v2-a4168029fe23b58e4979bd6cdd4b02c2_r.jpg?source=2c26e567" data-original-token="v2-a4168029fe23b58e4979bd6cdd4b02c2" data-rawheight="2829" data-rawwidth="2790" data-size="normal" src="https://picx.zhimg.com/50/v2-a4168029fe23b58e4979bd6cdd4b02c2_720w.jpg?source=2c26e567" width="2790"/></figure><p data-pid="MrbChr_5">此外，你可以在<a class="internal" href="https://www.zhihu.com/question/plots/Superiority-9999.png" rel="noopener noreferrer" target="_blank">此处</a>找到完整表格。</p><h3><b>统计显著性</b></h3><p data-pid="vC8Ke3BA">下图展示了采用 Wilcoxon 符号秩检验比较任意两种算法间对数损失的效应大小（r 值）：</p><p data-pid="Z66u0IN6">颜色表示：</p><ul><li data-pid="EGZzomS9">红色系表示行算法的性能劣于列算法：<br/></li><ul><li data-pid="h1lGMB9a">深红色：大效应 (r &gt; 0.5)</li><li data-pid="GJ33MwuC">红色：中等效应 (0.5 ≥ r &gt; 0.2)</li><li data-pid="72Si4Bcv">浅红色：小效应 (r ≤ 0.2)</li></ul><li data-pid="NyjmhTMj">绿色系表示行算法的性能优于列算法：<br/></li><ul><li data-pid="JyT0ZWJD">深绿色：大效应 (r &gt; 0.5)</li><li data-pid="IIQnJphX">绿色：中等效应 (0.5 ≥ r &gt; 0.2)</li><li data-pid="l6vp1flD">浅绿色：小效应 (r ≤ 0.2)</li></ul><li data-pid="6BjQuiaW">灰色表示 p 值大于 0.01，意味着我们无法得出哪个算法性能更优的结论。</li></ul><p data-pid="pzzMHb1n">Wilcoxon 检验同时考虑了成对数据差值的正负号和秩次，但未考虑不同用户数据集中复习次数的差异。因此，尽管该检验结果对于定性分析是可靠的，但在解读具体效应大小时应持谨慎态度。</p><p data-pid="9yRKEhTX">为提高图表的可读性，并未包含所有参评算法。</p><figure data-size="normal"><noscript><img class="origin_image zh-lightbox-thumb" data-caption="" data-default-watermark-src="https://picx.zhimg.com/50/v2-6d5937ddf070c564ba2367e9a35914c2_720w.jpg?source=2c26e567" data-original="https://picx.zhimg.com/v2-39fcb4e4b0daafaf9fa13f16eb95a432_r.jpg?source=2c26e567" data-original-token="v2-39fcb4e4b0daafaf9fa13f16eb95a432" data-rawheight="2818" data-rawwidth="2764" data-size="normal" src="https://pic1.zhimg.com/50/v2-39fcb4e4b0daafaf9fa13f16eb95a432_720w.jpg?source=2c26e567" width="2764"/></noscript><img class="origin_image zh-lightbox-thumb lazy" data-caption="" data-default-watermark-src="https://picx.zhimg.com/50/v2-6d5937ddf070c564ba2367e9a35914c2_720w.jpg?source=2c26e567" data-original="https://picx.zhimg.com/v2-39fcb4e4b0daafaf9fa13f16eb95a432_r.jpg?source=2c26e567" data-original-token="v2-39fcb4e4b0daafaf9fa13f16eb95a432" data-rawheight="2818" data-rawwidth="2764" data-size="normal" src="https://pic1.zhimg.com/50/v2-39fcb4e4b0daafaf9fa13f16eb95a432_720w.jpg?source=2c26e567" width="2764"/></figure><p data-pid="NH8oLU3g">此外，你可以在<a class="internal" href="https://www.zhihu.com/question/plots/Wilcoxon-9999-collections.png" rel="noopener noreferrer" target="_blank">此处</a>找到完整表格。</p><hr/><p data-pid="yccLKxzS">我之前发表的相关论文：</p><a class="internal" data-draft-node="block" data-draft-type="link-card" href="./577383961.html" rel="noopener noreferrer" target="_blank">KDD'22 | 墨墨背单词：基于时序模型与最优控制的记忆算法 [AI+教育] - 知乎</a><a class="internal" data-draft-node="block" data-draft-type="link-card" href="./656714407.html" rel="noopener noreferrer" target="_blank">Thoughts Memo：IEEE TKDE 2023 | 墨墨背单词：通过捕捉记忆动态，优化间隔重复调度</a><p data-pid="MjcBX0UV">相关研究资料：</p><a class="internal" data-draft-node="block" data-draft-type="link-card" href="./561539418.html" rel="noopener noreferrer" target="_blank">Thoughts Memo：间隔重复记忆算法研究资源汇总</a><p data-pid="Ni4FecI9">我写的入门文章：</p><a class="internal" data-draft-node="block" data-draft-type="link-card" href="./556020884.html" rel="noopener noreferrer" target="_blank">Thoughts Memo：间隔重复记忆算法：e 天内，从入门到入土。</a><p data-pid="DTJkIXYj">我的科研经历：</p><a class="internal" data-draft-node="block" data-draft-type="link-card" href="./543325359.html" rel="noopener noreferrer" target="_blank">Thoughts Memo：我是如何在本科期间发表顶会论文的？（内含开源代码和数据集）</a><p></p>

<hr>
<p data-pagefind-ignore><a href="./">← 返回目录</a></p>
</article>
<footer>
<p style="color: #999; font-size: 0.85em; text-align: center; margin-top: 2em;">
本页面由 <a href="https://github.com/L-M-Sherlock/ZhiHuArchive" target="_blank" rel="noopener noreferrer">ZhiHuArchive</a> 渲染，模板参考 <a href="https://github.com/frostming/fxzhihu" target="_blank" rel="noopener noreferrer">FxZhihu</a>。
</p>
</footer>
<script src="https://giscus.app/client.js"
data-repo="L-M-Sherlock/ZhiHuArchive"
data-repo-id="MDEwOlJlcG9zaXRvcnkzNDk5NDE0MzM="
data-category="Announcements"
data-category-id="DIC_kwDOFNuuuc4Ck92x"
data-mapping="title"
data-strict="0"
data-reactions-enabled="1"
data-emit-metadata="0"
data-input-position="top"
data-theme="preferred_color_scheme"
data-lang="zh-CN"
data-loading="lazy"
crossorigin="anonymous"
async>
</script>
</body>
</html>