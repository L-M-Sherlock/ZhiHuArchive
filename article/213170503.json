{
  "status": 0,
  "updated": 1650642987,
  "author": {
    "is_followed": false,
    "badge": [
      {
        "type": "identity",
        "description": "信息技术行业 算法工程师"
      }
    ],
    "name": "Thoughts Memo",
    "url": "https://api.zhihu.com/people/4c592f496dc33822b560b382907ff1d0",
    "gender": 1,
    "user_type": "people",
    "headline": "学校≠教育≠技能；文凭溢价=80%信号传递+20%人力资本",
    "avatar_url": "https://pic1.zhimg.com/50/v2-41f893b0cd84fb6a8c8f6d1bd29c9554_l.jpg?source=b1748391",
    "is_following": false,
    "type": "people",
    "id": "4c592f496dc33822b560b382907ff1d0"
  },
  "can_tip": false,
  "excerpt": "总目录：0 目录《间隔重复的历史》 上一章：06 1989: SuperMemo 适应用户记忆(中) 下…",
  "tipjarors_count": 0,
  "admin_closed_comment": false,
  "reason": "",
  "excerpt_title": "",
  "id": 213170503,
  "voteup_count": 30,
  "can_comment": {
    "status": true,
    "reason": ""
  },
  "created": 1599062032,
  "url": "https://api.zhihu.com/articles/213170503",
  "comment_permission": "all",
  "title": "06 1989: SuperMemo 适应用户记忆(下)",
  "image_width": 904,
  "content": "<p data-pid=\"hNbnflxd\">总目录：<a href=\"https://zhuanlan.zhihu.com/p/375379522?\" class=\"internal\">0 目录《间隔重复的历史》</a></p><p data-pid=\"k79ydgMM\">上一章：<a href=\"https://zhuanlan.zhihu.com/p/207094393\" class=\"internal\">06 1989: SuperMemo 适应用户记忆(中)</a></p><p data-pid=\"W0QRLNLI\">下篇主要从数据和理论上证明了 SM-5 算法对 SM-2 算法的优越性。本来还有后续的算法优化内容，介于其过于硬核，就不搬到知乎上了，感兴趣的朋友可以直接看我的电子书：</p><a href=\"https://link.zhihu.com/?target=https%3A//www.kancloud.cn/ankigaokao/supermemo-guru-cn/1895505\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">间隔重复的历史</a><hr/><h3><b>SuperMemo5 的评估（1989）</b></h3><p data-pid=\"gaAajYJ4\">SuperMemo 5的优势如此明显，以至于我没有收集太多数据来证明我的观点。我只拿我的<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Master%2527s_thesis\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">硕士论文</a></u>做了几次比较，结果毫无疑问。</p><p data-pid=\"z9XU2C5U\">档案警告：<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Why_use_literal_archives%253F\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">为什么使用文字档案?</a></u></p><p data-pid=\"x_9ib961\">本文是<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Piotr_Wozniak\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Piotr Wozniak</a></u>(1990)的《<i>优化学习</i>》的一部分。</p><p data-pid=\"-ThmeRlP\"><b>3.8. 算法 SM-5 的评估</b></p><p data-pid=\"hjCYr5aj\">算法 SM-5 自 1989 年 10 月 17 日开始使用，它提供了一种确定理想的最优间隔函数的有效方法，超出了所有人的预期，从而提高了习得率(在 9 个月内学习了 15,000 个项目)。图 3.5 显示习得速率至少是组合应用 SM-2 和 SM-4 算法的两倍！</p><figure data-size=\"normal\"><img src=\"https://picx.zhimg.com/v2-8c281fa742eee9a032df9a090587ab6d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"407\" data-rawheight=\"600\" class=\"content_image\" width=\"407\" data-original-token=\"v2-02768f3488716d0ea1fe6a5ed5025521\"/></figure><blockquote data-pid=\"6KTVejHH\"><b>图片：</b>在 SM-2 和 SM-5 算法的监督下，数据库中工作负担的变化</blockquote><p data-pid=\"_E_M2CEb\">对于 10 个月的数据库，知识保留率提高到 96% 左右。下面列出了选定数据库中的一些知识保留率数据，以显示 SM-2 和 SM-5 算法之间的比较：</p><ul><li data-pid=\"uNSCETjC\">日期 - 测量日期，</li><li data-pid=\"lCOxBv9o\">数据库 - 数据库的名称；ALL 表示所有数据库的平均值</li><li data-pid=\"Bf_jwiDC\">间隔 - 数据库中项目使用的平均当前间隔</li><li data-pid=\"1Pd8nDpj\">保留率 - 数据库中的知识保留率</li><li data-pid=\"8yFZpnyN\">版本 - 数据库所应用的算法版本</li></ul><table data-draft-node=\"block\" data-draft-type=\"table\" data-size=\"normal\" data-row-style=\"normal\"><tbody><tr><th>日期</th><th>数据库</th><th>间隔</th><th>保留率</th><th>版本</th></tr><tr><td>Dec 88</td><td>EVD</td><td>17 days</td><td>81%</td><td>SM-2</td></tr><tr><td>Dec 89</td><td>EVG</td><td>19 days</td><td>82%</td><td>SM-5</td></tr><tr><td>Dec 88</td><td>EVC</td><td>41 days</td><td>95%</td><td>SM-2</td></tr><tr><td>Dec 89</td><td>EVF</td><td>47 days</td><td>95%</td><td>SM-5</td></tr><tr><td>Dec 88</td><td>ALL</td><td>86 days</td><td>89%</td><td>SM-2</td></tr><tr><td>Dec 89</td><td>ALL</td><td>190 days</td><td>92%</td><td>SM-2, SM-4 and SM-5</td></tr></tbody></table><p data-pid=\"lTahNZRs\">在复习过程中，记录了下列成绩分布情况:</p><table data-draft-node=\"block\" data-draft-type=\"table\" data-size=\"normal\" data-row-style=\"normal\"><tbody><tr><th>Quality</th><th>Fraction</th></tr><tr><td>0</td><td>0%</td></tr><tr><td>1</td><td>0%</td></tr><tr><td>2</td><td>11%</td></tr><tr><td>3</td><td>18%</td></tr><tr><td>4</td><td>26%</td></tr><tr><td>5</td><td>45%</td></tr></tbody></table><p data-pid=\"dP5Iz5Kl\">根据算法 SM-5 的假设，该分布产生的平均回忆质量等于 4。遗忘指数等于 11%（成绩低于 3 的项目被认为是被遗忘的）。请注意，保留率数据表明数据库中只有 4% 的项目没有被记住。因此，遗忘指数超过遗忘项目百分比的 2.7 倍。</p><p data-pid=\"rHO-3XSr\">在一个 7 个月前的数据库中，发现 70% 的项目在测量之前的重复过程中甚至没有忘记一次，而只有 2% 的项目遗忘次数超过 3 次</p><h3><b>新算法优越性的理论证明</b></h3><p data-pid=\"W2h6Z4Af\">Anki 对 SuperMemo 5 的批评需要根据现代的<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Spaced_repetition\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">间隔重复</a></u>理论来做一个简单的证明。我们可以表明，今天的记忆模型可以映射到两种算法基础上的模型：<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Algorithm_SM-2\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">算法 SM-2</a></u> 和<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Algorithm_SM-5\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">算法 SM-5</a></u>，两者之间的关键区别是最优间隔函数的适应性缺失(在算法SM-5中由最优因子矩阵表示)。</p><p data-pid=\"-DxQ7HZ3\">SInc = f (C、S、R) 是一个<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability_increase\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">稳定性增长</a></u>函数，<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Complexity\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">复杂性</a></u> C、<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">稳定</a></u> S、<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">可恢复性</a></u> R 作为参数。这个函数决定了最优学习中复习<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Interval\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">间隔</a></u>的递增。</p><p data-pid=\"kQljPUfs\">两种算法，SM-2 和 SM-5 都忽略了<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">可提取性</a></u>维度。理论上，如果两种算法都能完美运行，我们可以假设它们的目标是 R=0.9。正如可以在 <u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">SuperMemo</a></u> 中测量的那样，这两种算法都失败了，因为它们不知道相关的<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Forgetting_curve\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">遗忘曲线</a></u>。他们只是不收集遗忘曲线数据。这种数据收集的可能性是在 1991 年才在<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Algorithm_SM-6\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">算法 SM-6</a></u> 中引入的。</p><p data-pid=\"RuOUIKk1\">然而，如果我们假设 <u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/The_birthday_of_spaced_repetition%3A_July_31%25EF%25BC%258C_1985\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">1985</a></u> 和 <u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo_1.0_for_DOS_%281987%29\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">1987</a></u> 启发式是完美的猜测，在理论上，该算法可以使用SInc=F(C,S)，常数R为90%。</p><p data-pid=\"VcZFGqvA\">由于 SM-2 使用相同的数字 EF 用于稳定性增加和项目复杂性，对于 SM-2，我们有以 EF=f&#39;(EF,interval) 的形式表示的 SInc=f(C,S) 方程，其中的数据可以很容易地显示 f&lt;&gt;f&#39; 。令人惊讶的是，SM-2 中使用的启发式通过解耦 EF 和项目复杂性之间的实际联系，使这个函数发挥作用。由于数据显示 SInc 随着 S 的增加而不断减少，在算法 SM-2 中，根据定义，如果要用 EF 来表示项的复杂度，那么所有项都需要在每次复习时获得复杂度。在实际应用中，算法 SM-2 使用 EF=f&#39;(EF,interval)，即 SInc(n)=f(SInc(n-1),interval)。</p><p data-pid=\"rAAHBh3A\">让我们假设 EF=f(EF,interval) 启发式正如 SM-2 算法的支持者所声称的那样，是一个很好的猜想。令 <i>SInc</i> 在算法 SM-5 中由 <u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/O-factor\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">O-factor</a></u> 表示。然后我们可以将 <i>SInc</i>=f(C,S) 表示为 <i>OF</i>=f(<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/EF\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">EF</a></u>,<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Interval\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">interval</a></u>)。</p><p data-pid=\"-IG-a_rG\">对于算法 SM-2, OF 是常数，等于 EF，在算法 SM-5 中，OF是可适应的，可以根据算法的表现进行修改。很明显，对表现差的算法进行惩罚，降低<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/OF_matrix\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">OF 矩阵</a></u>对应的项，并通过增加对应的项来奖励它，这要优于保持不变。</p><p data-pid=\"UIkT_m1H\">有趣的是，尽管 SM-2 算法的支持者声称它表现得很好，但神经网络 SuperMemo 算法的支持者却不断指责代数算法：缺乏适应性。实际上，<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Algorithm_SM-17\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">算法 SM-17</a></u> 的适应性是最好的，因为它是基于最精确的<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Three_component_model_of_memory\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">记忆模型</a></u>。</p><p data-pid=\"Qyq8QG8q\">可以想象，在 SM-2 中使用的启发法是如此精确，以致于原来对 <i>OF</i>=f(EF,interval) 的猜测不需要修改。然而，正如在实际应用中所显示的那样，<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/OF_matrix\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">OF 矩阵</a></u>迅速发展，并收敛到<u><a href=\"https://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/ANE1994\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这篇出版物(Wozniak, Gorzelanczyk 1994)</a></u>中描述的值。它们与算法 SM-2 中的假设有本质上的不同。</p><p data-pid=\"f6Vsk25n\"><b>总结：</b></p><ul><li data-pid=\"CBZLKgRS\">sm17 (2016): SInc=f(C,S,R)， 3 个变量，f 是有适应性的</li><li data-pid=\"eXJttA71\">sm5 (1989): SInc=f(C,S,0.9)， 2 个变量，f 是有适应性的</li><li data-pid=\"u6U1SBKo\">sm2 (1987): SInc=f(SInc,S,0.9) - 1 个变量，f 是固定的</li></ul><hr/><p data-pid=\"aYKJ8205\">从这篇开始，SuperMemo 的算法会越来越精致，也越来越硬核，所以不会翻译的太详细，想了解的朋友可以把我的翻译当作参考，具体细节还请看英文原文。</p><p data-pid=\"GOBH-08H\">下一章：<a href=\"https://zhuanlan.zhihu.com/p/429504395\" class=\"internal\">07 1990：记忆的通用公式</a></p>",
  "column": {
    "updated": 1710055189,
    "description": "该专栏翻译有关记忆，学习，睡眠，创造力，解决问题，脑科学，健康和教育的文章",
    "author": {
      "is_followed": false,
      "badge": [],
      "name": "Thoughts Memo",
      "url": "https://api.zhihu.com/people/4c592f496dc33822b560b382907ff1d0",
      "gender": 1,
      "user_type": "people",
      "headline": "学校≠教育≠技能；文凭溢价=80%信号传递+20%人力资本",
      "avatar_url": "https://pic1.zhimg.com/50/v2-41f893b0cd84fb6a8c8f6d1bd29c9554_l.jpg?source=b1748391",
      "is_following": false,
      "type": "people",
      "id": "4c592f496dc33822b560b382907ff1d0"
    },
    "url": "https://api.zhihu.com/columns/supermemo-guru-cn",
    "title": "学校教育问题",
    "image_url": "https://picx.zhimg.com/v2-f111d7ee1c41944859e975a712c0883b_720w.jpg?source=d16d100b",
    "type": "column",
    "id": "supermemo-guru-cn"
  },
  "comment_count": 2,
  "image_url": "https://picx.zhimg.com/v2-a76183f943e37f785644a1ecce4458d5_720w.jpg?source=b1748391",
  "linkbox": {
    "url": "",
    "category": "",
    "pic": "",
    "title": ""
  },
  "voting": 0,
  "type": "article",
  "suggest_edit": {
    "status": false,
    "url": "",
    "reason": "",
    "tip": "",
    "title": ""
  },
  "is_normal": true,
  "censored": false
}