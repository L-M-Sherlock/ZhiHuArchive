<meta charset="UTF-8">
05 1988：记忆的两个组成成分
<div><p>总目录：<a class="internal" href="https://zhuanlan.zhihu.com/p/375379522?">0 目录《间隔重复的历史》</a></p><p>上一篇：<a class="internal" href="https://zhuanlan.zhihu.com/p/97887756">04 1987 SuperMemo 1.0: 日志</a></p><p>如果你没有时间阅读长文，建议看：<a class="internal" href="https://zhuanlan.zhihu.com/p/179076885">浓缩通俗版</a></p><p><b>注意：由于知乎对 markdown 的支持不完善，部分排版可能影响阅读体验。</b></p><p><b>推荐在这里阅读：</b></p><a class="LinkCard new" data-draft-node="block" data-draft-type="link-card" data-text="05.1988 记忆的两个组成部分 · supermemo.guru 翻译计划 · 看云" href="https://www.kancloud.cn/ankigaokao/supermemo-guru-cn/1895544" target="_blank"><span><span></span><span></span></span><span></span></a><p>本文提出的记忆双组分模型很有启发意义，推荐阅读。</p><hr/><h2>1988：记忆的两个组成成分</h2><p>长期记忆的双组分模型是 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 的基础，并在 <a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer" target="_blank">SM-17 算法</a>中明确表示。它区分了知识在长期记忆存储中的稳定性和提取的难易程度。这仍然是学习理论中一个鲜为人知的典型事实，即一个人可以流利，但记忆力仍然很差。</p><p>从长远来看，流利度并不能很好地衡量学习效果。</p><h2>长期记忆的组成成分</h2><p>多年来，记忆研究人员一直使用“记忆强度”这个词。它应该反映出人们对事物的记忆有多好。</p><p>上世纪 80 年代中期，我对<a class="wrap external" href="https://supermemo.guru/wiki/Spaced_repetition" rel="nofollow noreferrer" target="_blank">间隔重复</a>的研究让我很快意识到，一个<i>强度</i>变量不足以描述存储在长期记忆中的知识的状态。我们需要两个变量来区分事实从记忆中提取的难易程度。</p><p>我的结论是，存储在长期记忆中的知识的状态可以用两个变量来描述：<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>和<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>。记忆的稳定性告诉您记忆在存储中可以持续多长时间。可提取性告诉你回忆一段知识是多么容易。在记忆研究中，这两个变量常常被混为一谈。</p><p>令人惊讶的是，在我观察了三十年之后，记忆的两个组成成分的概念仍然在渗透主流的记忆研究。2018 年，大多数论文忽略了这两个变量的分离，仍然依赖于单一的“记忆强度”概念。这导致了巨大的困惑和研究进展缓慢。</p><h2>记忆双组分模型的起源</h2><p>1988 年 1 月 9 日，我在计算机模拟课上的一篇论文中首次描述了<a class="wrap external" href="https://supermemo.guru/wiki/Two_component_model_of_memory" rel="nofollow noreferrer" target="_blank">长期记忆的两个组成成分</a>。在同一篇论文中，我用了一种不相关的推理方法，得出结论：<a class="wrap external" href="https://supermemo.guru/wiki/programural_learning" rel="nofollow noreferrer" target="_blank">陈述性学习</a>和<a class="wrap external" href="https://supermemo.guru/wiki/programural_learning" rel="nofollow noreferrer" target="_blank">过程性学习</a>一定涉及不同的回路。</p><p>如果您停下来思考一分钟，那么双组分的整个思想应该是非常显然的。如果你在复习后马上取两段记忆，一段最佳时间间隔很短，另一段最佳时间间隔很长，那么这两段记忆的记忆状态必然不同。两者都可以被完美地回忆(最大的可提取性)，它们还需要在记忆中持续的时间上有所不同(不同的稳定性)。我很惊讶我找不到任何关于这个主题的文献。然而，如果文献中没有提及在间隔重复中存在最优间隔，那么这个看似明显的结论可能隐藏在另一个看似明显的概念背后：在最优间隔复习中间隔递增的级数。这是一个可爱的例子，说明人类的进步是渐进的，而且缓慢得令人痛苦。我们是出了名的不善于创新。烛台下最暗。这一弱点可以通过网络交流的爆炸来打破。我主张少一些同行审查，多一些大胆的假设。我提到了 Robin Clarke 关于阿尔茨海默病的论文中的一个很好的例子。严格的同行审查让人想起普鲁士的学校教育：在追求完美的过程中，我们失去了创造力，失去了人性，最终失去了生活的乐趣。</p><p>1988 年 2 月 19 日，当我第一次向我的老师 Katulski 博士提出我的想法时，他并没有给我留下太深刻的印象，但他给了我一张计算机模拟学分的通行证。顺便说一句，不久之后，Katulski 成为 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo_1.0_for_DOS" rel="nofollow noreferrer" target="_blank">SuperMemo 1.0 for DOS</a> 的首批用户之一。</p><p>在我的<a class="wrap external" href="https://supermemo.guru/wiki/Master%27s%2520_thesis" rel="nofollow noreferrer" target="_blank">硕士论文</a>(1990)中，我添加了一个稍微正式的证明，证明这两个组件的存在(参见<a class="wrap external" href="https://supermemo.guru/wiki/History_of_spaced_repetition_%28print%29%23%2520proof" rel="nofollow noreferrer" target="_blank">下一节</a>)。我论文的那一部分没有引起注意。</p><p>1994年，J.Kowalski 在波兰恩特写道：</p><blockquote>我们已经到了这样一个阶段，对记忆的进化解释表明，它使用的原理是增加间隔和<a class="wrap external" href="https://supermemo.guru/wiki/Spacing_effect" rel="nofollow noreferrer" target="_blank">间隔效应</a>。除了进化论的推测外，还有什么证据可以证明这种记忆模型吗？在他的博士论文中，Wozniak 广泛地讨论了记忆的分子层面，并提出了一个假设模型，描述了学习过程中突触发生的变化。本文提出的新元素是记忆痕迹的<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>和<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>之间的区别。这不能用来支持 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 的有效性，因为一个简单的事实是，正是 SuperMemo 本身奠定了假设的基础。然而，越来越多的分子层面证据似乎与稳定性-可提取性模型相吻合，同时，该模型为导向 SuperMemo 的假设的正确性提供了支持。简单地说，可提取性是记忆的一种属性，它决定了突触对刺激反应的效率水平，从而引发学习行为。可提取性越低，您就越不可能回忆起对问题的正确回答。另一方面，稳定性反映了早期重复的历史，并决定了记忆痕迹能够维持的时间范围。记忆的稳定性越高，可提取性下降到零，即下降到记忆永久遗忘所需的时间就越长。根据 Wozniak 的说法，当我们第一次学习某样东西的时候，我们会在编码特定刺激反应关联的突触中体验到稳定性和可提取性的轻微提高。随着时间的推移，可提取性迅速下降；相当于遗忘的现象。同时，记忆的稳定性保持在大致相同的水平。然而，如果我们在可提取性下降到零之前重复这种关联，可提取性将恢复其初始值，而稳定性将增加到一个新的水平，显著高于初次学习时的水平。在下一次重复发生之前，由于稳定性的提高，可提取性以较慢的速度下降，在遗忘发生之前，重复之间的间隔可能要长得多。记忆的另外两个重要特性也应该注意到：(1) 当可提取性高时，重复不能增加稳定性(间隔效应)，(2) 遗忘时，稳定性迅速下降</blockquote><h2>同行评议刊物 (1995)</h2><p>我们与 <a class="wrap external" href="https://supermemo.guru/wiki/Janusz_Murakowski" rel="nofollow noreferrer" target="_blank">Janusz Murakowski 博士</a>和 <a class="wrap external" href="https://supermemo.guru/wiki/Edward_Gorzelanczyk" rel="nofollow noreferrer" target="_blank">Edward Gorzelanczyk 博士</a> 在 <a class="wrap external" href="https://link.zhihu.com/?target=http%3A//supermemory.com/english/2vm.htm" rel="nofollow noreferrer" target="_blank">1995</a> 发表了我们的想法。Murakowski 完善了数学证明。Gorzelanczyk 充实了分子模型。我们没有从科学界听到太多的热情和反馈。记忆的两个组成成分的概念就像葡萄酒，时间越久，味道就越好。我们一直想知道它什么时候会得到更广泛的认可。毕竟，我们并不是生活在<a class="wrap external" href="https://en.wikipedia.org/wiki/Gregor_Mendel" rel="nofollow noreferrer" target="_blank">孟德尔</a>的时代，把一块好宝石藏在某个晦涩的档案中。间隔重复的用户数以百万计，即使只有 0.1% 的人对这个理论感兴趣，他们也会听说我们的两个组分。今天，甚至 <a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 中的<a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">最新算法</a>都是基于双组分模型的，而且运行起来很有魅力。具有讽刺意味的是，用户往往会涌向<a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-2" rel="nofollow noreferrer" target="_blank">更简单的解决方案</a>，那里隐藏着人类记忆的所有机制。即使在 <a class="wrap external" href="https://link.zhihu.com/?target=http%3A//supermemo.com/" rel="nofollow noreferrer" target="_blank">supermemo.com</a> 上，我们也确保不会用屏幕上过多的数字吓到客户。这样，我们就可以在渴望简单的用户中更好地采用模型的指导功能。</p><h2>Robert Bjork 的研究</h2><p>记忆的两个组成成分的概念在以前的研究中有相似之处，特别是在 <a class="wrap external" href="https://supermemo.guru/wiki/Bjork" rel="nofollow noreferrer" target="_blank">Bjork</a> 的研究中。</p><p>在 20 世纪 40 年代，科学家研究了习惯强度和反应强度作为老鼠行为的独立组成部分。这些概念后来在 Bjork 的废用理论中重新表述。Herbert Simon 在 1966 年的论文中似乎注意到了记忆稳定性变量的必要性。1969 年，Robert Bjork 提出了强度悖论：回忆的概率和复习的记忆效果之间存在反向关系。请注意，他的是根据两分量模型对间隔效应的重述，这距离阐明记忆变量之间的区别只有一小步之遥。这引出了 Bjork 的新废用理论(1992)，该理论区分了储存强度和提取强度。这是与可提取性和稳定性相近的等价物，但对作为区别基础的机制的解释略有不同。最引人注目的是，Bjork 认为，当可提取性降至零时，仍然保留了稳定的记忆(在我们的模型中，稳定性变得不确定)。在细胞层面上，Bjork 可能是对的，至少在一段时间内是正确的，但实践 SuperMemo 显示了完全遗忘的力量，而从神经的角度来看，保留废弃的记忆将是非常低效的，独立于它们的稳定性。最后但并非最不重要的一点是，Bjork 用连接性来定义存储强度，这与我认为优秀学生身上会发生的事情非常接近：一致性会影响稳定性。</p><p>为什么记忆的两个组成成分还没有进入主流研究？我认为，如果人类的思维倾向于短视，而我们都是故意的，那么科学的头脑可能真的会被繁重的职责、发表或灭亡、拨款之争、等级制度、利益冲突、同行评议、教学义务，甚至行为准则扼杀。记忆研究人员倾向于生活在“记忆强度”的单一维度中。在这个维度上，他们不能真正理解需要研究以解决问题的分子和神经过程的真实动力学。具有讽刺意味的是，进步可能来自那些倾向于从事人工智能或神经网络工作的人。Demis Hassabis 或 Andreas Knoblauch 的惊人头脑通过独立的推理过程、模型和模拟提出了两个想法。生物学家将需要聆听数学和计算机科学的语言。</p><h2>算法 SM-17 中的双组分模型</h2><p><a class="wrap external" href="https://supermemo.guru/wiki/Two_component_model_of_long-term_memory" rel="nofollow noreferrer" target="_blank">长期记忆的双组分模型</a>是 <a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer" target="_blank">Algorithm SM-17</a> 的基础。算法 SM-17 的成功，是该模型正确性的最终实践证明。</p><p>记忆的两个组成成分的值的实际变化图提供了记忆状态演变的概念性可视化：</p><figure><img class="origin_image zh-lightbox-thumb lazy" data-actualsrc="https://pic1.zhimg.com/v2-a85197c6920ebb497461bfb3f49d8e8c_b.jpg" data-caption="" src="https://pic1.zhimg.com/v2-a85197c6920ebb497461bfb3f49d8e8c_r.jpg" data-rawheight="484" data-rawwidth="800" data-size="normal" src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='800' height='484'&gt;&lt;/svg&gt;" width="800"/></figure><p><br/></p><blockquote><b>图片：</b>记忆状态随着时间的推移而发生变化。横轴表示跨越整个重复历史的时间。顶部面板显示可提取性(十次幂，<img alt="R^{10}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=R%5E%7B10%7D"/>，便于分析)。灰色网格的可提取性指标分别为 R=99%、R=98% 等。中间深蓝色的面板显示的最佳间隔。重复日期用蓝色竖线标记，并以浅蓝绿色标记。当 R 越过 90% 线时，最佳区间的末端用红色竖线表示(仅当区间大于最佳区间时)。下面板显示稳定性(以 <img alt="\ln(S)/\ln(days)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cln%28S%29%2F%5Cln%28days%29"/> 表示，便于分析)。从图中可以看出，当稳定性较低时，早期重复后的可提取性下降较快(指数级)，但在第 7 次复习后的 10 年时间里，可提取性仅从100%下降到 94%。所有的值都来自一个实际的重复历史和记忆的三组分模型。</blockquote><p>因为一个现实生活中的应用 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 需要解决不同难度的学习材料，模型中所涉及的第三个变<a class="wrap external" href="https://supermemo.guru/wiki/Item_difficulty" rel="nofollow noreferrer" target="_blank">项目难度</a> (D)。项目难度的一些影响也已经在这篇<a class="wrap external" href="https://supermemo.guru/wiki/History_of_spaced_repetition" rel="nofollow noreferrer" target="_blank">文章</a>被讨论。特别是具有不同子成分的复合记忆对记忆稳定性的影响。</p><p>为了实现新的算法，我们定义了记忆的三个组成成分如下:</p><ul><li>记忆稳定性(S)被定义为在复习时产生 0.9 的平均回忆概率的重复间隔。<br/><br/></li><li>记忆可提取性(R)被定义为在假设同质学习材料按负指数函数遗忘的前提下，任意时刻的期望回忆概率，衰减常数由记忆稳定性(S)决定<br/><br/></li><li>项目难度(D)定义为复习时记忆稳定性(S)可能增加的最大值，线性映射到 0..1 区间，0 代表最容易的可能项目，1 代表 SuperMemo 中考虑的最高难度(目前的截止极限是稳定性增加 6 倍于记录的最大值)</li></ul><h2>证明</h2><p>下面是我硕士论文中的实际证明。这些语言和模型已经有 30 年的历史了，而且有些笨拙。然而，核心思想至今仍然站得住脚。要更好地理解证明，请参见 Murakowski 的证明。</p><blockquote>档案警告：为什么要使用文字档案？ <br/>这篇文章是：“优化学习” (1990) <a class="wrap external" href="https://supermemo.guru/wiki/Piotr_Wozniak" rel="nofollow noreferrer" target="_blank">Piotr Wozniak</a> 的一部分</blockquote><p>10.4.2. 记忆的两个变量：稳定性和可提取性</p><p>有一个重要的结论直接来自于 SuperMemo 理论，那就是有两个变量，而不是像人们通常认为的一个描述突触电导率和一般记忆的变量。为了说明这种情况，让我们再次考虑突触记忆的 calpain 模型。从模型中可以明显看出，它的作者假设只需要一个自变量来描述突触的传导性。钙的内流、钙蛋白酶的活性、食物蛋白的降解和谷氨酸受体的数量都是这种变量的例子。请注意，所有提到的参数都是相关的，即知道其中一个参数，我们可以计算所有其他参数；显然，只有在能够构造相关公式的情况下才能计算。参数的依赖性是它们之间因果联系的直接结果。<br/> <br/>然而，最佳学习过程恰好需要两个独立变量来描述给定时刻突触的状态：</p><ul><li>起时钟作用的变量，用于测量两次重复之间的时间。这里可以使用的示例性参数包括：<br/><br/></li><ul><li><img alt=" T_e  " eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=+T_e++"/> - 自上次重复以来已经过去的时间（属于区间 &lt;0，最佳间隔&gt;），<br/><br/></li><li><img alt="T_L" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=T_L"/> - 在下一次重复发生之前必须经过的时间（<img alt="T_L" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=T_L"/>= 最佳间隔 - <img alt=" T_e  " eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=+T_e++"/>），<br/><br/></li><li><img alt="P_f" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=P_f"/> - 突触在有问题的一天内丢失记忆痕迹的概率（属于区间 &lt;0，1&gt;）。<br/><br/></li></ul><li>衡量记忆持久性的变量。这里可以使用的示例性参数包括：<br/><br/></li><ul><li>I(n+1) - 在下一次重复之后应该使用的最佳间隔（I(n+1)=I(n)*C，其中 C 是大于 3 的常数），<br/><br/></li><li>I(n) - 现在的最佳间隔<br/><br/></li><li>n - 在回答问题的时刻之前重复的次数等。</li></ul></ul><p>现在让我们看看上述变量是否充分必要地描述突触在时间最优学习过程中的状态。为了说明变量是相互独立的，我们将说明它们之间没有一个可以相互计算。让我们注意到，在给定的重复间隔内，I(n) 参数保持不变，而  <img alt="T_e" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=T_e"/>  参数从 0 变为 I(n)。这表明没有满足条件的函数 f：</p><p><img alt="T_e=f(I(n))" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=T_e%3Df%28I%28n%29%29"/> </p><p>另一方面，在随后的重复时刻，<img alt="T_e" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=T_e"/> 总是等于零，而 I(n) 总是有一个不同的、递增的值。因此，不存在满足条件的函数 g：</p><p><img alt="I(n)=g(T_e)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=I%28n%29%3Dg%28T_e%29"/></p><p>因此 I(n) 和 <img alt="T_e" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=T_e"/> 是独立的。</p><p>为了说明在最优学习过程中不需要其他变量，让我们注意到，在任何给定时间，我们都可以使用下面的算法计算未来重复的所有时刻：</p><ol><li> 经过 I(n)- <img alt="T_e" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=T_e"/>  天</li><li>让我们重复一遍。</li><li>令 <img alt="T_e" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=T_e"/> 为零，I(n) 增加 C 倍。</li><li>回到 1。</li></ol><p>请注意，对于给定的突触，C 的值是一个恒定的特征，因此在学习过程中不会改变。稍后我将使用术语<b>可提取性</b>来表示第一个变量，使用术语<b>稳定性</b>来表示第二个变量。为了证明第一个学期的选择是合理的，让我注意到，我们过去常常认为记忆在学习任务之后是强烈的，然后它们就会消失，直到它们变得不再可以找回。这是决定记忆何时不再存在的可提取性。还值得一提的是，可提取性是被默认为唯一需要描述记忆的变量(就像在 calain 模型中一样)。稳定性变量的不可见性是因为研究人员将精力集中在单一的学习任务和观察突触的后续变化上，而稳定性的重要性只有在多次重复同一任务的过程中才能可视化。为了总结对记忆变量的分析，让我们提出在开发任何生物模型时必须提出的标准问题。记忆的两个变量的存在可能产生的进化优势是什么？</p><p>可提取性和稳定性对于编写一个学习过程的代码都是必要的，该学习过程允许随后的重复间隔在不遗忘的情况下增加长度。很容易证明，就个人的存活率而言，这种学习模式是最好的，如果我们承认这样一个事实，即记住而不遗忘会在短时间内阻塞有限的记忆系统。如果记忆是健忘的，它必须有一种方法来保留这些似乎对生存很重要的痕迹。重复作为一种增强记忆的因素就是这样一种方法。现在让我们考虑一下重复过程的最合适时机是什么。如果一个给定的现象出现 n 次，那么它出现 n+1 次的可能性就会增加，因此更长的记忆保留时间似乎是有利的。描述最佳重复过程的确切函数取决于记忆存储的大小、个人可能遇到的现象的数量以及许多其他因素。然而，通过重复记忆来维持记忆所需要的时间间隔的增加，以及记忆的可提取性和稳定性的进化价值，都是无可争议的。我们可以想象，在进化过程中，许多情况都会干扰记忆发展的简单图景。例如，与强烈压力相关的事件应该被更好地记住。事实上，儿茶酚胺对学习影响的研究证实了这一点。也许，使用荷尔蒙刺激可以提高应用 SuperMemo 方法的学生的表现。</p><p><b>临时摘要</b></p><ol><li>假设存在描述最优学习过程所需的两个自变量。这些变量被命名为记忆的可提取性和稳定性<br/><br/></li><li>记忆的可提取性反映了重复之间的时间间隔，并指示记忆痕迹在回忆过程中能在多大程度上被成功利用<br/><br/></li><li>记忆的稳定性反映了学习过程中重复的历史，并且随着突触的每一次刺激而增加。它确定最佳重复间隔的长度</li></ol><figure><img class="origin_image zh-lightbox-thumb lazy" data-actualsrc="https://pic4.zhimg.com/v2-670a3760d1ba148495419a7bd46514df_b.jpg" data-caption="" src="https://pic4.zhimg.com/v2-670a3760d1ba148495419a7bd46514df_r.jpg" data-rawheight="600" data-rawwidth="426" data-size="normal" src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='426' height='600'&gt;&lt;/svg&gt;" width="426"/></figure><blockquote><b>图：</b>在我的硕士论文“优化学习”(1990)中，我提出了一些假设概念，这些概念可能是基于间隔重复的优化学习过程的基础。(A)分子现象 (B)突触的数量变化。这些观点在今天看来有些过时，但代表记忆可提取性的锯齿形曲线在有关间隔重复的流行出版物中得到了广泛的认识。它们通常被错误地归因于赫尔曼•艾宾浩斯 </blockquote><h2>Murakowski 的证明</h2><p>这里有一份由 <a class="wrap external" href="https://supermemo.guru/wiki/Janusz_Murakowski" rel="nofollow noreferrer" target="_blank">Murakowski</a> 提交的证明：</p><blockquote>在早期的研究中已经发现，配对联想学习中的最佳重复间隔，理解为需要最小重复次数才能无限期地保持恒定的知识保持水平(例如95%)的间隔，可以用以下公式大致表示(<a class="wrap external" href="https://supermemo.guru/wiki/Optimization_of_repetition_spacing_in_the_practice_of_learning" rel="nofollow noreferrer" target="_blank">Wozniak 和 Gorzelanczyk，1994</a>)：</blockquote><ul><li>(1)  <img alt="I_1=C_1" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=I_1%3DC_1"/> </li><li>(2)  <img alt="I_i=I_{i-1}*C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=I_i%3DI_%7Bi-1%7D%2AC_2"/> </li></ul><p> 这里：</p><ul><li><img alt="I_i" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=I_i"/>  - 第 i 次重复后的重复间隔。</li><li><img alt="C_1" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_1"/> - 第一个间隔的长度(取决于所选的知识保留，通常等于几天)。</li><li><img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> - 常数，表示后续重复中重复间隔的增加(取决于所选的知识记忆和记忆项目的难度)</li></ul><p>上述公式是使用计算机优化过程为人类受试者找到的，该计算机优化过程使用主动回忆丢弃技术来监督单词对的自定步速学习过程。[...]</p><p>如下所示，被广泛研究的记忆强度(或突触增强)不足以解释最佳重复间隔的规律：<i>[...]</i></p><ol><li> 我们想要确定存储记忆痕迹所涉及的(分子)变量集，这些变量足以说明最佳重复间隔。首先，让我们假设这些变量在学习中的两个相关性，它们受制于公式(1)及(2)所表示的最佳间距：<br/></li><ol><li><i>r</i> - 从当前时刻到当前最佳间隔结束的剩余时间(最佳间隔是指保留率在结束时降至先前定义的水平的间隔，例如 95%)。</li><li><i>s</i> - 当前最佳间隔的长度。<br/><br/></li></ol><li> 仅在第 i 次重复开始时， <img alt="r=0" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r%3D0"/> ，而  <img alt="s_i&gt;s_{i-1}&gt;0" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s_i%3Es_%7Bi-1%7D%3E0"/>  ( <img alt="s_i" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s_i"/> 表示正好在第 i 次重复开始时的 <img alt="s" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s"/>)。这表明没有函数  <img alt="g_1" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=g_1"/>  使得 <img alt="s=g_1(R)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s%3Dg_1%28R%29"/> ，即 <img alt="s" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s"/> 不能只是 <img alt="r" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r"/> 的函数。<br/><br/></li><li> 在重复间隔期间， <img alt="r(t_1)&lt;&gt;r(t_2)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r%28t_1%29%3C%3Er%28t_2%29"/> 当 <img alt="r(t_1)&lt;&gt;r(t_2)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r%28t_1%29%3C%3Er%28t_2%29"/> ( <img alt="t" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=t"/> 表示时间， <img alt="r(t)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r%28t%29"/>  表示时刻 <img alt="t" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=t"/>)。另一方面， <img alt="s(t_1)=s(t_2)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s%28t_1%29%3Ds%28t_2%29"/>  ( <img alt="s(t)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s%28t%29"/> 表示此时的 <img alt="s" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s"/>)。这表明不存在函数  <img alt="g_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=g_2"/>  使得  <img alt="r=g_2(s)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r%3Dg_2%28s%29"/> ，否则我们将有： <img alt="r(t_1)=g_2(s(t_1))=g_2(s(t_2))=r(t_2)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r%28t_1%29%3Dg_2%28s%28t_1%29%29%3Dg_2%28s%28t_2%29%29%3Dr%28t_2%29"/> ，这导致了一个矛盾。<img alt="r" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r"/> 不能仅是 <img alt="s" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s"/> 的函数。<br/><br/></li><li> 在步骤 2 和 3 中，我们已经证明了 <img alt="r" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r"/> 和 <img alt="s" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s"/> 是独立的，因为没有函数 <img alt="g_1" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=g_1"/> 和  <img alt="g_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=g_2"/>  使得 <img alt="r=g_2(s)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r%3Dg_2%28s%29"/> 或 <img alt="r=g_2(s)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r%3Dg_2%28s%29"/> 。这显然不意味着没有参数  <img alt="x" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=x"/>  和函数 <img alt="y_s" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=y_s"/> 和  <img alt="y_r" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=y_r"/>  使得 <img alt="s=y_s(x)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s%3Dy_s%28x%29"/> 和 <img alt="r=y_r(x)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r%3Dy_r%28x%29"/> 。 <br/><br/></li><li> 可以看出，<img alt="r" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r"/> 和 <img alt="s" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s"/> 足以计算最佳重复间隔(参见方程式(1)及(2))。让我们首先假设以下两个函数 <img alt="f_r" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=f_r"/> 和 <img alt="f_s" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=f_s"/> 在 s 涉及记忆存储i的系统中是已知的： <img alt="r_i=f_r(s_i)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r_i%3Df_r%28s_i%29"/>  和  <img alt="s_i=f_s(s_{i-1})" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s_i%3Df_s%28s_%7Bi-1%7D%29"/> 。在我们的例子中，这些函数具有平凡的形式 <img alt="f_r：r_i=s_i" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=f_r%EF%BC%9Ar_i%3Ds_i"/> 和 <img alt="f_s：s_i=s_{i-1}*C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=f_s%EF%BC%9As_i%3Ds_%7Bi-1%7D%2AC_2"/> (其中 <img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 是公式(2)中的常量。在这种情况下，变量 <img alt="r" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r"/> 和 <img alt="s" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s"/> 足以在任何时刻 <img alt="t" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=t"/> 以最佳重复间隔表示记忆。以下是重复间隔算法，它表明这是正确的：<br/></li><ol><li> 假设变量  <img alt="r_i" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r_i"/>  和  <img alt="s_i" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s_i"/>  描述第 i 次重复后的记忆状态</li><li>时间流逝  <img alt="r_i" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r_i"/> </li><li>开始重复</li><li>让函数  <img alt="f_s" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=f_s"/>  用于从  <img alt="s_i" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s_i"/>  计算新值  <img alt="s_{i+1}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s_%7Bi%2B1%7D"/> </li><li>让函数  <img alt="f_r" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=f_r"/>  用于从  <img alt="s_{i+1}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=s_%7Bi%2B1%7D"/>  计算新值  <img alt="r_{i+1}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=r_%7Bi%2B1%7D"/> </li><li><img alt="i:=i+1" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=i%3A%3Di%2B1"/> </li><li>回到 2</li></ol></ol><p>上述推理表明，变量 r 和 s 形成了计算最佳重复间隔所需的足够的自变量集合。显然，使用形式为 r''=Tr(r') 和 s''=Ts(s') 的一组变换函数，可以设想可以描述记忆系统状态的变量对 r-s 的无穷族。一个困难的选择仍然是选择这样一对 r-s，它将最方便地与突触水平上发生的分子现象相对应。</p><p>在涉及 r-s 对变量的记忆系统中，作者提出了以下术语和解释：变量 R(可提取性)确定在给定时刻可以调用给定记忆轨迹的概率，而变量 S(记忆的稳定性)确定由于遗忘而导致的可提取性下降的速率，从而确定最佳重复间隔中的重复间隔的长度。</p><p>假设可提取性以负指数下降，并将稳定性解释为可提取性衰减常数的倒数，我们可以方便地使用以下公式(t 表示时间)来表示 R 和 S 之间的关系：</p><p>(3)  <img alt="R=e^{-t/S}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=R%3De%5E%7B-t%2FS%7D"/> </p><p>从推理的步骤 1-5 中使用的 r-s 对到建议的解释 R-S 的变换函数如下(假设最佳重复间隔的定义为产生知识保持的间隔 K=0.95)：</p><p>(4)  <img alt="S=-s/\ln(K)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=S%3D-s%2F%5Cln%28K%29"/> <br/>(5)  <img alt="R=e^{-(s-r)/S}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=R%3De%5E%7B-%28s-r%29%2FS%7D"/> </p><p>因此，第 i 次重复后的稳定性( <img alt="S_i" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=S_i"/> )与确定由公式(1)和(2)定义的最佳重复间隔的常数  <img alt="C_1" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_1"/>  和 <img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 之间的关系可以写成：</p><p>(6) <img alt="S_i=-(C_1*C_2^{i-1})/\ln(K)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=S_i%3D-%28C_1%2AC_2%5E%7Bi-1%7D%29%2F%5Cln%28K%29"/> </p><p>最后，在最佳重复间隔中的可提取性可以表示为：</p><p>(7)  <img alt="R_i(t)=\exp^{(t\ln(K)/(C_1C_2^{i-1}))}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=R_i%28t%29%3D%5Cexp%5E%7B%28t%5Cln%28K%29%2F%28C_1C_2%5E%7Bi-1%7D%29%29%7D"/> </p><p>其中：</p><ul><li>i - 问题的重复次数</li><li>t - 从第 i 次重复开始的时间</li><li><img alt="R_i(t)" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=R_i%28t%29"/> - 自第 i 次重复以来经过时间  t 之后的最佳重复间隔的可提取性</li><li><img alt="C_1" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_1"/> 和 <img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> - 来自公式(1)和(2)的常量。</li><li>K-知识保留量等于 0.95(重要的 是要注意由公式(7)表示的关系。由于较短间隔产生的间距效应，保留率高于 0.95 的情况可能不成立)</li></ul><h2>SuperMemo 中的记忆的两个组成成分</h2><p>SuperMemo 一直基于记忆的双组分模型，该模型在过去 30 年中以越来越明显的形式出现。公式(2) 中的常数 <img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 在 Murakowski 的上述证明中表示稳定性增加。2018 年，稳定性增加在 SuperMemo 中表示为矩阵 SInc[]。<img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 说明在学习中应该增加多少重复间隔，才能达到可接受的遗忘水平标准。实际上，<img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 不是常数。这取决于许多因素。其中，最重要的是：</p><ul><li>项目难度(D)(参见：复杂性)：记住的信息越难，<img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 越小(即必须更频繁地复习困难的材料)<br/><br/></li><li><a class="wrap external" href="https://supermemo.guru/wiki/Memory_stability" rel="nofollow noreferrer" target="_blank">记忆稳定性</a> (S)：记忆越持久，<img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 值越小<br/><br/></li><li>回忆概率(<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>)(R)：回忆的概率越低，<img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 值越高(即由于<a class="wrap external" href="https://supermemo.guru/wiki/Spacing_effect" rel="nofollow noreferrer" target="_blank">间隔效应</a>，如果延迟查看项目，可以更好地记住它们)</li></ul><p>由于这些多重依赖关系，<img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 的精确值不容易预测。SuperMemo 通过使用多维矩阵来表示多自变量函数，并根据在实际学习过程中所做的测量来调整这些矩阵的值，从而解决了这个和类似的优化问题。这些矩阵的初始值是从理论模型或从先前的测量中导出的。随着时间的推移，实际使用的值将与理论预测的值或根据以前学生的数据得出的值略有不同。</p><p>例如，如果给定难度、给定记忆状态的给定项的 <img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 值产生的重复间隔比期望的间隔长(即产生的回忆率低于期望的水平)，则 <img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 值相应减少。</p><p>以下是<a class="wrap external" href="https://supermemo.guru/wiki/Stability_increase" rel="nofollow noreferrer" target="_blank">稳定性增加</a>(常数 <img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/>)多年来的演变：</p><ul><li>在纸笔版本的 SuperMemo(1985) 中，<img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 确实(几乎)是一个常数。设置为平均 1.75 (为了舍入误差和简单性，从 1.5 到 2.0 不等)，没有考虑材料难度、稳定性或记忆的可提取性等。<br/><br/></li><li>在 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo_for_DOS" rel="nofollow noreferrer" target="_blank">SuperMemo for DOS</a>(1987) 的早期版本中，<img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> (命名为 E-因子)首次反映了项目难度。成绩不好时降低，成绩好时增加。<br/><br/></li><li>SuperMemo 4(1989) 没有使用 <img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/>，但是为了计算重复间隔，它第一次使用了优化矩阵<br/><br/></li><li>在 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo_5" rel="nofollow noreferrer" target="_blank">SuperMemo 5</a> (1990) 中，<img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> (命名为 O-因子)最终被表示为一个矩阵，它既包括难度维度，也包括稳定性维度。同样，矩阵的条目将受到测量-验证-校正循环的影响，该循环将从基于先前测量的初始值开始，产生向满足学习标准的值的收敛<br/><br/></li><li>在 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo_6" rel="nofollow noreferrer" target="_blank">SuperMemo 6</a>(1991) 中，<img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 以 <a class="wrap external" href="https://supermemo.guru/wiki/O-Factor_matrix" rel="nofollow noreferrer" target="_blank">O-因子矩阵</a>的形式派生自一个包含可提取性维度的三维矩阵。第三维度的重要意义是，<a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 第一次使检查不同难度和记忆稳定性的遗忘曲线成为可能<br/><br/></li><li>在 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo_8" rel="nofollow noreferrer" target="_blank">SuperMemo 8</a>(1997) 到 <a class="wrap external" href="https://link.zhihu.com/?target=http%3A//www.super-memo.com/supermemo16.html" rel="nofollow noreferrer" target="_blank">SuperMemo 16</a> 中，<img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 的表示没有有太大变化，但是，用于产生从理论数据到真实数据的快速而稳定的转换的算法将逐渐变得越来越复杂。最重要的是，新的 SuperMemo 更好地利用了 <img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 的可提取性性维度。因此，与间隔效应无关，学生可以偏离初始学习标准，例如在考试前临时抱佛脚，而不会在优化过程中引入噪声<br/><br/></li><li>在 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo_17" rel="nofollow noreferrer" target="_blank">SuperMemo 17</a> (2016) 中， <img alt="C_2" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=C_2"/> 最终采取了基于最初的记忆双组分模型的形式。它取自稳定性增加矩阵(SInc)，该矩阵具有三个维度，表示决定稳定性增加的三个变量：复杂性、稳定性和可提取性。在使用称为算法 SM-17 的复杂算法学习期间用数据填充 SInc 矩阵。可使用 <b>Tools：Memory：4D Graphs</b> (<b>稳定性</b> 选项卡)在 SuperMemo 17 中检查稳定性增加矩阵。</li></ul><hr/><p>下一章：<a class="internal" href="https://zhuanlan.zhihu.com/p/205600711">06 1989: SuperMemo 适应用户记忆(上)</a></p><p></p></div>