<meta charset="UTF-8">
05 1988：记忆的两个组成成分
<p data-pid="t82yH_S0">如果你没有时间阅读长文，建议看：<a href="https://zhuanlan.zhihu.com/p/179076885" class="internal">浓缩通俗版</a></p><p data-pid="pzIsHe0I"><b>注意：由于知乎对 markdown 的支持不完善，部分排版可能影响阅读体验。</b></p><p data-pid="28g-YAld"><b>推荐在这里阅读：</b></p><a href="http://link.zhihu.com/?target=https%3A//www.kancloud.cn/ankigaokao/supermemo-guru-cn/1895544" data-draft-node="block" data-draft-type="link-card" class=" wrap external" target="_blank" rel="nofollow noreferrer">05.1988：记忆的两个组成成分</a><p data-pid="L9ynyMru">本文提出的记忆双组分模型很有启发意义，推荐阅读。</p><hr><h2>1988: Two component of memory</h2><h2>1988：记忆的两个组成成分</h2><p data-pid="ECdPiRPW"><a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Two-component_model_of_long-term_memory" class=" wrap external" target="_blank" rel="nofollow noreferrer">Two-component model of long-term memory</a> lays at the foundation of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a>, and is expressed explicitly in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Algorithm_SM-17" class=" wrap external" target="_blank" rel="nofollow noreferrer">Algorithm SM-17</a>. It differentiates between how <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">stable</a> knowledge is in long term memory storage, and how <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">easy it is to retrieve</a>. This remains a little known and quintessential fact of the theory of learning that one can be fluent and still remember poorly.</p><p data-pid="McbPwJaR">长期记忆的双组分模型是 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a> 的基础，并在 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Algorithm_SM-17" class=" wrap external" target="_blank" rel="nofollow noreferrer">SM-17 算法</a>中明确表示。它区分了知识在长期记忆存储中的稳定性和提取的难易程度。这仍然是学习理论中一个鲜为人知的典型事实，即一个人可以流利，但记忆力仍然很差。</p><p data-pid="GRLJ0xvI">Fluency is a poor measure of learning in the long term</p><p data-pid="2WxRaRSn">从长远来看，流利度并不能很好地衡量学习效果。</p><h2>Components of long-term memory</h2><h2>长期记忆的组成成分</h2><p data-pid="pJLMhfI4">For many years, memory researchers used the term <i>strength of memory</i>. It was supposed to reflect how well things are remembered.</p><p data-pid="BuY_hC6N">多年来，记忆研究人员一直使用“记忆强度”这个词。它应该反映出人们对事物的记忆有多好。</p><p data-pid="3XiLm2sr">My work over <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Spaced_repetition" class=" wrap external" target="_blank" rel="nofollow noreferrer">spaced repetition</a> in the mid 1980s lead to a quick realization that one variable, <i>strength</i>, is not enough to describe the status of a piece of knowledge stored in long-term memory. We need two variables that separate the strength from the ease with which a fact can be retrieved from memory.</p><p data-pid="f99Drjmr">上世纪 80 年代中期，我对<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Spaced_repetition" class=" wrap external" target="_blank" rel="nofollow noreferrer">间隔重复</a>的研究让我很快意识到，一个<i>强度</i>变量不足以描述存储在长期记忆中的知识的状态。我们需要两个变量来区分事实从记忆中提取的难易程度。</p><p data-pid="G-Zfy3ND">I concluded that the status of a piece of knowledge stored in long-term memory can be described by two variables that I named: <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">stability</a> and <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">retrievability</a>. Stability of memory tells you how long the memory can last in the storage. Retrievability tells you how easy it is to recall a piece of knowledge. Those two variables used to be conflated in memory research.</p><p data-pid="JRekoCG_">我的结论是，存储在长期记忆中的知识的状态可以用两个变量来描述：<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">稳定性</a>和<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">可提取性</a>。记忆的稳定性告诉您记忆在存储中可以持续多长时间。可提取性告诉你回忆一段知识是多么容易。在记忆研究中，这两个变量常常被混为一谈。</p><p data-pid="eYTrV2jB">Amazingly, three decades after my observations, the idea of two components of memory is still to permeate mainstream memory research. In 2018, most of papers ignore the separation between the two variables and still rely on a single concept of <i>memory strength</i>. This leads to monumental confusion and slow progress in research.</p><p data-pid="NAsMJzPP">令人惊讶的是，在我观察了三十年之后，记忆的两个组成成分的概念仍然在渗透主流的记忆研究。2018 年，大多数论文忽略了这两个变量的分离，仍然依赖于单一的“记忆强度”概念。这导致了巨大的困惑和研究进展缓慢。</p><h2>Origins of the two component model of memory</h2><h2>记忆双组分模型的起源</h2><p data-pid="DKQlVu23">I first described the idea of the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Two_component_model_of_memory" class=" wrap external" target="_blank" rel="nofollow noreferrer">two components of long-term memory</a> in a paper for my computer simulations class on Jan 9, 1988. In an unrelated line of reasoning, in the same paper, I concluded that different circuits must be involved in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Declarative_learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">declarative</a> and <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Procedural_learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">procedural learning</a>.</p><p data-pid="sl5YiANz">1988 年 1 月 9 日，我在计算机模拟课上的一篇论文中首次描述了<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Two_component_model_of_memory" class=" wrap external" target="_blank" rel="nofollow noreferrer">长期记忆的两个组成成分</a>。在同一篇论文中，我用了一种不相关的推理方法，得出结论：<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/programural_learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">陈述性学习</a>和<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/programural_learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">过程性学习</a>一定涉及不同的回路。</p><p data-pid="WdQ-MIDP">If you pause for a minute, the whole idea of the two components should be pretty obvious. If you take two <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Item" class=" wrap external" target="_blank" rel="nofollow noreferrer">memories</a> right after a review, one with a short <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Optimum_interval" class=" wrap external" target="_blank" rel="nofollow noreferrer">optimum interval</a>, and the other with a long optimum interval, the memory status of the two must differ. Both can be recalled perfectly (maximum <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">retrievability</a>) and they also need to differ in how long they can last in memory (different <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">stability</a>). I was surprised I could not find any literature on the subject. However, if the literature has no mention of the existence of the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Optimum_interval" class=" wrap external" target="_blank" rel="nofollow noreferrer">optimum interval</a> in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Spaced_repetition" class=" wrap external" target="_blank" rel="nofollow noreferrer">spaced repetition</a>, this seemingly obvious conclusion might be hiding behind another seemingly obvious idea: the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Birth_of_SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">progression of increasing interval in optimally spaced review</a>. This is a lovely illustration how human progress is incremental and agonizingly slow. We are notoriously bad at thinking out of the box. The darkest place is under the candlestick. This weakness can be broken with an explosion of communication on the web. I advocate less <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Peer_review" class=" wrap external" target="_blank" rel="nofollow noreferrer">peer review</a>, and more bold hypothesizing. I speak of a fantastic example coming from <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Bad_learning_contributes_to_Alzheimer%27s" class=" wrap external" target="_blank" rel="nofollow noreferrer">Robin Clarke's paper in reference to Alzheimer's</a>. Strict peer review is reminiscent of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Prussian_education_system" class=" wrap external" target="_blank" rel="nofollow noreferrer">Prussian schooling</a>: in the quest for perfection, we lose our creativity, then humanity, and ultimately the pleasure of life.</p><p data-pid="eaccxy3O">如果您停下来思考一分钟，那么双组分的整个思想应该是非常显然的。如果你在复习后马上取两段记忆，一段最佳时间间隔很短，另一段最佳时间间隔很长，那么这两段记忆的记忆状态必然不同。两者都可以被完美地回忆(最大的可提取性)，它们还需要在记忆中持续的时间上有所不同(不同的稳定性)。我很惊讶我找不到任何关于这个主题的文献。然而，如果文献中没有提及在间隔重复中存在最优间隔，那么这个看似明显的结论可能隐藏在另一个看似明显的概念背后：在最优间隔复习中间隔递增的级数。这是一个可爱的例子，说明人类的进步是渐进的，而且缓慢得令人痛苦。我们是出了名的不善于创新。烛台下最暗。这一弱点可以通过网络交流的爆炸来打破。我主张少一些同行审查，多一些大胆的假设。我提到了 Robin Clarke 关于阿尔茨海默病的论文中的一个很好的例子。严格的同行审查让人想起普鲁士的学校教育：在追求完美的过程中，我们失去了创造力，失去了人性，最终失去了生活的乐趣。</p><p data-pid="3Bs3_8JH">When I first presented my ideas to my teacher Dr Katulski on Feb 19, 1988, he was not too impressed, but he gave me a pass for computer simulations credit. Incidentally, a while later, Katulski became one of the first users of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo_1.0_for_DOS" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo 1.0 for DOS</a>.</p><p data-pid="5bRma2w8">1988 年 2 月 19 日，当我第一次向我的老师 Katulski 博士提出我的想法时，他并没有给我留下太深刻的印象，但他给了我一张计算机模拟学分的通行证。顺便说一句，不久之后，Katulski 成为 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo_1.0_for_DOS" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo 1.0 for DOS</a> 的首批用户之一。</p><p data-pid="pFL_cZyI">In my <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Master%27s_Thesis" class=" wrap external" target="_blank" rel="nofollow noreferrer">Master's Thesis</a> (1990), I added a slightly more formal proof of the existence of the two components (see <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/History_of_spaced_repetition_%28print%29%23Proof" class=" wrap external" target="_blank" rel="nofollow noreferrer">next</a>). That part of my thesis remained unnoticed.</p><p data-pid="3KzPCicL">在我的<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Master%27s%2520_thesis" class=" wrap external" target="_blank" rel="nofollow noreferrer">硕士论文</a>(1990)中，我添加了一个稍微正式的证明，证明这两个组件的存在(参见<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/History_of_spaced_repetition_%28print%29%23%2520proof" class=" wrap external" target="_blank" rel="nofollow noreferrer">下一节</a>)。我论文的那一部分没有引起注意。</p><p data-pid="kBirFTvp">In 1994, J. Kowalski <a href="http://link.zhihu.com/?target=http%3A//www.super-memory.com/articles/kowal.htm" class=" wrap external" target="_blank" rel="nofollow noreferrer">wrote in Enter</a>, Poland:</p><p data-pid="F0gk3pEJ">1994年，J.Kowalski 在波兰恩特写道：</p><blockquote data-pid="VvenyZ6A"> We got to the point where the evolutionary interpretation of memory indicates that it works using the principles of increasing intervals and the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Spacing_effect" class=" wrap external" target="_blank" rel="nofollow noreferrer">spacing effect</a>. Is there any proof for this model of memory apart from the evolutionary speculation? In his Doctoral Dissertation, Wozniak discussed widely molecular aspects of memory and has presented a hypothetical model of changes occurring in the synapse in the process of learning. The novel element presented in the thesis was the distinction between the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">stability</a> and <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">retrievability</a> of memory traces. This could not be used to support the validity of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a> because of the simple fact that it was SuperMemo itself that laid the groundwork for the hypothesis. However, an increasing molecular evidence seems to coincide with the stability-retrievability model providing, at the same time, support for the correctness of assumptions leading to SuperMemo. In plain terms, retrievability is a property of memory which determines the level of efficiency with which synapses can fire in response to the stimulus, and thus elicit the learned action. The lower the retrievability the less you are likely to recall the correct response to a question. On the other hand, stability reflects the history of earlier repetitions and determines the extent of time in which memory traces can be sustained. The higher the stability of memory, the longer it will take for the retrievability to drop to the zero level, i.e. to the level where memories are permanently lost. According to Wozniak, when we learn something for the first time we experience a slight increase in the stability and retrievability in synapses involved in coding the particular stimulus-response association. In time, retrievability declines rapidly; the phenomenon equivalent to forgetting. At the same time, the stability of memory remains at the approximately same level. However, if we repeat the association before retrievability drops to zero, retrievability regains its initial value, while stability increases to a new level, substantially higher than at primary learning. Before the next repetition takes place, due to increased stability, retrievability decreases at a slower pace, and the inter-repetition interval might be much longer before forgetting takes place. Two other important properties of memory should also be noted: (1) repetitions have no power to increase the stability at times when retrievability is high (spacing effect), (2) upon forgetting, stability declines rapidly<br><br> 我们已经到了这样一个阶段，对记忆的进化解释表明，它使用的原理是增加间隔和<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Spacing_effect" class=" wrap external" target="_blank" rel="nofollow noreferrer">间隔效应</a>。除了进化论的推测外，还有什么证据可以证明这种记忆模型吗？在他的博士论文中，Wozniak 广泛地讨论了记忆的分子层面，并提出了一个假设模型，描述了学习过程中突触发生的变化。本文提出的新元素是记忆痕迹的<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">稳定性</a>和<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">可提取性</a>之间的区别。这不能用来支持 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a> 的有效性，因为一个简单的事实是，正是 SuperMemo 本身奠定了假设的基础。然而，越来越多的分子层面证据似乎与稳定性-可提取性模型相吻合，同时，该模型为导向 SuperMemo 的假设的正确性提供了支持。简单地说，可提取性是记忆的一种属性，它决定了突触对刺激反应的效率水平，从而引发学习行为。可提取性越低，您就越不可能回忆起对问题的正确回答。另一方面，稳定性反映了早期重复的历史，并决定了记忆痕迹能够维持的时间范围。记忆的稳定性越高，可提取性下降到零，即下降到记忆永久遗忘所需的时间就越长。根据 Wozniak 的说法，当我们第一次学习某样东西的时候，我们会在编码特定刺激反应关联的突触中体验到稳定性和可提取性的轻微提高。随着时间的推移，可提取性迅速下降；相当于遗忘的现象。同时，记忆的稳定性保持在大致相同的水平。然而，如果我们在可提取性下降到零之前重复这种关联，可提取性将恢复其初始值，而稳定性将增加到一个新的水平，显著高于初次学习时的水平。在下一次重复发生之前，由于稳定性的提高，可提取性以较慢的速度下降，在遗忘发生之前，重复之间的间隔可能要长得多。记忆的另外两个重要特性也应该注意到：(1) 当可提取性高时，重复不能增加稳定性(间隔效应)，(2) 遗忘时，稳定性迅速下降</blockquote><h2>Peer review publication (1995)</h2><h2>同行评议刊物 (1995)</h2><p data-pid="imfW1Q-7">We published our ideas with Drs <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Janusz_Murakowski" class=" wrap external" target="_blank" rel="nofollow noreferrer">Janusz Murakowski</a> and <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Edward_Gorzelanczyk" class=" wrap external" target="_blank" rel="nofollow noreferrer">Edward Gorzelanczyk</a> in <a href="http://link.zhihu.com/?target=http%3A//super-memory.com/english/2vm.htm" class=" wrap external" target="_blank" rel="nofollow noreferrer">1995</a>. Murakowski perfected the mathematical proof. Gorzelanczyk fleshed out the molecular model. We have not heard much enthusiasm or feedback from the scientific community. The idea of two components of memory is like wine, the older it gets, the better it tastes. We keep wondering when it will receive a wider recognition. After all, we do not live in <a href="http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Gregor_Mendel" class=" wrap external" target="_blank" rel="nofollow noreferrer">Mendel</a>'s time to keep a good gem hidden in some obscure archive. There are <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Exponential_adoption_of_spaced_repetition" class=" wrap external" target="_blank" rel="nofollow noreferrer">millions of users</a> of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Spaced_repetition" class=" wrap external" target="_blank" rel="nofollow noreferrer">spaced repetition</a> and even if 0.1% got interested in the theory, they would hear of our two components. Today, even the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Algorithm_SM-17" class=" wrap external" target="_blank" rel="nofollow noreferrer">newest algorithm</a> in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a> is based on the two-component model and it works like a charm. Ironically, users tend to flock to <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Algorithm_SM-2" class=" wrap external" target="_blank" rel="nofollow noreferrer">simpler solutions</a>, where all the mechanics of human memory remain hidden. Even at <a href="http://link.zhihu.com/?target=http%3A//supermemo.com/" class=" wrap external" target="_blank" rel="nofollow noreferrer">supermemo.com</a> we make sure we do not scare customers with excess numbers on the screen. This way we trade the instructional power of the model for better adoption among users who crave simplicity.</p><p data-pid="sBun0JRI">我们与 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Janusz_Murakowski" class=" wrap external" target="_blank" rel="nofollow noreferrer">Janusz Murakowski 博士</a>和 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Edward_Gorzelanczyk" class=" wrap external" target="_blank" rel="nofollow noreferrer">Edward Gorzelanczyk 博士</a> 在 <a href="http://link.zhihu.com/?target=http%3A//supermemory.com/english/2vm.htm" class=" wrap external" target="_blank" rel="nofollow noreferrer">1995</a> 发表了我们的想法。Murakowski 完善了数学证明。Gorzelanczyk 充实了分子模型。我们没有从科学界听到太多的热情和反馈。记忆的两个组成成分的概念就像葡萄酒，时间越久，味道就越好。我们一直想知道它什么时候会得到更广泛的认可。毕竟，我们并不是生活在<a href="http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Gregor_Mendel" class=" wrap external" target="_blank" rel="nofollow noreferrer">孟德尔</a>的时代，把一块好宝石藏在某个晦涩的档案中。间隔重复的用户数以百万计，即使只有 0.1% 的人对这个理论感兴趣，他们也会听说我们的两个组分。今天，甚至 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Algorithm_SM-17" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a> 中的<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">最新算法</a>都是基于双组分模型的，而且运行起来很有魅力。具有讽刺意味的是，用户往往会涌向<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Algorithm_SM-2" class=" wrap external" target="_blank" rel="nofollow noreferrer">更简单的解决方案</a>，那里隐藏着人类记忆的所有机制。即使在 <a href="http://link.zhihu.com/?target=http%3A//supermemo.com/" class=" wrap external" target="_blank" rel="nofollow noreferrer">supermemo.com</a> 上，我们也确保不会用屏幕上过多的数字吓到客户。这样，我们就可以在渴望简单的用户中更好地采用模型的指导功能。</p><h2>Robert Bjork's research</h2><h2>Robert Bjork 的研究</h2><p data-pid="N7DCVXLs">The concept of the two components of memory has parallels in prior research, esp. by <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Bjork" class=" wrap external" target="_blank" rel="nofollow noreferrer">Bjork</a>.</p><p data-pid="MFvC-ss9">记忆的两个组成成分的概念在以前的研究中有相似之处，特别是在 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Bjork" class=" wrap external" target="_blank" rel="nofollow noreferrer">Bjork</a> 的研究中。</p><p data-pid="v9buB9iq">In the 1940s, scientists investigated habit strength and response strength as independent components of behavior in rats. Those concepts were later reformulated in Bjork's disuse theory. Herbert Simon seems to have noticed the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Herbert_Simon_predicted_two_component_model_of_memory" class=" wrap external" target="_blank" rel="nofollow noreferrer">need for memory stability variable in his paper in 1966</a>. In 1969, <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Robert_Bjork" class=" wrap external" target="_blank" rel="nofollow noreferrer">Robert Bjork</a> formulated the <i>Strength Paradox</i>: a reverse relationship between the probability of recall and the memory effect of a review. Note that his is a restatement of the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Spacing_effect" class=" wrap external" target="_blank" rel="nofollow noreferrer">spacing effect</a> in terms of the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Two_component_model" class=" wrap external" target="_blank" rel="nofollow noreferrer">two component model</a>, which is just a short step away from formulating the distinction between the variables of memory. This led to <a href="http://link.zhihu.com/?target=https%3A//www.researchgate.net/profile/Robert_Bjork/publication/281322665_A_new_theory_of_disuse_and_an_old_theory_of_stimulus_fluctuation/links/58b6f20945851591c5d55e96/A-new-theory-of-disuse-and-an-old-theory-of-stimulus-fluctuation.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer">Bjork's New Theory of Disuse (1992)</a> that would distinguish between the storage strength and the retrieval strength. Those are close equivalents of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">retrievability</a> and <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">stability</a> with a slightly different interpretation of the mechanisms that underlie the distinction. Most strikingly, Bjork believes that when <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">retrievability</a> drops to zero, stable memories are still retained (in our model, stability becomes indeterminate). At the cellular level, Bjork might be right, at least for a while, but practise of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a> shows the power of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Complete_forgetting" class=" wrap external" target="_blank" rel="nofollow noreferrer">complete forgetting</a>, while, from the neural point of view, retaining memories in disuse would be highly inefficient independent of their <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">stability</a>. Last but not least, Bjork defines storage strength in terms of connectivity, which is very close to what I believe happens in good students: <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Coherence" class=" wrap external" target="_blank" rel="nofollow noreferrer">coherence</a> affects <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">stability</a>.</p><p data-pid="TgP28crg">在 20 世纪 40 年代，科学家研究了习惯强度和反应强度作为老鼠行为的独立组成部分。这些概念后来在 Bjork 的废用理论中重新表述。Herbert Simon 在 1966 年的论文中似乎注意到了记忆稳定性变量的必要性。1969 年，Robert Bjork 提出了强度悖论：回忆的概率和复习的记忆效果之间存在反向关系。请注意，他的是根据两分量模型对间隔效应的重述，这距离阐明记忆变量之间的区别只有一小步之遥。这引出了 Bjork 的新废用理论(1992)，该理论区分了储存强度和提取强度。这是与可提取性和稳定性相近的等价物，但对作为区别基础的机制的解释略有不同。最引人注目的是，Bjork 认为，当可提取性降至零时，仍然保留了稳定的记忆(在我们的模型中，稳定性变得不确定)。在细胞层面上，Bjork 可能是对的，至少在一段时间内是正确的，但实践 SuperMemo 显示了完全遗忘的力量，而从神经的角度来看，保留废弃的记忆将是非常低效的，独立于它们的稳定性。最后但并非最不重要的一点是，Bjork 用连接性来定义存储强度，这与我认为优秀学生身上会发生的事情非常接近：一致性会影响稳定性。</p><p data-pid="oLk-WXYV">Why aren't the two components of memory entering mainstream research yet? I claim that if human mind tends to be short-sighted, and we all are, by design, the mind of science can be truly strangulated by strenuous duties, publish or perish, battles for grants, hierarchies, conflict of interest, <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Peer_review" class=" wrap external" target="_blank" rel="nofollow noreferrer">peer review</a>, teaching obligations, and even the code of conduct. Memory researchers tend to live in a single dimension of "memory strength". In that dimension, they cannot truly appreciate true dynamics of molecular and neural processes that need to be investigated to crack the problem. Ironically, progress may come from those who tend to work in artificial intelligence or neural networks. Prodigious minds of <a href="http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Demis_Hassabis" class=" wrap external" target="_blank" rel="nofollow noreferrer">Demis Hassabis</a> or <a href="http://link.zhihu.com/?target=https%3A//scholar.google.de/citations%3Fuser%3DxVXueeQAAAAJ%26hl%3Den" class=" wrap external" target="_blank" rel="nofollow noreferrer">Andreas Knoblauch</a> come up with twin ideas by independent reasoning process, models, and simulations. Biologists will need to listen to the language of mathematics and/or computer science.</p><p data-pid="x-fC1SJl">为什么记忆的两个组成成分还没有进入主流研究？我认为，如果人类的思维倾向于短视，而我们都是故意的，那么科学的头脑可能真的会被繁重的职责、发表或灭亡、拨款之争、等级制度、利益冲突、同行评议、教学义务，甚至行为准则扼杀。记忆研究人员倾向于生活在“记忆强度”的单一维度中。在这个维度上，他们不能真正理解需要研究以解决问题的分子和神经过程的真实动力学。具有讽刺意味的是，进步可能来自那些倾向于从事人工智能或神经网络工作的人。Demis Hassabis 或 Andreas Knoblauch 的惊人头脑通过独立的推理过程、模型和模拟提出了两个想法。生物学家将需要聆听数学和计算机科学的语言。</p><h2>Two component model in Algorithm SM-17</h2><h2>算法 SM-17 中的双组分模型</h2><p data-pid="WcghpEKK">The <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Two_component_model_of_long-term_memory" class=" wrap external" target="_blank" rel="nofollow noreferrer">two component model of long-term memory</a> underlies <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Algorithm_SM-17" class=" wrap external" target="_blank" rel="nofollow noreferrer">Algorithm SM-17</a>. The success of Algorithm SM-17 is the ultimate practical proof for the correctness of the model.</p><p data-pid="kJAHuT1T"><a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Two_component_model_of_long-term_memory" class=" wrap external" target="_blank" rel="nofollow noreferrer">长期记忆的双组分模型</a>是 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Algorithm_SM-17" class=" wrap external" target="_blank" rel="nofollow noreferrer">Algorithm SM-17</a> 的基础。算法 SM-17 的成功，是该模型正确性的最终实践证明。</p><p data-pid="DbyVocwt">A graph of actual changes in the value of the two components of memory provides a conceptual visualization of the evolving memory status:</p><p data-pid="OpmPBn3H">记忆的两个组成成分的值的实际变化图提供了记忆状态演变的概念性可视化：</p><p><br></p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-a85197c6920ebb497461bfb3f49d8e8c_720w.jpg?source=3af55fa1" data-caption="" data-size="normal" data-rawwidth="800" data-rawheight="484" class="origin_image zh-lightbox-thumb" width="800" data-original="https://pic1.zhimg.com/v2-a85197c6920ebb497461bfb3f49d8e8c_r.jpg?source=3af55fa1"></figure><p><br></p><blockquote data-pid="UzVgR2qe"><b>Figure:</b> Changes in memory status over time for an exemplary piece of knowledge. The horizontal axis represents time spanning the entire repetition history. The top panel shows retrievability (tenth power,  <img src="https://www.zhihu.com/equation?tex=R%5E%7B10%7D" alt="R^{10}" eeimg="1"> , for easier analysis). Retrievability grid in gray is labelled by R=99%, R=98%, etc. The middle panel displays optimum intervals in navy. Repetition dates are marked by blue vertical lines and labelled in aqua. The end of the optimum interval where R crosses 90% line is marked by red vertical lines (only if intervals are longer than optimum intervals). The bottom panel visualizes stability (presented as <img src="https://www.zhihu.com/equation?tex=%5Cln%28S%29%2F%5Cln%28days%29" alt="\ln(S)/\ln(days)" eeimg="1"> for easier analysis). The graph shows that retrievability drops fast (exponentially) after early repetitions when stability is low, however, it only drops from 100% to 94% in long 10 years after the 7th review. All values are derived from an actual repetition history and the three component model of memory.<br><br> <b>图片：</b>记忆状态随着时间的推移而发生变化。横轴表示跨越整个重复历史的时间。顶部面板显示可提取性(十次幂，<img src="https://www.zhihu.com/equation?tex=R%5E%7B10%7D" alt="R^{10}" eeimg="1">，便于分析)。灰色网格的可提取性指标分别为 R=99%、R=98% 等。中间深蓝色的面板显示的最佳间隔。重复日期用蓝色竖线标记，并以浅蓝绿色标记。当 R 越过 90% 线时，最佳区间的末端用红色竖线表示(仅当区间大于最佳区间时)。下面板显示稳定性(以 <img src="https://www.zhihu.com/equation?tex=%5Cln%28S%29%2F%5Cln%28days%29" alt="\ln(S)/\ln(days)" eeimg="1"> 表示，便于分析)。从图中可以看出，当稳定性较低时，早期重复后的可提取性下降较快(指数级)，但在第 7 次复习后的 10 年时间里，可提取性仅从100%下降到 94%。所有的值都来自一个实际的重复历史和记忆的三组分模型。</blockquote><p data-pid="pR4egDzp">Due to the fact that a real-life application of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a> requires tackling learning material of varying difficulty, the third variable involved in the model is <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Item_difficulty" class=" wrap external" target="_blank" rel="nofollow noreferrer">item difficulty</a> (D). Some of the implications of item difficulty have also been discussed in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/History_of_spaced_repetition" class=" wrap external" target="_blank" rel="nofollow noreferrer">this article</a>. In particular, the impact of composite memories with subcomponents of different memory stability (S).</p><p data-pid="ba041A6B">因为一个现实生活中的应用 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a> 需要解决不同难度的学习材料，模型中所涉及的第三个变<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Item_difficulty" class=" wrap external" target="_blank" rel="nofollow noreferrer">项目难度</a> (D)。项目难度的一些影响也已经在这篇<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/History_of_spaced_repetition" class=" wrap external" target="_blank" rel="nofollow noreferrer">文章</a>被讨论。特别是具有不同子成分的复合记忆对记忆稳定性的影响。</p><p data-pid="HDqpyDnH">For the purpose of the new algorithm we have defined the three components of memory as follows:</p><p data-pid="dVEjAtuv">为了实现新的算法，我们定义了记忆的三个组成成分如下:</p><ul><li data-pid="EbOfcwB2"><a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Memory_stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">Memory stability</a> (S) is defined as the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Interval" class=" wrap external" target="_blank" rel="nofollow noreferrer">inter-repetition interval</a> that produces average <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Recall" class=" wrap external" target="_blank" rel="nofollow noreferrer">recall</a> probability of 0.9 at review time</li><li data-pid="6_OGCOG2"><a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Memory_retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">Memory retrievability</a> (R) is defined as the expected probability of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Recall" class=" wrap external" target="_blank" rel="nofollow noreferrer">recall</a> at any time on the assumption of the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Forgetting_curve" class=" wrap external" target="_blank" rel="nofollow noreferrer">negatively exponential forgetting</a> of homogenous learning material with the decay constant determined by <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Memory_stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">memory stability</a> (S)</li><li data-pid="gVWNmFb4"><a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Item_difficulty" class=" wrap external" target="_blank" rel="nofollow noreferrer">Item difficulty</a> (D) is defined as the maximum possible increase in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Memory_stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">memory stability</a> (S) at review mapped linearly into 0..1 interval with 0 standing for the easiest possible <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Item" class=" wrap external" target="_blank" rel="nofollow noreferrer">items</a>, and 1 standing for the highest difficulty in consideration in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a> (the cut off limit currently stands at stability increase 6x less than the maximum recorded)</li><li data-pid="Vl4W7CKu">记忆稳定性(S)被定义为在复习时产生 0.9 的平均回忆概率的重复间隔。</li><li data-pid="g2hxJOLO">记忆可提取性(R)被定义为在假设同质学习材料按负指数函数遗忘的前提下，任意时刻的期望回忆概率，衰减常数由记忆稳定性(S)决定</li><li data-pid="bBi3L776">项目难度(D)定义为复习时记忆稳定性(S)可能增加的最大值，线性映射到 0..1 区间，0 代表最容易的可能项目，1 代表 SuperMemo 中考虑的最高难度(目前的截止极限是稳定性增加 6 倍于记录的最大值)</li></ul><h2>Proof</h2><h2>证明</h2><p data-pid="cFPhtU8m">The actual proof from my <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Optimization_of_learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">Master's Thesis</a> follows. The language and models are 3 decades old and somewhat inept. However, the core idea still holds water to this day. For a better take on the proof, see <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/History_of_spaced_repetition_%28print%29%23Proof_by_Murakowski" class=" wrap external" target="_blank" rel="nofollow noreferrer">Murakowski proof</a>.</p><p data-pid="u5PuxbY-">下面是我硕士论文中的实际证明。这些语言和模型已经有 30 年的历史了，而且有些笨拙。然而，核心思想至今仍然站得住脚。要更好地理解证明，请参见 Murakowski 的证明。</p><blockquote data-pid="K3QVj1UL">Archive warning: <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Why_use_literal_archives%253F" class=" wrap external" target="_blank" rel="nofollow noreferrer">Why use literal archives?</a><br><br>档案警告：为什么要使用文字档案？<br> <br>This text was part of: "<i>Optimization of learning</i>" by <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Piotr_Wozniak" class=" wrap external" target="_blank" rel="nofollow noreferrer">Piotr Wozniak</a> (1990)<br> <br>这篇文章是：“优化学习” (1990) <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Piotr_Wozniak" class=" wrap external" target="_blank" rel="nofollow noreferrer">Piotr Wozniak</a> 的一部分<br> <br>10.4.2. Two variables of memory: stability and retrievability<br><br>10.4.2. 记忆的两个变量：稳定性和可提取性<br> <br>There is an important conclusion that comes directly from the SuperMemo theory that there are two, and not one, as it is commonly believed, independent variables that describe the conductivity of a synapse and memory in general. To illustrate the case, let us again consider the calpain model of synaptic memory. It is obvious from the model, that its authors assume that only one independent variable is necessary to describe the conductivity of a synapse. Influx of calcium, activity of calpain, degradation of fodrin and number of glutamate receptors are all examples of such a variable. Note that all the mentioned parameters are dependent, i.e. knowing one of them we could calculate all others; obviously only in the case if we were able to construct the relevant formulae. The dependence of the parameters is a direct consequence of causal links between all of them.<br> <br>有一个重要的结论直接来自于 SuperMemo 理论，那就是有两个变量，而不是像人们通常认为的一个描述突触电导率和一般记忆的变量。为了说明这种情况，让我们再次考虑突触记忆的 calpain 模型。从模型中可以明显看出，它的作者假设只需要一个自变量来描述突触的传导性。钙的内流、钙蛋白酶的活性、食物蛋白的降解和谷氨酸受体的数量都是这种变量的例子。请注意，所有提到的参数都是相关的，即知道其中一个参数，我们可以计算所有其他参数；显然，只有在能够构造相关公式的情况下才能计算。参数的依赖性是它们之间因果联系的直接结果。<br> <br>However, the process of optimal learning requires exactly two independent variables to describe the state of a synapse at a given moment:<br> <br>然而，最佳学习过程恰好需要两个独立变量来描述给定时刻突触的状态：</blockquote><ul><li data-pid="S62BWkoe"> A variable that plays the role of a clock that measures time between repetitions. Exemplary parameters that can be used here are:</li><li data-pid="7IoDH_KF"><img src="https://www.zhihu.com/equation?tex=T_e" alt="T_e" eeimg="1"> - time that has elapsed since the last repetition (it belongs to the range &lt;0,optimal-interval&gt;),</li><li data-pid="IBiB1QA0"><img src="https://www.zhihu.com/equation?tex=T_L" alt="T_L" eeimg="1"> - time that has to elapse before the next repetition will take place (<img src="https://www.zhihu.com/equation?tex=T_L" alt="T_L" eeimg="1">=optimal-interval-<img src="https://www.zhihu.com/equation?tex=T_e" alt="T_e" eeimg="1">),</li><li data-pid="IbXSjpxg"><img src="https://www.zhihu.com/equation?tex=P_f" alt="P_f" eeimg="1"> - probability that the synapse will lose the trace of memory during the day in question (it belongs to the range &lt;0,1&gt;).</li><li data-pid="-gYjrWPd">起时钟作用的变量，用于测量两次重复之间的时间。这里可以使用的示例性参数包括：</li><li data-pid="nUi2alK_"><img src="https://www.zhihu.com/equation?tex=+T_e++" alt=" T_e  " eeimg="1"> - 自上次重复以来已经过去的时间（属于区间 &lt;0，最佳间隔&gt;），</li><li data-pid="ef6giLc3"><img src="https://www.zhihu.com/equation?tex=T_L" alt="T_L" eeimg="1"> - 在下一次重复发生之前必须经过的时间（<img src="https://www.zhihu.com/equation?tex=T_L" alt="T_L" eeimg="1">= 最佳间隔 - <img src="https://www.zhihu.com/equation?tex=+T_e++" alt=" T_e  " eeimg="1">），</li><li data-pid="mRTjj6t6"><img src="https://www.zhihu.com/equation?tex=P_f" alt="P_f" eeimg="1"> - 突触在有问题的一天内丢失记忆痕迹的概率（属于区间 &lt;0，1&gt;）。</li></ul><p><br></p><ul><li data-pid="OdtnVBda"> A variable that measures the durability of memory. Exemplary parameters that can be used here are:</li><li data-pid="YFxMRb5B"> I(n+1) - optimal interval that should be used after the next repetition (I(n+1)=I(n)*C where C is a constant greater than three),</li><li data-pid="jqs97LoI">I(n) - current optimal interval,</li><li data-pid="d5HAMbd8">n - number of repetitions preceding the moment in question, etc.</li><li data-pid="FFor4vSP">衡量记忆持久性的变量。这里可以使用的示例性参数包括：</li><li data-pid="hm8-gRaT">I(n+1) - 在下一次重复之后应该使用的最佳间隔（I(n+1)=I(n)*C，其中 C 是大于 3 的常数），</li><li data-pid="qy81LkNw">I(n) - 现在的最佳间隔</li><li data-pid="ExP8SjsO">n - 在回答问题的时刻之前重复的次数等。</li></ul><p data-pid="kVzS8bT6">Let us now see if the above variables are necessary and sufficient to characterize the state of synapses in the process of time-optimal learning. To show that variables are independent, we will show that none of them can be calculated from the other. Let us notice that the I(n) parameter remains constant during a given inter-repetition interval, while the Te parameter changes from zero to I(n). This shows that there is no function f that satisfies the condition:</p><p data-pid="p-7pC1kr">现在让我们看看上述变量是否充分必要地描述突触在时间最优学习过程中的状态。为了说明变量是相互独立的，我们将说明它们之间没有一个可以相互计算。让我们注意到，在给定的重复间隔内，I(n) 参数保持不变，而  <img src="https://www.zhihu.com/equation?tex=T_e" alt="T_e" eeimg="1">  参数从 0 变为 I(n)。这表明没有满足条件的函数 f：</p><p data-pid="2cIwiWl4"><img src="https://www.zhihu.com/equation?tex=T_e%3Df%28I%28n%29%29" alt="T_e=f(I(n))" eeimg="1"> </p><p data-pid="GJv8XBid">On the other hand, at the moment of subsequent repetitions, Te always equals zero while I(n) has always a different, increasing value. Therefore there is no function g that satisfies the condition:</p><p data-pid="1tChDs2T">另一方面，在随后的重复时刻，<img src="https://www.zhihu.com/equation?tex=T_e" alt="T_e" eeimg="1"> 总是等于零，而 I(n) 总是有一个不同的、递增的值。因此，不存在满足条件的函数 g：</p><p data-pid="pvp9xW_8"><img src="https://www.zhihu.com/equation?tex=I%28n%29%3Dg%28T_e%29" alt="I(n)=g(T_e)" eeimg="1"></p><p data-pid="QYT0rNaI">Hence independence of I(n) and <img src="https://www.zhihu.com/equation?tex=T_e" alt="T_e" eeimg="1">.<br>因此 I(n) 和 <img src="https://www.zhihu.com/equation?tex=T_e" alt="T_e" eeimg="1"> 是独立的。</p><p data-pid="lyxZgj-d">To show that no other variables are necessary in the process of optimal learning, let us notice that at any given time we can compute all the moments of future repetitions using the following algorithm:</p><p data-pid="yBO1wTJu">为了说明在最优学习过程中不需要其他变量，让我们注意到，在任何给定时间，我们都可以使用下面的算法计算未来重复的所有时刻:</p><ol><li data-pid="K_6UFYS8">Let there elapse I(n) - <img src="https://www.zhihu.com/equation?tex=T_e" alt="T_e" eeimg="1">  days.</li><li data-pid="f3wH55IV">Let there be a repetition.</li><li data-pid="EbGnfRWv">Let <img src="https://www.zhihu.com/equation?tex=T_e" alt="T_e" eeimg="1"> be zero and I(n) increase C times.</li><li data-pid="PcnytTuA"> Go to 1.</li></ol><p><br></p><ol><li data-pid="K8j_b6z0"> 经过 I(n)- <img src="https://www.zhihu.com/equation?tex=T_e" alt="T_e" eeimg="1">  天</li><li data-pid="3KiWb-_V">让我们重复一遍。</li><li data-pid="kvBAw3rG">令 <img src="https://www.zhihu.com/equation?tex=T_e" alt="T_e" eeimg="1"> 为零，I(n) 增加 C 倍。</li><li data-pid="w3UGWiTE">回到 1。</li></ol><p data-pid="IAPakMVx">Note that the value of C is a constant characteristic for a given synapse and as such does not change in the process of learning. I will later use the term <b>retrievability</b> to refer to the first of the variables and the term <b>stability</b> to refer to the second one. To justify the choice of the first term, let me notice that we use to think that memories are strong after a learning task and that they fade away afterwards until they become no longer retrievable. This is retrievability that determines the moment at which memories are no longer there. It is also worth mentioning that retrievability was the variable that was tacitly assumed to be the only one needed to describe memory (as in the calpain model). The invisibility of the stability variable resulted from the fact that researchers concentrated their effort on a single learning task and observation of the follow-up changes in synapses, while the importance of stability can be visualized only in the process of repeating the same task many times. To conclude the analysis of memory variables, let us ask the standard question that must be posed in development of any biological model. What is the possible evolutionary advantage that arises from the existence of two variables of memory?</p><p data-pid="LI0Bimew">请注意，对于给定的突触，C 的值是一个恒定的特征，因此在学习过程中不会改变。稍后我将使用术语<b>可提取性</b>来表示第一个变量，使用术语<b>稳定性</b>来表示第二个变量。为了证明第一个学期的选择是合理的，让我注意到，我们过去常常认为记忆在学习任务之后是强烈的，然后它们就会消失，直到它们变得不再可以找回。这是决定记忆何时不再存在的可提取性。还值得一提的是，可提取性是被默认为唯一需要描述记忆的变量(就像在 calain 模型中一样)。稳定性变量的不可见性是因为研究人员将精力集中在单一的学习任务和观察突触的后续变化上，而稳定性的重要性只有在多次重复同一任务的过程中才能可视化。为了总结对记忆变量的分析，让我们提出在开发任何生物模型时必须提出的标准问题。记忆的两个变量的存在可能产生的进化优势是什么？</p><p data-pid="heCSnwDn">Retrievability and stability are both necessary to code for a process of learning that allows subsequent inter-repetition intervals to increase in length without forgetting. It can be easily demonstrated that such model of learning is best with respect to the survival rate of an individual if we acknowledge the fact that remembering without forgetting would in a short time clog up the memory system which is a finite one. If memory is to be forgetful it must have a means of retaining these traces that seem to be important for survival. Repetition as a memory strengthening factor is such a means. Let us now consider what is the most suitable timing of the repetitory process. If a given phenomenon is encountered for the n-th time, the probability that it will be encountered for the n+1 time increases and therefore a longer memory retention time seems advantageous. The exact function that describes the best repetitory process depends on the size of memory storage, number of possible phenomena encountered by an individual, and many others. However, the usefulness of increasing intervals required to sustain memory by repetitions is indisputable and so is the evolutionary value of retrievability and stability of memory. One can imagine many situations interfering with this simple picture of the development of memory in the course of evolution. For example, events that were associated with an intense stress should be remembered better. Indeed, this fact was proved in research on the influence of catecholamines on learning. Perhaps, using hormonal stimulation one could improve the performance of a student applying the SuperMemo method.</p><p data-pid="oPquf5Lz">可提取性和稳定性对于编写一个学习过程的代码都是必要的，该学习过程允许随后的重复间隔在不遗忘的情况下增加长度。很容易证明，就个人的存活率而言，这种学习模式是最好的，如果我们承认这样一个事实，即记住而不遗忘会在短时间内阻塞有限的记忆系统。如果记忆是健忘的，它必须有一种方法来保留这些似乎对生存很重要的痕迹。重复作为一种增强记忆的因素就是这样一种方法。现在让我们考虑一下重复过程的最合适时机是什么。如果一个给定的现象出现 n 次，那么它出现 n+1 次的可能性就会增加，因此更长的记忆保留时间似乎是有利的。描述最佳重复过程的确切函数取决于记忆存储的大小、个人可能遇到的现象的数量以及许多其他因素。然而，通过重复记忆来维持记忆所需要的时间间隔的增加，以及记忆的可提取性和稳定性的进化价值，都是无可争议的。我们可以想象，在进化过程中，许多情况都会干扰记忆发展的简单图景。例如，与强烈压力相关的事件应该被更好地记住。事实上，儿茶酚胺对学习影响的研究证实了这一点。也许，使用荷尔蒙刺激可以提高应用 SuperMemo 方法的学生的表现。</p><p data-pid="rmj98Lsa"><b>Interim summary</b></p><p data-pid="z892PDNB"><b>临时摘要</b></p><ol><li data-pid="qPRkLZOS">Existence of two independent variables necessary to describe the process of optimal learning was postulated. These variables were named <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">retrievability</a> and <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">stability</a> of memory</li><li data-pid="Oom-tlIE">Retrievability of memory reflects the lapse of time between repetitions and indicates to what extent memory traces can successfully be used in the process of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Recall" class=" wrap external" target="_blank" rel="nofollow noreferrer">recall</a></li><li data-pid="E0cOxQuG">Stability of memory reflects the history of repetitions in the process of learning and increases with each stimulation of the synapse. It determines the length of the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Optimum_interval" class=" wrap external" target="_blank" rel="nofollow noreferrer">optimum inter-repetition interval</a></li></ol><p><br></p><ol><li data-pid="HVth4cjd">假设存在描述最优学习过程所需的两个自变量。这些变量被命名为记忆的可提取性和稳定性</li><li data-pid="2dlp9SVX">记忆的可提取性反映了重复之间的时间间隔，并指示记忆痕迹在回忆过程中能在多大程度上被成功利用</li><li data-pid="8ZftlKse">记忆的稳定性反映了学习过程中重复的历史，并且随着突触的每一次刺激而增加。它确定最佳重复间隔的长度</li></ol><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-670a3760d1ba148495419a7bd46514df_720w.jpg?source=3af55fa1" data-caption="" data-size="normal" data-rawwidth="426" data-rawheight="600" class="origin_image zh-lightbox-thumb" width="426" data-original="https://pic2.zhimg.com/v2-670a3760d1ba148495419a7bd46514df_r.jpg?source=3af55fa1"></figure><blockquote data-pid="Ifo_USF1"><b>Figure:</b> In my Master's Thesis titled "Optimization of learning" (1990), I presented some hypothetical concepts that might underly the process of optimal learning based on spaced repetition. (A) Molecular phenomena (B) Quantitative changes in the synapse. Those ideas are a bit dated today, but the serrated curves representing memory retrievability came to be widely known in popular publications on spaced repetition. They are usually wrongly attributed to Hermann Ebbinghaus<br><br><b>图：</b>在我的硕士论文“优化学习”(1990)中，我提出了一些假设概念，这些概念可能是基于间隔重复的优化学习过程的基础。(A)分子现象 (B)突触的数量变化。这些观点在今天看来有些过时，但代表记忆可提取性的锯齿形曲线在有关间隔重复的流行出版物中得到了广泛的认识。它们通常被错误地归因于赫尔曼•艾宾浩斯 </blockquote><h2>Proof by Murakowski</h2><h2>Murakowski 的证明</h2><p data-pid="kbnss88Q">Here is an improved proof by <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Janusz_Murakowski" class=" wrap external" target="_blank" rel="nofollow noreferrer">Murakowski</a>:</p><p data-pid="MM-Ya8Pk">这里有一份由 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Janusz_Murakowski" class=" wrap external" target="_blank" rel="nofollow noreferrer">Murakowski</a> 提交的证明：</p><blockquote data-pid="g5Gc2J-E"> It has been found in earlier research that the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Spaced_repetition" class=" wrap external" target="_blank" rel="nofollow noreferrer">optimum spacing of repetitions</a> in paired-associate learning, understood as the spacing which takes a minimum number of repetitions to indefinitely maintain a constant level of knowledge retention (e.g. 95%), can roughly be expressed using the following formulae (<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Optimization_of_repetition_spacing_in_the_practice_of_learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">Wozniak and Gorzelanczyk 1994</a>):<br><br>在早期的研究中已经发现，配对联想学习中的最佳重复间隔，理解为需要最小重复次数才能无限期地保持恒定的知识保持水平(例如95%)的间隔，可以用以下公式大致表示(<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Optimization_of_repetition_spacing_in_the_practice_of_learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">Wozniak 和 Gorzelanczyk，1994</a>)：</blockquote><ul><li data-pid="fw4C5ePf">(1)  <img src="https://www.zhihu.com/equation?tex=I_1%3DC_1" alt="I_1=C_1" eeimg="1"> </li><li data-pid="-DCBJO8K">(2)  <img src="https://www.zhihu.com/equation?tex=I_i%3DI_%7Bi-1%7D%2AC_2" alt="I_i=I_{i-1}*C_2" eeimg="1"> </li></ul><p data-pid="Ntr8m5XM"> where:<br> 这里：</p><ul><li data-pid="CqFP3Ppn"><img src="https://www.zhihu.com/equation?tex=I_i" alt="I_i" eeimg="1">  - <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Optimum_interval" class=" wrap external" target="_blank" rel="nofollow noreferrer">inter-repetition interval</a> after the i-th repetition</li><li data-pid="F0HstoMY"><img src="https://www.zhihu.com/equation?tex=C_1" alt="C_1" eeimg="1">  - length of the first interval (dependent on the chosen knowledge <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retention" class=" wrap external" target="_blank" rel="nofollow noreferrer">retention</a>, and usually equal to several days)</li><li data-pid="JLdPVZ4H"><img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1">  - constant that denotes the increase of inter-repetition intervals in subsequent repetitions (dependent on the chosen knowledge retention, and the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Difficulty" class=" wrap external" target="_blank" rel="nofollow noreferrer">difficulty</a> of the remembered item)</li><li data-pid="ekJmecEC"><img src="https://www.zhihu.com/equation?tex=I_i" alt="I_i" eeimg="1">  - 第 i 次重复后的重复间隔。</li><li data-pid="m5J9B6Bw"><img src="https://www.zhihu.com/equation?tex=C_1" alt="C_1" eeimg="1"> - 第一个间隔的长度(取决于所选的知识保留，通常等于几天)。</li><li data-pid="zFAqtNIm"><img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> - 常数，表示后续重复中重复间隔的增加(取决于所选的知识记忆和记忆项目的难度)</li></ul><p data-pid="lToZciad">The above formulae have been found for human subjects using computer optimization procedures employed to supervise the process of self-paced learning of word-pairs using the active recall drop-out technique. [...]</p><p data-pid="NF4DtmGC">上述公式是使用计算机优化过程为人类受试者找到的，该计算机优化过程使用主动回忆丢弃技术来监督单词对的自定步速学习过程。[...]</p><p data-pid="574Opg4s">As it will be shown below, the widely investigated strength of memory (or synaptic potentiation) does not suffice to account for the regular pattern of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Spaced_repetition" class=" wrap external" target="_blank" rel="nofollow noreferrer">optimum repetition spacing</a>: [...]</p><p data-pid="mzeSkVHP">如下所示，被广泛研究的记忆强度(或突触增强)不足以解释最佳重复间隔的规律：<i>[...]</i></p><ol><li data-pid="37OC2Whm"> We want to determine the set of (molecular) variables involved in storing memory traces that will suffice to account for the optimum spacing of repetitions. Let us, initially, assume two correlates of these variables in learning that is subject to optimum spacing as expressed by Eqns. (1) and (2):</li><ol><li data-pid="w0hODuNS"><i>r</i> - time which remains from the present moment until the end of the current optimum interval (optimum interval is the interval at the end of which the retention drops to the previously defined level, e.g. 95%)</li><li data-pid="C9nD6RLG"><i>s</i> - length of the current optimum interval.</li></ol><li data-pid="i5aapnHz"> Just at the onset of the i-th repetition,  <img src="https://www.zhihu.com/equation?tex=r%3D0" alt="r=0" eeimg="1"> , while <img src="https://www.zhihu.com/equation?tex=s_i%3Es_%7Bi-1%7D%3E0" alt="s_i&gt;s_{i-1}&gt;0" eeimg="1"> ( <img src="https://www.zhihu.com/equation?tex=s_i" alt="s_i" eeimg="1"> denotes <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1"> right at the onset of the i-th repetition). This indicates that there is no function  <img src="https://www.zhihu.com/equation?tex=g_1" alt="g_1" eeimg="1">  such that  <img src="https://www.zhihu.com/equation?tex=s%3Dg_1%28r%29" alt="s=g_1(r)" eeimg="1"> , i.e.  <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1">  cannot be a function of  <img src="https://www.zhihu.com/equation?tex=r" alt="r" eeimg="1">  only.</li><li data-pid="F930bkx2"> During the inter-repetition interval, <img src="https://www.zhihu.com/equation?tex=r%28t_1%29%3C%3Er%28t_2%29" alt="r(t_1)&lt;&gt;r(t_2)" eeimg="1"> if  <img src="https://www.zhihu.com/equation?tex=t_1%3C%3Et_2" alt="t_1&lt;&gt;t_2" eeimg="1">  ( <img src="https://www.zhihu.com/equation?tex=t" alt="t" eeimg="1">  denotes time and  <img src="https://www.zhihu.com/equation?tex=r%28t%29" alt="r(t)" eeimg="1">  denotes  <img src="https://www.zhihu.com/equation?tex=r" alt="r" eeimg="1">  at the moment <img src="https://www.zhihu.com/equation?tex=t" alt="t" eeimg="1"> ). On the other hand,  <img src="https://www.zhihu.com/equation?tex=s%28t_1%29%3Ds%28t_2%29" alt="s(t_1)=s(t_2)" eeimg="1">  ( <img src="https://www.zhihu.com/equation?tex=s%28t%29" alt="s(t)" eeimg="1"> denotes  <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1">  at the moment <img src="https://www.zhihu.com/equation?tex=t" alt="t" eeimg="1"> ). This shows that there is no function  <img src="https://www.zhihu.com/equation?tex=g_2" alt="g_2" eeimg="1">  such that  <img src="https://www.zhihu.com/equation?tex=r%3Dg_2%28s%29" alt="r=g_2(s)" eeimg="1"> , or we would have:  <img src="https://www.zhihu.com/equation?tex=r%28t_1%29%3Dg_2%28s%28t_1%29%29%3Dg_2%28s%28t_2%29%29%3Dr%28t_2%29" alt="r(t_1)=g_2(s(t_1))=g_2(s(t_2))=r(t_2)" eeimg="1"> , which leads to a contradiction.  <img src="https://www.zhihu.com/equation?tex=r" alt="r" eeimg="1">  cannot be a function of <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1"> only.</li><li data-pid="coNzSeyj"> In Steps 2 and 3 we have shown that <img src="https://www.zhihu.com/equation?tex=r" alt="r" eeimg="1"> and <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1"> are independent, as there are no functions <img src="https://www.zhihu.com/equation?tex=g_1" alt="g_1" eeimg="1"> and  <img src="https://www.zhihu.com/equation?tex=g_2" alt="g_2" eeimg="1">  such that  <img src="https://www.zhihu.com/equation?tex=s%3Dg_1%28r%29" alt="s=g_1(r)" eeimg="1">  or  <img src="https://www.zhihu.com/equation?tex=r%3Dg_2%28s%29" alt="r=g_2(s)" eeimg="1"> . This obviously does not mean that there exists no parameter  <img src="https://www.zhihu.com/equation?tex=x" alt="x" eeimg="1">  and functions  <img src="https://www.zhihu.com/equation?tex=y_s" alt="y_s" eeimg="1">  and  <img src="https://www.zhihu.com/equation?tex=y_r" alt="y_r" eeimg="1">  such that <img src="https://www.zhihu.com/equation?tex=s%3Dy_s%28x%29" alt="s=y_s(x)" eeimg="1"> and  <img src="https://www.zhihu.com/equation?tex=r%3Dy_r%28x%29" alt="r=y_r(x)" eeimg="1"> .</li><li data-pid="TTJLWHeS"> It can be shown that <img src="https://www.zhihu.com/equation?tex=r" alt="r" eeimg="1"> and <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1"> suffice to compute the optimum spacing of repetitions (cf. Eqns. (1) and (2)). Let us first assume that the two following functions  <img src="https://www.zhihu.com/equation?tex=f_r" alt="f_r" eeimg="1">  and  <img src="https://www.zhihu.com/equation?tex=f_s" alt="f_s" eeimg="1">  are known in the system involved in memory storage:  <img src="https://www.zhihu.com/equation?tex=r_i+%3Df_r+%28+s_i+%29" alt="r_i =f_r ( s_i )" eeimg="1">  and  <img src="https://www.zhihu.com/equation?tex=s_i+%3Df_s+%28+s_%7Bi-1%7D+%29" alt="s_i =f_s ( s_{i-1} )" eeimg="1"> . In our case, these functions have a trivial form <img src="https://www.zhihu.com/equation?tex=f_r+%3A+r_i+%3D+s_i" alt="f_r : r_i = s_i" eeimg="1"> and  <img src="https://www.zhihu.com/equation?tex=f_s+%3A+s_i+%3D+s_%7Bi-1%7D+%2AC_2" alt="f_s : s_i = s_{i-1} *C_2" eeimg="1">  (where <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> is the constant from Eqn. (2)). In such a case, the variables <img src="https://www.zhihu.com/equation?tex=r" alt="r" eeimg="1"> and <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1"> are sufficient to represent memory at any moment  <img src="https://www.zhihu.com/equation?tex=t" alt="t" eeimg="1">  in optimum spacing of repetitions. Here is a repetition spacing algorithm which shows this to be true:</li><ol><li data-pid="Wikb4Mcr"> assume that the variables  <img src="https://www.zhihu.com/equation?tex=r_i" alt="r_i" eeimg="1">  and  <img src="https://www.zhihu.com/equation?tex=s_i" alt="s_i" eeimg="1">  describe the state of memory after the i-th repetition</li><li data-pid="wipWEkDB">let there elapse  <img src="https://www.zhihu.com/equation?tex=r_i" alt="r_i" eeimg="1">  time</li><li data-pid="5Z8LNjfi">let there be a repetition</li><li data-pid="GHXwx-WJ">let the function  <img src="https://www.zhihu.com/equation?tex=f_s" alt="f_s" eeimg="1">  be used to compute the new value of  <img src="https://www.zhihu.com/equation?tex=s_%7Bi%2B1%7D" alt="s_{i+1}" eeimg="1">  from  <img src="https://www.zhihu.com/equation?tex=s_i" alt="s_i" eeimg="1"> </li><li data-pid="4OhRJ5q2">let the function  <img src="https://www.zhihu.com/equation?tex=f_r" alt="f_r" eeimg="1">  be used to compute the new value of  <img src="https://www.zhihu.com/equation?tex=r_%7Bi%2B1%7D" alt="r_{i+1}" eeimg="1">  from <img src="https://www.zhihu.com/equation?tex=s_%7Bi%2B1%7D" alt="s_{i+1}" eeimg="1"> </li><li data-pid="_Xwkqj8-"><img src="https://www.zhihu.com/equation?tex=i%3A%3Di%2B1" alt="i:=i+1" eeimg="1"> </li><li data-pid="L7vmY-Ev"> goto 2</li></ol></ol><p><br></p><ol><li data-pid="g8hV3UL_"> 我们想要确定存储记忆痕迹所涉及的(分子)变量集，这些变量足以说明最佳重复间隔。首先，让我们假设这些变量在学习中的两个相关性，它们受制于公式(1)及(2)所表示的最佳间距：</li><ol><li data-pid="lxffzAGY"><i>r</i> - 从当前时刻到当前最佳间隔结束的剩余时间(最佳间隔是指保留率在结束时降至先前定义的水平的间隔，例如 95%)。</li><li data-pid="OY9Z_gE_"><i>s</i> - 当前最佳间隔的长度。</li></ol><li data-pid="sP_Cu7T_"> 仅在第 i 次重复开始时， <img src="https://www.zhihu.com/equation?tex=r%3D0" alt="r=0" eeimg="1"> ，而  <img src="https://www.zhihu.com/equation?tex=s_i%3Es_%7Bi-1%7D%3E0" alt="s_i&gt;s_{i-1}&gt;0" eeimg="1">  ( <img src="https://www.zhihu.com/equation?tex=s_i" alt="s_i" eeimg="1"> 表示正好在第 i 次重复开始时的 <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1">)。这表明没有函数  <img src="https://www.zhihu.com/equation?tex=g_1" alt="g_1" eeimg="1">  使得 <img src="https://www.zhihu.com/equation?tex=s%3Dg_1%28R%29" alt="s=g_1(R)" eeimg="1"> ，即 <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1"> 不能只是 <img src="https://www.zhihu.com/equation?tex=r" alt="r" eeimg="1"> 的函数。</li><li data-pid="kLe-EWkG"> 在重复间隔期间， <img src="https://www.zhihu.com/equation?tex=r%28t_1%29%3C%3Er%28t_2%29" alt="r(t_1)&lt;&gt;r(t_2)" eeimg="1"> 当 <img src="https://www.zhihu.com/equation?tex=r%28t_1%29%3C%3Er%28t_2%29" alt="r(t_1)&lt;&gt;r(t_2)" eeimg="1"> ( <img src="https://www.zhihu.com/equation?tex=t" alt="t" eeimg="1"> 表示时间， <img src="https://www.zhihu.com/equation?tex=r%28t%29" alt="r(t)" eeimg="1">  表示时刻 <img src="https://www.zhihu.com/equation?tex=t" alt="t" eeimg="1">)。另一方面， <img src="https://www.zhihu.com/equation?tex=s%28t_1%29%3Ds%28t_2%29" alt="s(t_1)=s(t_2)" eeimg="1">  ( <img src="https://www.zhihu.com/equation?tex=s%28t%29" alt="s(t)" eeimg="1"> 表示此时的 <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1">)。这表明不存在函数  <img src="https://www.zhihu.com/equation?tex=g_2" alt="g_2" eeimg="1">  使得  <img src="https://www.zhihu.com/equation?tex=r%3Dg_2%28s%29" alt="r=g_2(s)" eeimg="1"> ，否则我们将有： <img src="https://www.zhihu.com/equation?tex=r%28t_1%29%3Dg_2%28s%28t_1%29%29%3Dg_2%28s%28t_2%29%29%3Dr%28t_2%29" alt="r(t_1)=g_2(s(t_1))=g_2(s(t_2))=r(t_2)" eeimg="1"> ，这导致了一个矛盾。<img src="https://www.zhihu.com/equation?tex=r" alt="r" eeimg="1"> 不能仅是 <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1"> 的函数。</li><li data-pid="gwJR4KcG"> 在步骤 2 和 3 中，我们已经证明了 <img src="https://www.zhihu.com/equation?tex=r" alt="r" eeimg="1"> 和 <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1"> 是独立的，因为没有函数 <img src="https://www.zhihu.com/equation?tex=g_1" alt="g_1" eeimg="1"> 和  <img src="https://www.zhihu.com/equation?tex=g_2" alt="g_2" eeimg="1">  使得 <img src="https://www.zhihu.com/equation?tex=r%3Dg_2%28s%29" alt="r=g_2(s)" eeimg="1"> 或 <img src="https://www.zhihu.com/equation?tex=r%3Dg_2%28s%29" alt="r=g_2(s)" eeimg="1"> 。这显然不意味着没有参数  <img src="https://www.zhihu.com/equation?tex=x" alt="x" eeimg="1">  和函数 <img src="https://www.zhihu.com/equation?tex=y_s" alt="y_s" eeimg="1"> 和  <img src="https://www.zhihu.com/equation?tex=y_r" alt="y_r" eeimg="1">  使得 <img src="https://www.zhihu.com/equation?tex=s%3Dy_s%28x%29" alt="s=y_s(x)" eeimg="1"> 和 <img src="https://www.zhihu.com/equation?tex=r%3Dy_r%28x%29" alt="r=y_r(x)" eeimg="1"> 。 </li><li data-pid="KVZ4hTPX"> 可以看出，<img src="https://www.zhihu.com/equation?tex=r" alt="r" eeimg="1"> 和 <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1"> 足以计算最佳重复间隔(参见方程式(1)及(2))。让我们首先假设以下两个函数 <img src="https://www.zhihu.com/equation?tex=f_r" alt="f_r" eeimg="1"> 和 <img src="https://www.zhihu.com/equation?tex=f_s" alt="f_s" eeimg="1"> 在 s 涉及记忆存储i的系统中是已知的： <img src="https://www.zhihu.com/equation?tex=r_i%3Df_r%28s_i%29" alt="r_i=f_r(s_i)" eeimg="1">  和  <img src="https://www.zhihu.com/equation?tex=s_i%3Df_s%28s_%7Bi-1%7D%29" alt="s_i=f_s(s_{i-1})" eeimg="1"> 。在我们的例子中，这些函数具有平凡的形式 <img src="https://www.zhihu.com/equation?tex=f_r%EF%BC%9Ar_i%3Ds_i" alt="f_r：r_i=s_i" eeimg="1"> 和 <img src="https://www.zhihu.com/equation?tex=f_s%EF%BC%9As_i%3Ds_%7Bi-1%7D%2AC_2" alt="f_s：s_i=s_{i-1}*C_2" eeimg="1"> (其中 <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 是公式(2)中的常量。在这种情况下，变量 <img src="https://www.zhihu.com/equation?tex=r" alt="r" eeimg="1"> 和 <img src="https://www.zhihu.com/equation?tex=s" alt="s" eeimg="1"> 足以在任何时刻 <img src="https://www.zhihu.com/equation?tex=t" alt="t" eeimg="1"> 以最佳重复间隔表示记忆。以下是重复间隔算法，它表明这是正确的：</li><ol><li data-pid="rs_ykNX0"> 假设变量  <img src="https://www.zhihu.com/equation?tex=r_i" alt="r_i" eeimg="1">  和  <img src="https://www.zhihu.com/equation?tex=s_i" alt="s_i" eeimg="1">  描述第 i 次重复后的记忆状态</li><li data-pid="yoOIXm3Q">时间流逝  <img src="https://www.zhihu.com/equation?tex=r_i" alt="r_i" eeimg="1"> </li><li data-pid="E3E_3jlc">开始重复</li><li data-pid="xVn-mmrA">让函数  <img src="https://www.zhihu.com/equation?tex=f_s" alt="f_s" eeimg="1">  用于从  <img src="https://www.zhihu.com/equation?tex=s_i" alt="s_i" eeimg="1">  计算新值  <img src="https://www.zhihu.com/equation?tex=s_%7Bi%2B1%7D" alt="s_{i+1}" eeimg="1"> </li><li data-pid="Y6sd6YJt">让函数  <img src="https://www.zhihu.com/equation?tex=f_r" alt="f_r" eeimg="1">  用于从  <img src="https://www.zhihu.com/equation?tex=s_%7Bi%2B1%7D" alt="s_{i+1}" eeimg="1">  计算新值  <img src="https://www.zhihu.com/equation?tex=r_%7Bi%2B1%7D" alt="r_{i+1}" eeimg="1"> </li><li data-pid="dREriOhq"><img src="https://www.zhihu.com/equation?tex=i%3A%3Di%2B1" alt="i:=i+1" eeimg="1"> </li><li data-pid="fuWK9Xlb">回到 2</li></ol></ol><p data-pid="HjWZqiq7">The above reasoning shows that variables <i>r</i> and <i>s</i> form a sufficient set of independent variables needed to compute the optimum spacing of repetitions. Obviously, using a set of transformation functions of the form <i>r</i>''=Tr(<i>r</i>') and <i>s</i>''=Ts(<i>s</i>'), one can conceive an infinite family of variable pairs <i>r</i>-<i>s</i> that could describe the status of the memory system. A difficult choice remains to choose such a pair <i>r</i>-<i>s</i> that will most conveniently correspond with molecular phenomena occurring at the level of the synapse.</p><p data-pid="vry-vnUK">上述推理表明，变量 r 和 s 形成了计算最佳重复间隔所需的足够的自变量集合。显然，使用形式为 r''=Tr(r') 和 s''=Ts(s') 的一组变换函数，可以设想可以描述记忆系统状态的变量对 r-s 的无穷族。一个困难的选择仍然是选择这样一对 r-s，它将最方便地与突触水平上发生的分子现象相对应。</p><p data-pid="c2cHHVap">The following terminology and interpretation is proposed by the authors in a memory system involving the existence of the <i>r</i>-<i>s</i> pair of variables: the variable R, retrievability, determines the probability with which a given memory trace can be invoked at a given moment, while the variable S, stability of memory, determines the rate of decline of retrievability as a result of forgetting, and consequently the length of inter-repetition intervals in the optimum spacing of repetitions.</p><p data-pid="USshzSXF">在涉及 r-s 对变量的记忆系统中，作者提出了以下术语和解释：变量 R(可提取性)确定在给定时刻可以调用给定记忆轨迹的概率，而变量 S(记忆的稳定性)确定由于遗忘而导致的可提取性下降的速率，从而确定最佳重复间隔中的重复间隔的长度。</p><p data-pid="5av73oiQ">Assuming the negatively exponential decrease of retrievability, and the interpretation of stability as a reciprocal of the retrievability decay constant, we might conveniently represent the relationship between R and S using the following formula (t denotes time):</p><p data-pid="aKfN85Fn">假设可提取性以负指数下降，并将稳定性解释为可提取性衰减常数的倒数，我们可以方便地使用以下公式(t 表示时间)来表示 R 和 S 之间的关系：</p><p data-pid="fwsAdv5i">(3)  <img src="https://www.zhihu.com/equation?tex=R%3De%5E%7B-t%2FS%7D" alt="R=e^{-t/S}" eeimg="1"> </p><p data-pid="w56s-vPM">The transformation functions from the pair <i>r</i>-<i>s</i> used in Steps 1-5 of the reasoning, to the proposed interpretation R-S will look as follows (assuming the definition of the optimum inter-repetition interval as the interval that produces retention of knowledge K=0.95):</p><p data-pid="50i23Hwe">从推理的步骤 1-5 中使用的 r-s 对到建议的解释 R-S 的变换函数如下(假设最佳重复间隔的定义为产生知识保持的间隔 K=0.95)：</p><p data-pid="kg1H1ObG">(4)  <img src="https://www.zhihu.com/equation?tex=S%3D-s%2F%5Cln%28K%29" alt="S=-s/\ln(K)" eeimg="1"> <br>(5)  <img src="https://www.zhihu.com/equation?tex=R%3De%5E%7B-%28s-r%29%2FS%7D" alt="R=e^{-(s-r)/S}" eeimg="1"> </p><p data-pid="hbtlDcQ9">The relationship between the stability after the i-th repetition ( <img src="https://www.zhihu.com/equation?tex=S_i" alt="S_i" eeimg="1"> ) and the constants  <img src="https://www.zhihu.com/equation?tex=C_1" alt="C_1" eeimg="1">  and  <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1">  determining the optimum spacing of repetitions as defined by Eqns. (1) and (2) can therefore be written as:</p><p data-pid="SuW31iW0">因此，第 i 次重复后的稳定性( <img src="https://www.zhihu.com/equation?tex=S_i" alt="S_i" eeimg="1"> )与确定由公式(1)和(2)定义的最佳重复间隔的常数  <img src="https://www.zhihu.com/equation?tex=C_1" alt="C_1" eeimg="1">  和 <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 之间的关系可以写成：</p><p data-pid="zdjtQU8O">(6) <img src="https://www.zhihu.com/equation?tex=S_i%3D-%28C_1%2AC_2%5E%7Bi-1%7D%29%2F%5Cln%28K%29" alt="S_i=-(C_1*C_2^{i-1})/\ln(K)" eeimg="1"> </p><p data-pid="LIHPwCwE">and finally, retrievability in the optimum spacing of repetitions can be expressed as:</p><p data-pid="X_Y-AXNr">最后，在最佳重复间隔中的可提取性可以表示为：</p><p data-pid="IqdKSjIG">(7)  <img src="https://www.zhihu.com/equation?tex=R_i%28t%29%3D%5Cexp%5E%7B%28t%5Cln%28K%29%2F%28C_1C_2%5E%7Bi-1%7D%29%29%7D" alt="R_i(t)=\exp^{(t\ln(K)/(C_1C_2^{i-1}))}" eeimg="1"> </p><p data-pid="N0Wi4hW7">where:</p><p data-pid="_oZ91BMl">这里：</p><ul><li data-pid="uZGx9SyU">i - number of the repetition in question</li><li data-pid="TTjmJEXf">t - time since the i-th repetition</li><li data-pid="nK2r76NY"><img src="https://www.zhihu.com/equation?tex=R_i%28t%29" alt="R_i(t)" eeimg="1"> - retrievability after the time t passing since the i-th repetition in optimum spacing of repetitions</li><li data-pid="5U92CKxH"><img src="https://www.zhihu.com/equation?tex=C_1" alt="C_1" eeimg="1">  and <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> - constants from Eqns. (1) and (2)</li><li data-pid="xCSk9nut">K - retention of knowledge equal to 0.95 (it is important to notice that the relationship expressed by Eqn. (7) may not be true for retention higher than 0.95 due to the spacing effect resulting from shorter intervals)</li><li data-pid="T-j4ZZ08">i - 问题的重复次数</li><li data-pid="V_nS9HdA">t - 从第 i 次重复开始的时间</li><li data-pid="3BlAYwHd"><img src="https://www.zhihu.com/equation?tex=R_i%28t%29" alt="R_i(t)" eeimg="1"> - 自第 i 次重复以来经过时间  t 之后的最佳重复间隔的可提取性</li><li data-pid="eoRjCZIS"><img src="https://www.zhihu.com/equation?tex=C_1" alt="C_1" eeimg="1"> 和 <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> - 来自公式(1)和(2)的常量。</li><li data-pid="3U5yAaP2">K-知识保留量等于 0.95(重要的 是要注意由公式(7)表示的关系。由于较短间隔产生的间距效应，保留率高于 0.95 的情况可能不成立)</li></ul><h2>Two components of memory in SuperMemo</h2><h2>SuperMemo 中的记忆的两个组成成分</h2><p data-pid="dIbIuBLo"><a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a> has always been based on the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Two_component_model_of_memory" class=" wrap external" target="_blank" rel="nofollow noreferrer">two component model of memory</a>, which emerged in an increasingly explicit form over the last three decades. The constant <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> in Eqn. (2) in Murakowski proof above represents <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability_increase" class=" wrap external" target="_blank" rel="nofollow noreferrer">stability increase</a>. In 2018, stability increase is represented in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a> as matrix <i>SInc[]</i>. <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> says how much inter-repetition intervals should increase in learning to meet the criteria of admissible level of forgetting. In reality, <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> is not a constant. It depends on a number of factors. Of these, the most important are:</p><p data-pid="5Jt4sE3m">SuperMemo 一直基于记忆的双组分模型，该模型在过去 30 年中以越来越明显的形式出现。公式(2) 中的常数 <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 在 Murakowski 的上述证明中表示稳定性增加。2018 年，稳定性增加在 SuperMemo 中表示为矩阵 SInc[]。<img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 说明在学习中应该增加多少重复间隔，才能达到可接受的遗忘水平标准。实际上，<img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 不是常数。这取决于许多因素。其中，最重要的是：</p><ul><li data-pid="HN3HTq1z">item difficulty (D)(see: <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Complexity" class=" wrap external" target="_blank" rel="nofollow noreferrer">complexity</a>): the more difficult the remembered piece of information the smaller the <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> (i.e. difficult material must be reviewed more often)</li><li data-pid="S539j_xj"><a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Memory_stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">memory stability</a> (S): the more lasting/durable the memory, the smaller the <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1">value</li><li data-pid="_K7PPA7f"> probability of recall (<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">retrievability</a>)(R): the lower the probability of recall, the higher the <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> value (i.e. due to the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Spacing_effect" class=" wrap external" target="_blank" rel="nofollow noreferrer">spacing effect</a>, items are remembered better if reviewed with delay)<br> </li><li data-pid="FGwZ8yAO"> 项目难度(D)(参见：复杂性)：记住的信息越难，<img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 越小(即必须更频繁地复习困难的材料)</li><li data-pid="e3cf2SNH"><a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Memory_stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">记忆稳定性</a> (S)：记忆越持久，<img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 值越小</li><li data-pid="TL7WlBTl">回忆概率(<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">可提取性</a>)(R)：回忆的概率越低，<img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 值越高(即由于<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Spacing_effect" class=" wrap external" target="_blank" rel="nofollow noreferrer">间隔效应</a>，如果延迟查看项目，可以更好地记住它们)</li></ul><p data-pid="3YiNWpwm">Due to those multiple dependencies, the precise value of <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> is not easily predictable. SuperMemo solves this and similar optimization problems by using multidimensional matrices to represent multi-argument functions and adjusting the value of those matrices on the basis of measurements made during an actual learning process. The initial values of those matrices are derived from a theoretical model or from previous measurements. The actually used values will, over time, differ slightly from those theoretically predicted or those derived from data of previous students.</p><p data-pid="x7qQpAmm">由于这些多重依赖关系，<img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 的精确值不容易预测。SuperMemo 通过使用多维矩阵来表示多自变量函数，并根据在实际学习过程中所做的测量来调整这些矩阵的值，从而解决了这个和类似的优化问题。这些矩阵的初始值是从理论模型或从先前的测量中导出的。随着时间的推移，实际使用的值将与理论预测的值或根据以前学生的数据得出的值略有不同。</p><p data-pid="Fpe_iXic">For example, if the value of <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> for a given item of a given difficulty with a given memory status produces an inter-repetition interval that is longer than desired (i.e. producing lower than desired level of recall), the value of <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> is reduced accordingly.</p><p data-pid="FP-WKLKh">例如，如果给定难度、给定记忆状态的给定项的 <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 值产生的重复间隔比期望的间隔长(即产生的回忆率低于期望的水平)，则 <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 值相应减少。</p><p data-pid="aPhn2Yoa">Here is the evolution of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability_increase" class=" wrap external" target="_blank" rel="nofollow noreferrer">stability increase</a> (constant  <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> ) over years:</p><p data-pid="P7JDqlyV">以下是<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability_increase" class=" wrap external" target="_blank" rel="nofollow noreferrer">稳定性增加</a>(常数 <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1">)多年来的演变：</p><ul><li data-pid="opsHbMVe">in the paper-and-pencil version of SuperMemo (1985), <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> was indeed (almost) a constant. Set at the average of 1.75 (varying from 1.5 to 2.0 for rounding errors and simplicity), it did not consider <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Difficulty" class=" wrap external" target="_blank" rel="nofollow noreferrer">material difficulty</a>, <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">stability</a> or <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">retrievability</a> of memories, etc.</li><li data-pid="wfjJ5wWH">在纸笔版本的 SuperMemo(1985) 中，<img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 确实(几乎)是一个常数。设置为平均 1.75 (为了舍入误差和简单性，从 1.5 到 2.0 不等)，没有考虑材料难度、稳定性或记忆的可提取性等。</li><li data-pid="phW8MAMd">in early versions of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo_for_DOS" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo for DOS</a> (1987), <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1">, named <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/E-Factor" class=" wrap external" target="_blank" rel="nofollow noreferrer">E-Factor</a>, reflected <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Difficulty" class=" wrap external" target="_blank" rel="nofollow noreferrer">item difficulty</a> for the first time. It was decreased for bad grades and increased for good grades</li><li data-pid="sis56_uC">在 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo_for_DOS" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo for DOS</a>(1987) 的早期版本中，<img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> (命名为 E-因子)首次反映了项目难度。成绩不好时降低，成绩好时增加。</li><li data-pid="h6qQLquT">SuperMemo 4 (1989) did not use <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1">, but, to compute inter-repetition intervals, it employed optimization matrices for the first time</li><li data-pid="ksA9OLAH">SuperMemo 4(1989) 没有使用 <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1">，但是为了计算重复间隔，它第一次使用了优化矩阵</li><li data-pid="AOItmHxx">in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo_5" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo 5</a> (1990), <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1">, named <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/O-Factor" class=" wrap external" target="_blank" rel="nofollow noreferrer">O-Factor</a> was finally represented as a matrix and it included both the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Difficulty" class=" wrap external" target="_blank" rel="nofollow noreferrer">difficulty</a> dimension as well as the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">stability</a> dimension. Again, entries of the matrix would be subject to the measure-verify-correct cycle that would, starting with the initial value based on prior measurements, produce a convergence towards the value that would satisfy the learning criteria</li><li data-pid="zBmu87-l">在 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo_5" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo 5</a> (1990) 中，<img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> (命名为 O-因子)最终被表示为一个矩阵，它既包括难度维度，也包括稳定性维度。同样，矩阵的条目将受到测量-验证-校正循环的影响，该循环将从基于先前测量的初始值开始，产生向满足学习标准的值的收敛</li><li data-pid="jXqiSdJC">in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo_6" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo 6</a> (1991), <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> in the form of the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/O-Factor_matrix" class=" wrap external" target="_blank" rel="nofollow noreferrer">O-Factor matrix</a> would be derived from a three-dimensional matrix that would include the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">retrievability</a> dimension. The important implication of the third dimension was that, for the first time, <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a> would make it possible to inspect <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Forgetting_curve" class=" wrap external" target="_blank" rel="nofollow noreferrer">forgetting curves</a> for different levels of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Difficulty" class=" wrap external" target="_blank" rel="nofollow noreferrer">difficulty</a> and <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">memory stability</a></li><li data-pid="8zhrW3pU">在 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo_6" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo 6</a>(1991) 中，<img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 以 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/O-Factor_matrix" class=" wrap external" target="_blank" rel="nofollow noreferrer">O-因子矩阵</a>的形式派生自一个包含可提取性维度的三维矩阵。第三维度的重要意义是，<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo</a> 第一次使检查不同难度和记忆稳定性的遗忘曲线成为可能</li><li data-pid="P2owmv-i">in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo_8" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo 8</a> (1997) through <a href="http://link.zhihu.com/?target=http%3A//www.super-memo.com/supermemo16.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo 16</a>, the representation of <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> would not change much, however, the algorithm used to produce a quick and stable transition from the theoretical to the real set of data would gradually get more and more complex. Most importantly, new SuperMemos make a better use of the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">retrievability</a> dimension of <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1">. Thus, independent of the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Spacing_effect" class=" wrap external" target="_blank" rel="nofollow noreferrer">spacing effect</a>, the student can depart from the initial learning criteria, e.g. to cram before an exam, without introducing noise into the optimization procedure</li><li data-pid="zj_1QUiG">在 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo_8" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo 8</a>(1997) 到 <a href="http://link.zhihu.com/?target=http%3A//www.super-memo.com/supermemo16.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo 16</a> 中，<img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 的表示没有有太大变化，但是，用于产生从理论数据到真实数据的快速而稳定的转换的算法将逐渐变得越来越复杂。最重要的是，新的 SuperMemo 更好地利用了 <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 的可提取性性维度。因此，与间隔效应无关，学生可以偏离初始学习标准，例如在考试前临时抱佛脚，而不会在优化过程中引入噪声</li><li data-pid="6BftkNwf">in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo_17" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo 17</a> (2016),<img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> finally took the form based on the original <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Two_component_model_of_memory" class=" wrap external" target="_blank" rel="nofollow noreferrer">two component model of memory</a>. It is taken from <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability_increase" class=" wrap external" target="_blank" rel="nofollow noreferrer">stability increase</a> matrix (SInc) that has three dimensions that represent the three variables that determine the increase in stability: <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Complexity" class=" wrap external" target="_blank" rel="nofollow noreferrer">complexity</a>, <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stability" class=" wrap external" target="_blank" rel="nofollow noreferrer">stability</a> and <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Retrievability" class=" wrap external" target="_blank" rel="nofollow noreferrer">retrievability</a>. The SInc matrix is filled up with data during learning using a complex algorithm known as <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Algorithm_SM-17" class=" wrap external" target="_blank" rel="nofollow noreferrer">Algorithm SM-17</a>. The stability increase matrix can be inspected in SuperMemo 17 with <b>Tools : Memory : 4D Graphs</b> (<b>Stability</b> tab)</li><li data-pid="QoTkiEPj">在 <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/SuperMemo_17" class=" wrap external" target="_blank" rel="nofollow noreferrer">SuperMemo 17</a> (2016) 中， <img src="https://www.zhihu.com/equation?tex=C_2" alt="C_2" eeimg="1"> 最终采取了基于最初的记忆双组分模型的形式。它取自稳定性增加矩阵(SInc)，该矩阵具有三个维度，表示决定稳定性增加的三个变量：复杂性、稳定性和可提取性。在使用称为算法 SM-17 的复杂算法学习期间用数据填充 SInc 矩阵。可使用 <b>Tools：Memory：4D Graphs</b> (<b>稳定性</b> 选项卡)在 SuperMemo 17 中检查稳定性增加矩阵。</li></ul>