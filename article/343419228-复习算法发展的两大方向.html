<meta charset="UTF-8">
复习算法发展的两大方向
<div><p>目前的复习算法主要可以分为两大类别——以 SuperMemo 为代表的状态转移法和以 Duolingo 为代表的机器学习方法。</p><h2>方法简介</h2><p>何为状态转移法？即复习安排与记忆的当前状态和反馈直接关联，并且每次复习都会根据相关的记忆模型（或者经验公式）改变记忆状态，以此为复习安排的基础。在状态转移法看来，单条记忆的每一次反馈都会改变此记忆的状态，每一次复习安排都是以此前的所有安排所造成的状态转移为基础的。算法代表：SM-2<sup><a aria-labelledby="ref_1" data-reference-link="true" href="#ref_1" id="ref_1_0">[1]</a></sup>、Leitner box、Pimsleur</p><p>那么机器学习法呢？则是将单条记忆的历史反馈降维成几个特征，再使用各种模型对这些特征进行学习。机器学习方法将会得到一组权重，新的复习安排会先对相关的反馈历史和当前反馈做特征提取，然后将权重代入计算得出复习间隔。算法代表：half-life regression<sup><a aria-labelledby="ref_2" data-reference-link="true" href="#ref_2" id="ref_2_0">[2]</a></sup>、MemAid、FullRecall</p><h2>优缺点分析</h2><p>两种方法的优缺点都很明显，并且有一定的互补性，分析如下：</p><p><b>状态转移法</b></p><p>状态转移法的优点在于，它能利用到较为完整的反馈历史，对不按照正常安排的复习有天然的适应空间（也就是潜力，至于能否发挥出来，还需要看算法的具体设计）。</p><p>缺点是，由于记忆异质性和观察者效应，不存在完全相同的状态，如何忽略无关的区别、减少状态空间的大小，是这种方法的难点。（SuperMemo 8 划分出了 20 * 20 * 20 的状态空间，也就是说有 8000 种状态）</p><figure><img class="origin_image zh-lightbox-thumb lazy" data-actualsrc="https://pic1.zhimg.com/v2-33b1c4abac8b58c4e4a221d1e7bbd704_b.jpg" data-caption="" src="https://pic1.zhimg.com/v2-33b1c4abac8b58c4e4a221d1e7bbd704_r.jpg" data-rawheight="1038" data-rawwidth="1506" data-size="normal" src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='1506' height='1038'&gt;&lt;/svg&gt;" width="1506"/></figure><p><b>机器学习法</b></p><p>机器学习方法的优点在于，通过特征降维等方法，把原本的记忆反馈历史降维成了一个易于使用模型训练的二维表，从而可以使用梯度下降等方法来优化模型。</p><figure><img class="origin_image zh-lightbox-thumb lazy" data-actualsrc="https://pic2.zhimg.com/v2-8519d2921c19e29ea3842ad466dbe1ed_b.jpg" data-caption="" src="https://pic2.zhimg.com/v2-8519d2921c19e29ea3842ad466dbe1ed_r.jpg" data-rawheight="278" data-rawwidth="481" data-size="normal" src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='481' height='278'&gt;&lt;/svg&gt;" width="481"/></figure><p>它的缺点也很明显，降维可能会丢失有用的过程数据。就比如 Duolingo 的 half-life regression 模型中，直接将历史反馈数据降维成历史遗忘次数和历史复习次数。在这种降维方法下，用不同的间隔连续复习三次，只要累积的对应反馈一致，它们的特征就是一致的。这显然是不合理的，根据间隔效应，1 天、3 天、5 天的复习与 10 天、10 天、10 天的复习对记忆的影响是不同的。</p><p>想要解决这个问题，就需要将历史复习间隔当作时间序列特征输入，但这又会遇到与状态转移法一样的问题。</p><h2>小结</h2><p>通过对比状态转移方法和机器学习方法后，我们就会发现，这两种方法有很大的互补性。单纯地鼓吹其中一种方法的优越性是不符合实际的。根据定义，SuperMemo 历代算法中，纯粹的状态转移方法只有 SM-2（也就是 Anki 算法的基础<sup><a aria-labelledby="ref_3" data-reference-link="true" href="#ref_3" id="ref_3_0">[3]</a></sup>）一种。在 SM-3+ 中，统计、拟合的方法都被引入<sup><a aria-labelledby="ref_4" data-reference-link="true" href="#ref_4" id="ref_4_0">[4]</a></sup>。所以，从一定程度上来讲，SuperMemo 的后续算法都是在状态转移方法的基础上融合机器学习的方法。这也是笔者这段时间研究的重点，相关的思考也会陆续分享给大家。</p><h2>参考</h2><ol><li><a aria-label="back" class="ReferenceList-backLink" data-reference-link="true" href="#ref_1_0">^</a><span>04 SuperMemo 1.0: 日志 (1987)</span> <a class="external" href="https://zhuanlan.zhihu.com/p/97887756" rel="noopener noreferrer" target="_blank">https://zhuanlan.zhihu.com/p/97887756</a></li><li><a aria-label="back" class="ReferenceList-backLink" data-reference-link="true" href="#ref_2_0">^</a><span>duolingo / halflife-regression</span> <a class="external" href="https://github.com/duolingo/halflife-regression" rel="noopener noreferrer" target="_blank">https://github.com/duolingo/halflife-regression</a></li><li><a aria-label="back" class="ReferenceList-backLink" data-reference-link="true" href="#ref_3_0">^</a><span>What spaced repetition algorithm does Anki use?</span> <a class="external" href="https://faqs.ankiweb.net/what-spaced-repetition-algorithm.html" rel="noopener noreferrer" target="_blank">https://faqs.ankiweb.net/what-spaced-repetition-algorithm.html</a></li><li><a aria-label="back" class="ReferenceList-backLink" data-reference-link="true" href="#ref_4_0">^</a><span>1989: SuperMemo 适应用户记忆</span> <a class="external" href="https://zhuanlan.zhihu.com/p/205600711" rel="noopener noreferrer" target="_blank">https://zhuanlan.zhihu.com/p/205600711</a></li></ol></div>