<meta charset="UTF-8">
复习算法发展的两大方向
<p data-pid="7Y4Wi6lC">目前的复习算法主要可以分为两大类别——以 SuperMemo 为代表的状态转移法和以 Duolingo 为代表的机器学习方法。</p><h2>方法简介</h2><p data-pid="nrRP_i4R">何为状态转移法？即复习安排与记忆的当前状态和反馈直接关联，并且每次复习都会根据相关的记忆模型（或者经验公式）改变记忆状态，以此为复习安排的基础。在状态转移法看来，单条记忆的每一次反馈都会改变此记忆的状态，每一次复习安排都是以此前的所有安排所造成的状态转移为基础的。算法代表：SM-2<sup data-text="04 SuperMemo 1.0: 日志 (1987)" data-url="https://zhuanlan.zhihu.com/p/97887756" data-draft-node="inline" data-draft-type="reference" data-numero="1">[1]</sup>、Leitner box、Pimsleur</p><p data-pid="f17CV2KM">那么机器学习法呢？则是将单条记忆的历史反馈降维成几个特征，再使用各种模型对这些特征进行学习。机器学习方法将会得到一组权重，新的复习安排会先对相关的反馈历史和当前反馈做特征提取，然后将权重代入计算得出复习间隔。算法代表：half-life regression<sup data-text="duolingo / halflife-regression" data-url="https://github.com/duolingo/halflife-regression" data-draft-node="inline" data-draft-type="reference" data-numero="2">[2]</sup>、MemAid、FullRecall</p><h2>优缺点分析</h2><p data-pid="iMjxtDbB">两种方法的优缺点都很明显，并且有一定的互补性，分析如下：</p><p data-pid="kCHo9Efa"><b>状态转移法</b></p><p data-pid="XCNKGOMj">状态转移法的优点在于，它能利用到较为完整的反馈历史，对不按照正常安排的复习有天然的适应空间（也就是潜力，至于能否发挥出来，还需要看算法的具体设计）。</p><p data-pid="qD0NkTKY">缺点是，由于记忆异质性和观察者效应，不存在完全相同的状态，如何忽略无关的区别、减少状态空间的大小，是这种方法的难点。（SuperMemo 8 划分出了 20 * 20 * 20 的状态空间，也就是说有 8000 种状态）</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-33b1c4abac8b58c4e4a221d1e7bbd704_720w.jpg?source=3af55fa1" data-caption="" data-size="normal" data-rawwidth="1506" data-rawheight="1038" class="origin_image zh-lightbox-thumb" width="1506" data-original="https://pic3.zhimg.com/v2-33b1c4abac8b58c4e4a221d1e7bbd704_720w.jpg?source=3af55fa1"></figure><p data-pid="yRZhdnI7"><b>机器学习法</b></p><p data-pid="zb5E_6Au">机器学习方法的优点在于，通过特征降维等方法，把原本的记忆反馈历史降维成了一个易于使用模型训练的二维表，从而可以使用梯度下降等方法来优化模型。</p><figure data-size="normal"><img src="https://pic2.zhimg.com/v2-8519d2921c19e29ea3842ad466dbe1ed_720w.jpg?source=3af55fa1" data-caption="" data-size="normal" data-rawwidth="481" data-rawheight="278" class="origin_image zh-lightbox-thumb" width="481" data-original="https://pica.zhimg.com/v2-8519d2921c19e29ea3842ad466dbe1ed_720w.jpg?source=3af55fa1"></figure><p data-pid="1KjH-yJZ">它的缺点也很明显，降维可能会丢失有用的过程数据。就比如 Duolingo 的 half-life regression 模型中，直接将历史反馈数据降维成历史遗忘次数和历史复习次数。在这种降维方法下，用不同的间隔连续复习三次，只要累积的对应反馈一致，它们的特征就是一致的。这显然是不合理的，根据间隔效应，1 天、3 天、5 天的复习与 10 天、10 天、10 天的复习对记忆的影响是不同的。</p><p data-pid="DW5JT3LR">想要解决这个问题，就需要将历史复习间隔当作时间序列特征输入，但这又会遇到与状态转移法一样的问题。</p><h2>小结</h2><p data-pid="1b-blTYw">通过对比状态转移方法和机器学习方法后，我们就会发现，这两种方法有很大的互补性。单纯地鼓吹其中一种方法的优越性是不符合实际的。根据定义，SuperMemo 历代算法中，纯粹的状态转移方法只有 SM-2（也就是 Anki 算法的基础<sup data-text="What spaced repetition algorithm does Anki use?" data-url="https://faqs.ankiweb.net/what-spaced-repetition-algorithm.html" data-draft-node="inline" data-draft-type="reference" data-numero="3">[3]</sup>）一种。在 SM-3+ 中，统计、拟合的方法都被引入<sup data-text="1989: SuperMemo 适应用户记忆" data-url="https://zhuanlan.zhihu.com/p/205600711" data-draft-node="inline" data-draft-type="reference" data-numero="4">[4]</sup>。所以，从一定程度上来讲，SuperMemo 的后续算法都是在状态转移方法的基础上融合机器学习的方法。这也是笔者这段时间研究的重点，相关的思考也会陆续分享给大家。</p>