<meta charset="UTF-8">
07 1990：记忆的通用公式
<div><p>总目录：<a class="internal" href="https://zhuanlan.zhihu.com/p/375379522?">0 目录《间隔重复的历史》</a></p><p>上一章：<a class="internal" href="https://zhuanlan.zhihu.com/p/213170503">06 1989: SuperMemo 适应用户记忆(下)</a></p><hr/><blockquote><a class="wrap external" href="https://paratranz.cn/projects/3131" rel="nofollow noreferrer" target="_blank">Thoughts Memo</a> 汉化组译制</blockquote><p>原文：<a class="wrap external" href="https://supermemo.guru/wiki/History_of_spaced_repetition_%28print%29%231990%3A_Universal_formula_for_memory" rel="nofollow noreferrer" target="_blank">1990: Universal formula for memory</a></p><h2>最优复习与间歇复习</h2><p>到了 1990 年，我很是笃定我手握着重大发现。我破解了<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting" rel="nofollow noreferrer" target="_blank">遗忘</a>难题。我知道了记忆简单内容的复习<a class="wrap external" href="https://supermemo.guru/wiki/Spaced_repetition" rel="nofollow noreferrer" target="_blank">最佳时机</a>。一经在我<a class="wrap external" href="https://supermemo.guru/wiki/Optimization_of_learning" rel="nofollow noreferrer" target="_blank">硕士论文</a>中描述它的许可，我的探索欲也水涨船高。我希望我可以找到一个长期记忆的通用公式，能够让我跟踪记忆在各种形式的检索和接触中的表现形式。</p><p>我已经收集了一些数据，这些数据可能会帮助我找到这个公式。在 <a class="wrap external" href="https://supermemo.guru/wiki/Birth_of_SuperMemo" rel="nofollow noreferrer" target="_blank">1985</a> 年发现最佳重复间隔之前，我把问题写在一页页纸上来复习知识。此时复习混乱不堪，由可利用的时间、需要或心情支配。我把这称为「间歇性学习」。我有单个页面和每次复习的回忆数据。虽没有 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 的周期性，这种数据也算较为理想。这正是我为解决记忆问题而需要的数据。只不过，这些数据都仅仅记录在纸上。</p><p>1990 年春天，我叫我姐姐来打字录入数据。当然，我没有一个妹妹会情愿来做这件事。我的姐姐比我大 17 岁。我利用她对我的爱，让她做这种枯燥繁重的工作，而没有顾及到她的时间。她两年后去世了。我再也没有机会报答她对<a class="wrap external" href="https://supermemo.guru/wiki/Spaced_repetition" rel="nofollow noreferrer" target="_blank">间隔重复</a>理论的贡献，她甚至没有机会了解这个理论。从 1990 年 5 月 1 日开始，她在我不用电脑的时间，将数据从纸上转移到电脑上。她打字很慢，花了很多天。她的工夫是值得的。</p><h2>间歇学习模型</h2><p>在 1990 年的整个夏天，我没有专注于我的<a class="wrap external" href="https://supermemo.guru/wiki/Optimization_of_learning" rel="nofollow noreferrer" target="_blank">硕士论文</a>，而是研究「间歇学习模型」。对我来说，连续工作 10 个小时，感觉没有半点发现而在早上 7 点睡觉，或者让电脑整夜计算数据，都是很正常的。</p><p>锲而不舍，捣鼓调整是有代价的。只有少年才能负担得起，他们应该有空间和自由。尽管我已经 28 岁了，家人们还是默默忍受我的一举一动。就像一个不成熟的青少年。我住在我姐姐的公寓里，在那里我可以利用她的善意。在电脑前工作的时间很长，被借口为「在做我的硕士论文」。事实上，没有人要求我这样做，也没有人要求我这样做，它甚至没有推动 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 的发展。这是一个纯粹的科学好奇心的案例。我只是想知道记忆是如何工作的。</p><p>我有几十页的问题和他们的<a class="wrap external" href="https://supermemo.guru/wiki/Repetition_history" rel="nofollow noreferrer" target="_blank">重复历史</a>。我试图预测「每页的记忆失误」。我使用<a class="wrap external" href="https://supermemo.guru/wiki/Deviation" rel="nofollow noreferrer" target="_blank">平方根标准差</a>来预测失误（下面表示为Dev）。到 1990 年 7 月 10 日，星期二，我达到了 Dev&lt;3，感觉问题几乎「解决」了。1990 年 7 月 12 日，我改进到 Dev=2.877（顺便说一下，我的论文中提到了2.887241）。然而，到 1990 年 8 月 27 日，我在那天的笔记中宣布这个问题无法解决。</p><hr/><p> 个人轶事。<a class="wrap external" href="https://supermemo.guru/wiki/Why_use_anecdotes%253F" rel="nofollow noreferrer" target="_blank">为什么使用轶事？</a><br/><br/>1990 年 8 月 27 日：<b>我解决了</b>间歇学习，<b>表明这个问题是无法解决的</b>！单独一个参数无力描述与整页项目的记忆强度。这表明，<b><a class="wrap external" href="https://supermemo.guru/wiki/E-Factor" rel="nofollow noreferrer" target="_blank">E 因子</a>较低的项目没有</b><a class="wrap external" href="https://supermemo.guru/wiki/Optimal_interval" rel="nofollow noreferrer" target="_blank">最优间隔</a>！</p><hr/><p>1990 年 8 月 30 日，我在硕士论文中解说了这个模型。文章一共有 15 页，不算很好读。我打赌没有人有耐心读完整篇文章。90 年代末我的硕士论文节选版发布在网络，而描述间歇学习的这一章甚至没有在 <a class="wrap external" href="https://link.zhihu.com/?target=http%3A//supermemo.com/" rel="nofollow noreferrer" target="_blank">supermemo.com</a> 上发表。</p><p>然而，基于该模型得出的结论，深刻地影响了我随后几十年中对记忆的思考。该模型背后的想法，实际上非常类似我在开发 <a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer" target="_blank">SM-17 算法</a> (2014-2016) 时应用的优化。</p><p>当我宣布这个问题无法解决时，我的意思是我无法准确地描述「困难页」的记忆，因为性质不同的材料需要更复杂的模型。然而，这篇 1990 年 8 月 31 日记录的笔记却对此更加乐观：</p><hr/><p> 个人轶事。<a class="wrap external" href="https://supermemo.guru/wiki/Why_use_anecdotes%253F" rel="nofollow noreferrer" target="_blank">为什么使用轶事？</a><br/><br/>1990 年 8 月 31 日：不间断地研究间歇学习模型。到了晚上，计算机终究没有让我离解决方案更进一步。然而，我有个好主意，就是用 IL 模型的绝世优秀功能计算出最优间隔。屏幕上的结果映入眼帘时，我简直不敢相信我 [哔——] 看到什么。这些正是我在 1985 年<a class="wrap external" href="https://supermemo.guru/wiki/Birth_of_SuperMemo" rel="nofollow noreferrer" target="_blank">发现</a>时试图制定 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 方法时发现的间隔。我高兴地在家里跳来跳去，简直像一条有两条尾巴的狗。所以我可以说我真的解决了 IL 问题（对比 1990 年 8 月 27 日）。但我发现，这个成功并不是今天给我发现的一切：</p><ul><li><a class="wrap external" href="https://supermemo.guru/wiki/Optimal_factor" rel="nofollow noreferrer" target="_blank">最优系数</a>随着连续的间隔而减少（我以前凭直觉感觉是这样的），</li><li> 对于<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>等于 10%，<a class="wrap external" href="https://supermemo.guru/wiki/Retention" rel="nofollow noreferrer" target="_blank">保留率</a>为 94%（如 EVF <a class="wrap external" href="https://supermemo.guru/wiki/Database" rel="nofollow noreferrer" target="_blank">数据库</a>）</li><li><b><a class="wrap external" href="https://supermemo.guru/wiki/Retention" rel="nofollow noreferrer" target="_blank">保留率</a>与<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a></b>呈线性关系 [2018 年评论：在异质材料的小范围内]<b>（这无法从我 1 月份进行的模拟实验中计算出来）</b></li><li> 该模型说，<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>的理想值是 5-10%（工作量-保留率的权衡）</li><li> 如果间隔时间是最优时间的两倍，则<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">记忆强度</a>增加最多！！</li><li> 如果<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>为 20%，则<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">记忆强度</a>增加最多</li></ul><p> [...] 我的公式只有在间隔比以前的强度短不了多少时才有效。</p><hr/><h2>过去（1990）与现在（2018）的对比</h2><p>本章末尾的结论，以及程序本身都让人想起我在 2005 年寻找<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">记忆稳定性</a>提高的通用公式时使用的方法，以及在 2014 年，<a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer" target="_blank">算法 SM-17</a> 是基于对记忆的更精确的数学描述。像最新的 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 算法一样，该模型使得计算任何重复计划的<a class="wrap external" href="https://supermemo.guru/wiki/Retention" rel="nofollow noreferrer" target="_blank">保留率</a>成为可能。当然，它的准确度要低得多，因为它基于劣质的数据。此外， <a class="wrap external" href="https://link.zhihu.com/?target=http%3A//super-memo.com/supermemo17.html" rel="nofollow noreferrer" target="_blank">SuperMemo 17</a> 所做的实时工作，在 1990 年时需要花费许多小时的 PC 电脑时间。</p><p>我的硕士论文中这个看似无聊的老的部分到现在已经变得很重要了。我敢说，只有劣质的数据将这项工作与 25 年后出现的<a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer" target="_blank">算法 SM-17</a> 相隔甚远。我引用的这段文字在符号和文体上做了些许改进，但没有关于<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_curve" rel="nofollow noreferrer" target="_blank">遗忘曲线</a>的章节，该章节由于计算中使用的材料太不同而出现错误。</p><hr/><p>存档警告：<a class="wrap external" href="https://supermemo.guru/wiki/Why_use_literal_archives%253F" rel="nofollow noreferrer" target="_blank">为什么使用文字档案？</a></p><p>这段文字是《<a class="wrap external" href="https://supermemo.guru/wiki/Optimization_of_learning" rel="nofollow noreferrer" target="_blank">优化学习</a>》 作者：<a class="wrap external" href="https://supermemo.guru/wiki/Piotr_Wozniak" rel="nofollow noreferrer" target="_blank">Piotr Wozniak</a> (1990) 的一部分</p><h3><b>间歇学习模型</b></h3><p><a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 模型为计算<a class="wrap external" href="https://supermemo.guru/wiki/Optimal_interval" rel="nofollow noreferrer" target="_blank">最优间隔</a>提供了基础，在时间最优的学习过程中，应该把重复的内容分开。</p><p>然而，如果重复的时间间隔不规律，则无法预测记忆变量的变化。</p><p>下面我提出一个尝试，以增强 SuperMemo 模型，使其可以用于描述间歇学习的过程。</p><p>在<a class="wrap external" href="https://link.zhihu.com/?target=http%3A//super-memory.com/english/ol/beginning.htm" rel="nofollow noreferrer" target="_blank">第三章</a>中，我提到了，在<a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo_on_paper" rel="nofollow noreferrer" target="_blank">算法 SM-0</a> 开发之前，我学习英语和生物的方式。</p><p>那段时间（1982-1984年）收集的数据为构建间歇学习模型提供了一个很好的基础。遵照<a class="wrap external" href="https://supermemo.guru/wiki/Item" rel="nofollow noreferrer" target="_blank">最小信息原则</a>制定的<a class="wrap external" href="https://supermemo.guru/wiki/Minimum_information_principle" rel="nofollow noreferrer" target="_blank">项目</a>（通常有成对的词的形式）被分组在页面中，进行不定期的复习过程。</p><p>所收集的数据以计算机可读形式提供，包括71页的重复描述，此外，80个类似的页面参与了由<a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo_on_paper" rel="nofollow noreferrer" target="_blank">SM-0</a>时间表监督的过程。</p><hr/><h2>与算法 SM-17 的相似性</h2><p>请注意，这个问题的表述让人想起了<a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer" target="_blank">算法SM-17</a> 中用来计算<a class="wrap external" href="https://supermemo.guru/wiki/Stability_increase" rel="nofollow noreferrer" target="_blank">稳定性增长矩阵（SInc[]）</a>的程序。<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">记忆稳定性</a>被重新缩放，以便能够将其解释为一个<a class="wrap external" href="https://supermemo.guru/wiki/Interval" rel="nofollow noreferrer" target="_blank">间隔</a>。甚至符号也是相似的：S 代表<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>，D 代表<a class="wrap external" href="https://supermemo.guru/wiki/Deviation" rel="nofollow noreferrer" target="_blank">偏差</a>。页面遗忘数量代替了<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>。</p><p>我以前喜欢玩各种优化算法。你仍然可以在 <a class="wrap external" href="https://link.zhihu.com/?target=http%3A//super-memo.com/supermemo17.html" rel="nofollow noreferrer" target="_blank">SuperMemo 17</a> 中查看该算法做表面拟合优化的可视化（见<a class="wrap external" href="https://supermemo.guru/wiki/Stability_increase" rel="nofollow noreferrer" target="_blank">图片</a>）。12 个变量做处理可能有点低效，但我从不关心处理方法本身如何，只关心能否结果是否可以拓展我对记忆原理的认知。</p><p>对于那些熟悉<a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer" target="_blank">算法 SM-17</a> 的人，我们在下面的文本中改变了符号。此外，我们改变了 In 和 Ln 等符号，这些符号在打印时很容易被误读为对数。</p><p>变化清单：</p><ul><li> Ln -&gt; <img alt="\mathrm{Laps_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_n%7D"/> </li><li> In -&gt; <img alt="\mathrm{Int_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_n%7D"/> </li><li> Dn -&gt; <img alt="\mathrm{Dev_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BDev_n%7D"/> </li><li> R -&gt; RepNo<br/> </li></ul><h2>间歇学习问题的表述</h2><hr/><p>存档警告：<a class="wrap external" href="https://supermemo.guru/wiki/Why_use_literal_archives%253F" rel="nofollow noreferrer" target="_blank">为什么使用文字档案？</a></p><p>这段文字是《<a class="wrap external" href="https://supermemo.guru/wiki/Optimization_of_learning" rel="nofollow noreferrer" target="_blank">优化学习</a>》作者：<a class="wrap external" href="https://supermemo.guru/wiki/Piotr_Wozniak" rel="nofollow noreferrer" target="_blank">Piotr Wozniak</a> (1990) 的一部分</p><h3><b>11.1.间歇学习问题的提出</b></h3><p>1. 共有 161 个页面。</p><p>2. 每页包含约 40 个项目。</p><p>3. 对于每一页，学习过程的描述（在实验重复期间收集）有以下形式：</p><p> ((-, <img alt="\mathrm{Laps_1}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_1%7D"/> ),( <img alt="\mathrm{Int_2}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_2%7D"/> , <img alt="\mathrm{Laps_2}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_2%7D"/> ),( <img alt="\mathrm{Int_3}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_3%7D"/> , <img alt="\mathrm{Laps_3}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_3%7D"/> ), ...,( <img alt="\mathrm{Int_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_n%7D"/> , <img alt="\mathrm{Laps_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_n%7D"/> ))</p><p>其中：</p><ul><li><img alt="\mathrm{Int_i}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_i%7D"/> - 第 i 次重复前使用的间隔（范围在 1 到 800 之间），</li><li><img alt="\mathrm{Laps_i}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_i%7D"/> - 在第 i 次重复过程中，遗忘的次数（范围从 0 到 40），</li><li> n - 总重复次数（范围从 3 到 20）。</li></ul><p>4. 找到公式所描述的函数 f 和 g：</p><p> S(1)=S1<br/> S(n)=f(S(n-1), <img alt="\mathrm{Int_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_n%7D"/> , <img alt="\mathrm{Laps_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_n%7D"/> )<br/> Laps(n)=g(S(n-1), <img alt="\mathrm{Int_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_n%7D"/> )</p><p>其中：</p><ul><li> S(n) - 与第 n 次重复后的记忆强度相对应的任何变量（比较<a class="wrap external" href="https://link.zhihu.com/?target=http%3A//super-memory.com/english/ol/ol_memory.htm" rel="nofollow noreferrer" target="_blank">第 10 章</a>），</li><li><img alt="\mathrm{Int_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_n%7D"/> - 第 n 次重复前使用的间隔；取自间歇学习期间收集的数据，</li><li><img alt="\mathrm{Laps_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_n%7D"/> - 在第 n 次重复中的遗忘数量；取自间歇学习期间收集的数据，</li><li> Laps(n) - 对第 n 次重复中记忆遗忘数量的估计（它应该与 <img alt="\mathrm{Laps_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_n%7D"/> 相对应）</li><li> S1 - 一个常数，</li></ul><p>使函数 Dev 最小化：</p><p>Dev=sqrt(( <img alt="\mathrm{Dev_1}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BDev_1%7D"/> + <img alt="\mathrm{Dev_2}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BDev_2%7D"/> + ... + <img alt="\mathrm{Dev_{161}}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BDev_%7B161%7D%7D"/>)/RepNo)<br/><img alt="\mathrm Dev_i" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm+Dev_i"/> =sqr(Laps(1)- <img alt="\mathrm{Laps_1}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_1%7D"/>)+sqr(Laps(2)- <img alt="\mathrm{Laps_2}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_2%7D"/>)+ ... +sqr(Laps(n)- <img alt="\mathrm{Laps_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_n%7D"/>))</p><p>其中：</p><ul><li> Dev - 描述函数 f 和 g 输出值之间差值的函数，值会在间歇学习期间收集（它反映了数据在实验和理论预测之间的差）</li><li> RepNo - 全部页面上的重复次数总和</li><li><img alt="\mathrm{Dev_i}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BDev_i%7D"/> - 函数Dev的分项，对应第i页的Dev.</li><li> Laps(j) - 使用函数f和g，分别对第i页和第j次重复计算的遗忘数量，</li><li><img alt="\mathrm{Laps_j}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_j%7D"/> - 第 i 页、第 j 次重复时的遗忘数量；取自间歇学习期间收集的数据，</li><li>sqrt(x) - x 的平方根，</li><li>sqr(x) - x 的平方。<br/> </li></ul><p>请注意，只有当函数 f 和 g 简单且定义参数有限时（如 a*ln()+b or a*exp()+b 等），才会有生物学上的思考价值。否则，人们总是可以构建一个巨大的、无意义的公式来自动将 Dev 归零。</p><hr/><h2>解决间歇学习的问题</h2><hr/><p>存档警告：<a class="wrap external" href="https://supermemo.guru/wiki/Why_use_literal_archives%253F" rel="nofollow noreferrer" target="_blank">为什么使用文字档案？</a></p><p>这段文字是《<a class="wrap external" href="https://supermemo.guru/wiki/Optimization_of_learning" rel="nofollow noreferrer" target="_blank">优化学习</a>》 作者：<a class="wrap external" href="https://supermemo.guru/wiki/Piotr_Wozniak" rel="nofollow noreferrer" target="_blank">Piotr Wozniak</a> (1990) 的一部分</p><h3><b>11.2. 间歇学习的解决方案</b></h3><p>在搜索使<i>Dev</i>值最小的函数f和g时，我用的是 <a class="wrap external" href="https://supermemo.guru/wiki/Optimization_of_learning_%281990%29%3A_References" rel="nofollow noreferrer" target="_blank">Wozniak, 1988b</a> 中描述的最小化的数值算法（<i>一种在可行区域内寻找函数局部最大值的新算法。可信论文</i>）。</p><p>搜索中使用实例函数如下：</p><p>S(1)=x[1]<br/>S(n)=x[2]* <img alt="\mathrm{Int_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_n%7D"/>*exp(- <img alt="\mathrm{Laps_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_n%7D"/>*x[3])+x[4])<br/>Laps(n)=x[5]*(1-exp(- <img alt="\mathrm{Int_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_n%7D"/> /S(n-1)))</p><p>其中：</p><ul><li> x[i] - 由最小化程序计算的变量，</li><li> S(n)、Laps(n)、<img alt="\mathrm{Laps_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_n%7D"/> 和<img alt="\mathrm{Int_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_n%7D"/> - 如 11.1 中的定义</li></ul><p>注意，描述 S(n) 的函数 f 不使用 S(n-1) 作为它的参数（问题的表述允许，但不要求在先前强度的基础上计算新的强度）。</p><p>为了保持简易度和节省时间，我设定了在最小化过程中使用 12 个变量的限制。</p><p>我测试了大量的数学函数，这些函数是根据有关记忆的明显直觉构建的（例如，随着时间的推移，页面遗忘的数量会增加）。</p><p>其中包括指数型、对数型、幂型、双曲线型、S 型、钟型、多项式及一些可能的组合。</p><p>在大多数情况下，最小化程序将 Dev 的值减少到 3 以下，函数 f 和 g 的形状类似，与它们的性质独立。</p><p>使用少于 12 个变量得到的 Dev 的最小值是 2.887241。</p><p>函数 f 和 g 如下：</p><div><pre><code>constant S(1)=0.2104031;

function Sn(Intn,Lapsn,S(n-1));
begin
    S(n):=0.4584914*(Intn+1.47)*exp(-0.1549229*Lapsn-0.5854939)+0.35;
    if Lapsn=0 then
        if S(n-1)&gt;In then
            S(n):=S(n-1)*0.724994
        else 
            S(n):=Intn*1.1428571;
end;

function Lapsn(Intn,S(n-1));
var quot;
begin
    quot:=(Intn-0.16)/(S(n-1)-0.02)+1.652668;
    Lapsn:=-0.0005408*quot*quot+0.2196902*quot+0.311335;
end;</code></pre></div><p>在不显著改变Dev的值的情况下，这些函数可以很容易地转换为以下形式：</p><p>S(1)=1<br/>for <img alt="\mathrm{Int_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_n%7D"/> &gt;S(n-1): S(n)=1.5* <img alt="\mathrm{Int_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_n%7D"/>*exp(-0.15* <img alt="\mathrm{Laps_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_n%7D"/>)+1<br/>Laps(n)= <img alt="\mathrm{Int_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_n%7D"/>/S(n-1)<br/> <br/> 请注意：</p><ul><li> 只要操作没有明显影响 Dev 的值，函数中的特定元素就会被删除或四舍五入，</li><li> 记忆强度进行了重新缩放，使其可以被解释为一个间隔，其中<a class="wrap external" href="https://supermemo.guru/wiki/Lapse" rel="nofollow noreferrer" target="_blank">遗忘</a>数量等于 1，<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>等于 2.5%（一页有 40 个项目，1/40=2.5%），</li><li> 仅当 Intn 不小于 S(n-1) 时，强度公式才有效。这是因为，如果<a class="wrap external" href="https://supermemo.guru/wiki/Lapse" rel="nofollow noreferrer" target="_blank">遗忘</a>的数量很低，必须使用 S(n-1) 的值来计算 S(n)，例如 Intn &lt;= S(n-1): S(n)=S(n-1)*(1+0.5/1-exp(S(n-1))*(1-exp(- <img alt="\mathrm{Int_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_n%7D"/>)))</li><li> 这些公式不能用于描述间隔比最优间隔长很多的过程。这是因为对于 <img alt="\mathrm{Int_n}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BInt_n%7D"/> -&gt;∞，Laps(n) 的值超过 100%，</li><li> 该公式描述了集体项目的学习，其特点是 <a class="wrap external" href="https://supermemo.guru/wiki/E-Factor" rel="nofollow noreferrer" target="_blank">E-系数</a>的分布或多或少地均匀。因此，它没能普遍用在难度可变的项目。</li></ul><p> 就目前而言，上述公式构成了对间歇学习过程的最佳描述，以后将被称为间歇学习模型（简称 IL 模型）</p><hr/><h2>基于间歇学习模型的模拟试验</h2><p>有了上面发现的公式，我可以进行一系列的模拟实验，帮助我回答许多关于记忆在不同情况下的行为的假设情景。这些模拟实验影响了 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 之后多年的进展。特别是，从 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo_6" rel="nofollow noreferrer" target="_blank">SuperMemo 6</a>（1991 ）开始，工作量和<a class="wrap external" href="https://supermemo.guru/wiki/Retention" rel="nofollow noreferrer" target="_blank">保留率</a>之间的权衡在优化学习方面起到了重要作用。直到今天，为学习提供指导标准的是<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>（或<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>），而不是在<a class="wrap external" href="https://supermemo.guru/wiki/Recall" rel="nofollow noreferrer" target="_blank">回忆</a>水平较低时可能出现的、直观自然的<a class="wrap external" href="https://supermemo.guru/wiki/Stability_increase" rel="nofollow noreferrer" target="_blank">记忆稳定性增长</a>。设定记忆<a class="wrap external" href="https://supermemo.guru/wiki/Lapse" rel="nofollow noreferrer" target="_blank">遗忘</a>水平起到了下面<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>的作用。</p><hr/><p>存档警告：<a class="wrap external" href="https://supermemo.guru/wiki/Why_use_literal_archives%253F" rel="nofollow noreferrer" target="_blank">为什么使用文字档案？</a></p><p>这段文字选自《<a class="wrap external" href="https://supermemo.guru/wiki/Optimization_of_learning" rel="nofollow noreferrer" target="_blank">优化学习</a>》 ，<a class="wrap external" href="https://supermemo.guru/wiki/Piotr_Wozniak" rel="nofollow noreferrer" target="_blank">Piotr Wozniak</a> (1990) 著</p><h3><b>11.4. 间歇学习模型的验证</b></h3><p>为了验证间歇学习模型与 SuperMemo 理论的一致性，让我们尝试计算出分散重复的最优间隔。</p><p>最优间隔由<a class="wrap external" href="https://supermemo.guru/wiki/Lapse" rel="nofollow noreferrer" target="_blank">遗忘</a>的数量达到选定值 Lapso 的时刻确定。</p><p>算法如下：</p><p>1. i:=1</p><p>2. S(i):=1</p><p>3. 找到 Int(i+1)，使 Laps(i+1) 等于 <img alt="\mathrm{Laps_o}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_o%7D"/> . 使用公式：</p><p>Int(n)= <img alt="\mathrm{Laps_o}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_o%7D"/> *S(n-1) (取自 IL 模型)</p><p>其中：</p><p>Int(n) 表示第 n-1 个最优间隔。</p><p>4. i:=i+1</p><p>5. S(i):=1.5*Int(i)*exp(-0.15*<img alt="\mathrm{Laps_o}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_o%7D"/>)+1（取自 IL 模型）</p><p>6. goto 3</p><p>如果 Lapso 等于 2.5（<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a> 6.25%），而且间歇学习模型参数相同，那么可以观察到惊人的对应关系（比较第 16 页<a class="wrap external" href="https://supermemo.guru/wiki/Birthday_of_SuperMemo" rel="nofollow noreferrer" target="_blank">第 3.1 章</a>介绍的实验）：</p><ul><li> Rep - 重复的数量</li><li> 间隔 - 重复前的最优间隔，在 IL 模型的基础上由 <img alt="\mathrm{Laps_o}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_o%7D"/> =2.5 确定，</li><li> 系数 - 最优系数，等于最优间隔除以上一次的最优间隔，</li><li> SM-0 - 在得出 SM-0 算法的实验的基础上计算出的最优间隔</li></ul><table><tbody><tr><th>Rep</th><th>间隔</th><th>系数</th><th>SM-0</th></tr><tr><td>2</td><td>1.8</td><td></td><td>1</td></tr><tr><td>3</td><td>7.8</td><td>4.36</td><td>7</td></tr><tr><td>4</td><td>16.8</td><td>2.15</td><td>16</td></tr><tr><td>5</td><td>30.4</td><td>1.80</td><td>35</td></tr><tr><td>6</td><td>50.4</td><td>1.66</td><td></td></tr><tr><td>7</td><td>80.2</td><td>1.59</td><td></td></tr><tr><td>8</td><td>124</td><td>1.55</td><td></td></tr><tr><td>9</td><td>190</td><td>1.53</td><td></td></tr><tr><td>10</td><td>288</td><td>1.52</td><td></td></tr><tr><td>11</td><td>436</td><td>1.51</td><td></td></tr><tr><td>12</td><td>654</td><td>1.50</td><td></td></tr><tr><td>13</td><td>981</td><td>1.50</td><td></td></tr><tr><td>14</td><td>1462</td><td>1.49</td><td></td></tr><tr><td>15</td><td>2179</td><td>1.49</td><td></td></tr><tr><td>16</td><td>3247</td><td>1.49</td><td></td></tr><tr><td>17</td><td>4838</td><td>1.49</td><td></td></tr><tr><td>18</td><td>7209</td><td>1.49</td><td></td></tr></tbody></table><p>显然，这种确切的对应关系，在某种程度上是一种巧合，因为导致制定 SM-0 算法的实验并不是那么敏感。</p><p>值得注意的是，<b><a class="wrap external" href="https://supermemo.guru/wiki/Optimal_factor" rel="nofollow noreferrer" target="_blank">最优系数</a>有逐步降低的趋势！</b>这一事实似乎证实了最近一系列观察，这些观察基于对<a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-5" rel="nofollow noreferrer" target="_blank">SM-5 算法</a> 中使用的<a class="wrap external" href="https://supermemo.guru/wiki/OF_matrix" rel="nofollow noreferrer" target="_blank">最优系数矩阵</a>的分析。</p><p>如果 Lapso 等于4（<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a> 10%，如<a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-5" rel="nofollow noreferrer" target="_blank">算法 SM-5</a>），那么<a class="wrap external" href="https://supermemo.guru/wiki/Optimal_factor" rel="nofollow noreferrer" target="_blank">最优系数</a>的序列就类似于<a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-5" rel="nofollow noreferrer" target="_blank">算法 SM-5</a>中 <a class="wrap external" href="https://supermemo.guru/wiki/OF_matrix" rel="nofollow noreferrer" target="_blank">OF 矩阵</a>的一列。同时，知识保留几乎与 SM-5 <a class="wrap external" href="https://supermemo.guru/wiki/Database" rel="nofollow noreferrer" target="_blank">数据库</a>中的知识保留理想地匹配。</p><table><tbody><tr><th>Rep</th><th>间隔</th><th>保留率</th><th>系数</th></tr><tr><td>2</td><td>3</td><td>93.21678</td><td></td></tr><tr><td>3</td><td>16</td><td>93.80946</td><td>4.89</td></tr><tr><td>4</td><td>43</td><td>93.97184</td><td>2.74</td></tr><tr><td>5</td><td>102</td><td>94.04083</td><td>2.39</td></tr><tr><td>6</td><td>232</td><td>94.06886</td><td>2.27</td></tr><tr><td>7</td><td>517</td><td>94.08418</td><td>2.23</td></tr><tr><td>8</td><td>1138</td><td>94.09256</td><td>2.20</td></tr><tr><td>9</td><td>2502</td><td>94.09737</td><td>2.20</td></tr><tr><td>10</td><td>5481</td><td>94.09967</td><td>2.19</td></tr></tbody></table><p><a class="wrap external" href="https://supermemo.guru/wiki/Retention" rel="nofollow noreferrer" target="_blank">保留率</a>是将最优过程中每天的保留率求平均值得到的</p><p>R=(R(1)+R(2)+...+R(n))/n</p><p>R(d)=100-2.5*Laps(d-dlr)</p><p>其中：</p><ul><li> R - 平均保留率</li><li> R(d) - 学习过程中第 d 天的保留率</li><li> Laps(Int) - 间隔 I 天后的期望遗忘数量</li><li> dlr - 最后一次重复的日期</li></ul><hr/><h2>工作量与保留率的权衡</h2><p>尽管模型使用了异质材料，有些不准确的地方，但对于<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>如何影响学习所需时间，也能可靠地得出结论。这些观察结果经受住了时间的考验：</p><hr/><p>档案警告：<a class="wrap external" href="https://supermemo.guru/wiki/Why_use_literal_archives%253F" rel="nofollow noreferrer" target="_blank">为什么使用文字档案？</a></p><p>这段文字是《<a class="wrap external" href="https://supermemo.guru/wiki/Optimization_of_learning" rel="nofollow noreferrer" target="_blank">优化学习</a>》 作者：<a class="wrap external" href="https://supermemo.guru/wiki/Piotr_Wozniak" rel="nofollow noreferrer" target="_blank">Piotr Wozniak</a> (1990) 的一部分</p><p>通过比较通过间歇学习模型计算的保留率和工作量数据，可以得出非常有趣的结论：</p><ul><li><a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">指数</a> - 遗忘指数（ <img alt="\mathrm{Laps_o}" eeimg="1" loading="lazy" src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BLaps_o%7D"/> *2.5）确定了时间最优学习的最优间隔，其中使用 IL 模型安排学习</li><li><a class="wrap external" href="https://supermemo.guru/wiki/Retention" rel="nofollow noreferrer" target="_blank">保留率</a> - 在给定<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>得到的总体保留率（在 10,000 天后计算）</li><li> 重复次数 - 在给定<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>下，在实验过程的前 10,000 天安排的重复次数，</li><li><a class="wrap external" href="https://supermemo.guru/wiki/Optimal_factor" rel="nofollow noreferrer" target="_blank">系数</a> - 最优系数的渐近值（取自该过程的第 10000 天）</li></ul><table><tbody><tr><th>指数</th><th>保留率</th><th>重复次数</th><th>系数</th></tr><tr><td>2.5</td><td>97.76</td><td>两天一次</td><td>1.0000</td></tr><tr><td>4.5</td><td>96.88</td><td>65</td><td>1.0300</td></tr><tr><td>5.0</td><td>96.64</td><td>30</td><td>1.1600</td></tr><tr><td>5.5</td><td>96.39</td><td>22</td><td>1.3000</td></tr><tr><td>6.25</td><td>96.01</td><td>17</td><td>1.4900</td></tr><tr><td>7.5</td><td>95.37</td><td>13</td><td>1.7700</td></tr><tr><td>10.0</td><td>94.10</td><td>10</td><td>2.1900</td></tr><tr><td>12.5</td><td>92.78</td><td>9</td><td>2.4700</td></tr></tbody></table><p>图 11.2 表明，用于确定最优间隔的<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>应落在 5-10% 的范围内。</p><figure><img class="origin_image zh-lightbox-thumb lazy" data-actualsrc="https://pic1.zhimg.com/v2-6900213aaa3c21d197501288c638902c_b.jpg" data-caption="" src="https://pic1.zhimg.com/v2-6900213aaa3c21d197501288c638902c_r.jpg" data-rawheight="1198" data-rawwidth="1096" data-size="normal" src="data:image/svg+xml;utf8,&lt;svg xmlns='http://www.w3.org/2000/svg' width='1096' height='1198'&gt;&lt;/svg&gt;" width="1096"/></figure><blockquote>图 11.2 工作量-保留率的权衡：一方面，如果<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>低于 5%，那么工作量就会急剧增加，而不会对保留率产生实质性影响。另一方面，如果<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>超过 10%，工作量几乎没有变化，而保留率却稳步下降。显然，工作量-保留率的权衡直接对应于习得率和保留率之间的妥协。通过增加时间的可用性 X 倍（通过减少工作量 X 倍），可以增加习得率 X 倍（比较<a class="wrap external" href="https://link.zhihu.com/?target=http%3A//super-memory.com/articles/theory.htm" rel="nofollow noreferrer" target="_blank">第 5 章</a>）。请注意，在这个模型中，<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>和<a class="wrap external" href="https://supermemo.guru/wiki/Retention" rel="nofollow noreferrer" target="_blank">保留率</a>的关系几乎是线性的。（来源：《<a class="wrap external" href="https://supermemo.guru/wiki/Optimization_of_learning" rel="nofollow noreferrer" target="_blank">学习优化</a>》：<a class="wrap external" href="https://supermemo.guru/wiki/Search_for_a_universal_memory_formula" rel="nofollow noreferrer" target="_blank">间歇学习模型</a>，<a class="wrap external" href="https://supermemo.guru/wiki/Piotr_Wozniak" rel="nofollow noreferrer" target="_blank">Piotr Wozniak</a>, 1990)</blockquote><p>另一重要观察来自使记忆强度增长最大化的<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>的计算过程</p><p>由间歇学习模型可得</p><p>S(n)=1.5*Laps(n)*S(n-1)*exp(-0.15*Laps(n))+1</p><p>对变量 Laps(n) 进行微分后，我们得到：</p><p>S'(n)=1.5*S(n-1)*exp(-0.15*Laps(n))*(1-0.15*Laps(n))</p><p>最后，令其等于  0，我们得到：</p><p>Laps(n)=7.8</p><p>这相当于<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>等于 20%！这样的遗忘指数得出的间隔，相当于遗忘指数等于 10% 确定的最优间隔的 2 倍（如<a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-5" rel="nofollow noreferrer" target="_blank">SM-5 算法</a>）。然而，别忘了，工作量的唯一权衡因素是知识保留率而不是记忆强度。因此，上述发现并没有令<a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-5" rel="nofollow noreferrer" target="_blank">SM-5 算法</a> 失效</p><hr/><h2>结论：间歇学习模型</h2><p>该章结尾处得出的最终结论经受住了三十年的考验。只有<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_curve" rel="nofollow noreferrer" target="_blank">遗忘曲线</a>是非指数形状的说法是不准确的。这是因为这个模型是基于各种性质不同数据建立的，<a class="wrap external" href="https://supermemo.guru/wiki/Exponential_nature_of_forgetting" rel="nofollow noreferrer" target="_blank">遗忘的指数性质</a>不可显现出来。</p><hr/><p>档案警告：<a class="wrap external" href="https://supermemo.guru/wiki/Why_use_literal_archives%253F" rel="nofollow noreferrer" target="_blank">为什么使用文字档案？</a></p><p>这段文字选自《<a class="wrap external" href="https://supermemo.guru/wiki/Optimization_of_learning" rel="nofollow noreferrer" target="_blank">优化学习</a>》，<a class="wrap external" href="https://supermemo.guru/wiki/Piotr_Wozniak" rel="nofollow noreferrer" target="_blank">Piotr Wozniak</a> (1990) 著</p><h3><b>临时摘要</b></h3><ul><li> 构建了间歇学习模型，从而能对于不同的重复计划估计其知识保留率</li><li> 该模型确凿地说明，<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_curve" rel="nofollow noreferrer" target="_blank">遗忘曲线</a>不是指数型的 [2018 评论：错误的结论：对比<a class="wrap external" href="https://supermemo.guru/wiki/Exponential_nature_of_forgetting" rel="nofollow noreferrer" target="_blank">遗忘的指数性质</a>]</li><li> 该模型与实验数据吻合良好</li><li> 该模型能以惊人精度求出最优间隔和知识保留率的近似值，而这两个变量是 SuperMemo 模型所隐含的。</li><li> 该模型表明，最优系数在随着重复减少，并渐进接近最终值</li><li> 该模型表明，最节省学习时间的<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>的理想值应落在 5% 至 10% 之间</li><li> 该模型表明，遗忘指数与知识保留率几乎呈线性关系</li><li> 该模型说明，当间隔比 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo 方法</a>中使用的间隔长约 2 倍时，记忆强度的增幅最大。这相当于遗忘指数等于 20%<br/> </li></ul><hr/><p>下一章：<a class="internal" href="https://zhuanlan.zhihu.com/p/441532847">08 1991：启用遗忘曲线</a></p></div>