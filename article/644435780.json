{
  "id": "644435780",
  "title": "对于卡片生成任务，大型语言模型（LLM）经常需要额外的提示，来确定从何种角度制卡",
  "type": "article",
  "article_type": "normal",
  "excerpt_title": "",
  "url": "https://api.zhihu.com/articles/644435780",
  "image_url": "",
  "title_image": "",
  "excerpt": "在 <a href=\"https://link.zhihu.com/?target=https%3A//notes.andymatuschak.org/z2DY7qsP5iHsiA5hxUHheV8hu7Xe96vdGyYX\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">使用机器学习从解释性文本中生成优质的间隔重复卡片</a>[1]时，仅给模型一个文本段落和高亮范围，往往无法达到理想效果。对于说明文的片段，其可供强化的视角十分丰富：可以是一个陈述性细节，可以是其真实性的原因，可以是其产生的影响，或者是与前文的对比…",
  "created": 1689730839,
  "updated": 1724732123,
  "author": {
    "is_followed": false,
    "avatar_url_template": "https://picx.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6.jpg?source=172ae18b",
    "uid": "1521893281407864832",
    "user_type": "people",
    "is_following": false,
    "url_token": "JarrettYe",
    "id": "3c9990a12cdbcd92e20b1387b160f0a3",
    "description": "Anki 高考践行者，教育英特纳雄耐尔一定会实现！\n我的个人主页：https://l-m-sherlock.github.io/",
    "name": "Jarrett Ye",
    "is_advertiser": false,
    "headline": "钻研人类记忆，探索复习算法。改善教育公平，践行自由学习。",
    "gender": 1,
    "url": "https://api.zhihu.com/people/3c9990a12cdbcd92e20b1387b160f0a3",
    "avatar_url": "https://picx.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6_l.jpg?source=172ae18b",
    "is_org": false,
    "type": "people",
    "badge": [],
    "badge_v2": {
      "title": "钻研人类记忆，探索复习算法。改善教育公平，践行自由学习。",
      "merged_badges": [],
      "detail_badges": [],
      "icon": "",
      "night_icon": ""
    },
    "exposed_medal": {
      "medal_id": "1463836052717301760",
      "medal_name": "知「势」之星",
      "avatar_url": "https://picx.zhimg.com/v2-e66f695db706a1c8c79b8097c1565da2_r.png?source=172ae18b",
      "mini_avatar_url": "https://picx.zhimg.com/v2-e66f695db706a1c8c79b8097c1565da2_l.png?source=172ae18b",
      "description": "「知势榜」上榜答主即可获得",
      "medal_avatar_frame": ""
    }
  },
  "comment_permission": "all",
  "copyright_permission": "need_review",
  "state": "published",
  "ip_info": "广东",
  "image_width": 0,
  "image_height": 0,
  "content": "<p data-pid=\"xGBWlUFj\">在<a href=\"https://link.zhihu.com/?target=https%3A//notes.andymatuschak.org/z2DY7qsP5iHsiA5hxUHheV8hu7Xe96vdGyYX\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">使用机器学习从解释性文本中生成优质的间隔重复卡片</a><sup data-text=\"使用机器学习从解释性文本中生成优质的间隔重复卡片\" data-url=\"https://zhuanlan.zhihu.com/p/716570823\" data-draft-node=\"inline\" data-draft-type=\"reference\" data-numero=\"1\">[1]</sup>时，仅给模型一个文本段落和高亮范围，往往无法达到理想效果。对于说明文的片段，其可供强化的视角十分丰富：可以是一个陈述性细节，可以是其真实性的原因，可以是其产生的影响，或者是与前文的对比等等。所有这些都可能写成不同的优质卡片，但模型并不知道你究竟想要哪一个（<a href=\"https://link.zhihu.com/?target=https%3A//notes.andymatuschak.org/z62s1nNLEfhGbDmpb8Z7dZiYyi3kaSziuLVXd\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">卡片生成任务中，选择要强化的目标概念，和为这些目标概念编写卡片，是两个独立的问题</a><sup data-text=\"卡片生成任务中，选择要强化的目标概念，和为这些目标概念编写卡片，是两个独立的问题\" data-url=\"https://zhuanlan.zhihu.com/p/656354899\" data-draft-node=\"inline\" data-draft-type=\"reference\" data-numero=\"2\">[2]</sup>）。</p><p data-pid=\"_iL5152k\">然而，如果我给模型提供一两个提示，指明我希望强调短语的哪个方面，我得到的结果通常会更好。在界面上，这可能看起来像是：高亮你认为重要的部分，然后在上面写上「为什么」。或者，给自己写一张小便签：「这比我想象的要高。」</p><p data-pid=\"fkNBv1ey\">比如说，阅读 Griffiths 的《量子力学导论》时，我对 <img src=\"https://www.zhihu.com/equation?tex=V\" alt=\"V\" eeimg=\"1\"/> 被用作势能的符号感到惊讶——因为我习惯于用 <img src=\"https://www.zhihu.com/equation?tex=U\" alt=\"U\" eeimg=\"1\"/> 。我想要一张关于这个的卡片。但是，如果我只是高亮「力可以表示为势能函数的导数，1 F = −∂V/∂x」这句话中的 <img src=\"https://www.zhihu.com/equation?tex=V\" alt=\"V\" eeimg=\"1\"/> ，我得到的是「力和守恒系统中的势能之间的关系是什么？」。这个结果并不令人意外。模型怎么会知道，我感到惊讶的是那个符号呢？相比之下，如果我要求模型强调「符号」，我得到的是「在经典力学的语境下，符号 V 代表什么？」</p><p data-pid=\"dk0ZFzKC\">到目前为止，我发现只有在强化简单的事实陈述时，才不需要提供额外的提示。（例如：「碳的原子序数是 6。」）</p><h3>个人联系；个人笔记</h3><p data-pid=\"B1m1pb8R\">这里的根本问题是，最好的卡片往往涉及使材料具有个人意义——将一些抽象信息连接到你的目标上，或者深入到一个你认为特别引人注意，但作者并未强调的细节或视角。模型并不能容易地知道这些事情。</p><p data-pid=\"E_sXUPB1\">一种可能会有所帮助的方法是，从针对某个文本的个人笔记中生成卡片。</p><h2>链接至本文（已汉化）</h2><ul><li data-pid=\"w6piuua2\"><a href=\"https://zhuanlan.zhihu.com/p/639267420\" class=\"internal\" target=\"_blank\">将基于机器学习的卡片生成重新定义为过滤问题，有助于我们思考吗？</a></li><li data-pid=\"b8g105HW\"><a href=\"https://zhuanlan.zhihu.com/p/645670312\" class=\"internal\" target=\"_blank\">对于卡片生成任务，如果提供了充足的上下文，大型语言模型（LLM）可能会表现得更好</a></li><li data-pid=\"ENBNBqP2\"><a href=\"https://zhuanlan.zhihu.com/p/656354899\" class=\"internal\" target=\"_blank\">对于卡片生成任务，选择要强化的目标概念，和为这些目标概念编写卡片，是两个独立的问题</a></li><li data-pid=\"jh6B6G64\"><a href=\"https://zhuanlan.zhihu.com/p/656355546\" class=\"internal\" target=\"_blank\">对于卡片生成任务，大型语言模型（LLM）缺乏为复杂概念材料编写卡片的模式</a></li><li data-pid=\"oQvybjBk\"><a href=\"https://zhuanlan.zhihu.com/p/639267420\" class=\"internal\" target=\"_blank\">将卡片生成任务定义为强化目标的过滤问题</a></li><li data-pid=\"oas2d3vS\"><a href=\"https://zhuanlan.zhihu.com/p/656760808\" class=\"internal\" target=\"_blank\">GPT-4 在指导下，通常能够从解释性文本中为陈述性知识生成可用的间隔重复卡片</a></li><li data-pid=\"6gvvYJuB\"><a href=\"https://zhuanlan.zhihu.com/p/716570823\" class=\"internal\" target=\"_blank\">叶峻峣：使用机器学习从解释性文本中生成优质的间隔重复卡片</a></li></ul><h2>声明</h2><p data-pid=\"a1kSLiu9\">此内容发布由 Andy Matuschak 许可。未经允许，不得转载或修改。保留所有权利。</p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote data-pid=\"iQ6O6irS\"><a href=\"https://link.zhihu.com/?target=http%3A//paratranz.cn/projects/3131\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Thoughts Memo</a> 汉化组译制<br/>感谢主要译者 GPT-4、校对 <span class=\"nolink\">Jarrett</span>Ye<br/>原文：<a href=\"https://link.zhihu.com/?target=https%3A//notes.andymatuschak.org/zomoPzCNzSi5GqtfTeVWgm7RjmiArjS8vvM5\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">In prompt generation, LLMs often need extra hints about what angle to reinforce (andymatuschak.org)</a></blockquote>",
  "content_need_truncated": false,
  "force_login_when_click_read_more": false,
  "admin_closed_comment": false,
  "topics": [
    {
      "url": "https://api.zhihu.com/topics/20660508",
      "type": "topic",
      "id": "20660508",
      "name": "LLM"
    },
    {
      "url": "https://api.zhihu.com/topics/21338969",
      "type": "topic",
      "id": "21338969",
      "name": "间隔重复"
    },
    {
      "url": "https://api.zhihu.com/topics/21535352",
      "type": "topic",
      "id": "21535352",
      "name": "抽认卡"
    }
  ],
  "voteup_count": 7,
  "voting": 0,
  "heavy_up_status": "allow_heavy_up",
  "column": {
    "description": "",
    "can_manage": true,
    "intro": "间隔重复使记忆成为一种选择",
    "is_following": false,
    "url_token": "c_1525782291741208576",
    "id": "c_1525782291741208576",
    "articles_count": 182,
    "accept_submission": true,
    "title": "间隔重复 & 注意力管理",
    "url": "https://api.zhihu.com/columns/c_1525782291741208576",
    "comment_permission": "all",
    "created": 1751877449,
    "updated": 1656554846,
    "image_url": "https://picx.zhimg.com/v2-5502ae7e1e498ae4ef9aa3edbca986e3_720w.jpg?source=172ae18b",
    "author": {
      "is_followed": false,
      "avatar_url_template": "https://pic1.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6.jpg?source=172ae18b",
      "uid": "1521893281407864832",
      "user_type": "people",
      "is_following": false,
      "url_token": "JarrettYe",
      "id": "3c9990a12cdbcd92e20b1387b160f0a3",
      "description": "Anki 高考践行者，教育英特纳雄耐尔一定会实现！\n我的个人主页：https://l-m-sherlock.github.io/",
      "name": "Jarrett Ye",
      "is_advertiser": false,
      "headline": "钻研人类记忆，探索复习算法。改善教育公平，践行自由学习。",
      "gender": 1,
      "url": "https://api.zhihu.com/people/3c9990a12cdbcd92e20b1387b160f0a3",
      "avatar_url": "https://picx.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6_l.jpg?source=172ae18b",
      "is_org": false,
      "type": "people",
      "badge_v2": {
        "title": "",
        "merged_badges": [],
        "detail_badges": [],
        "icon": "",
        "night_icon": ""
      }
    },
    "followers": 227,
    "type": "column",
    "column_type": "normal"
  },
  "comment_count": 2,
  "contributions": [
    {
      "id": 45954480,
      "state": "accepted",
      "type": "first_publish",
      "column": {
        "description": "",
        "can_manage": true,
        "intro": "间隔重复使记忆成为一种选择",
        "is_following": false,
        "url_token": "c_1525782291741208576",
        "id": "c_1525782291741208576",
        "articles_count": 182,
        "accept_submission": true,
        "title": "间隔重复 & 注意力管理",
        "url": "https://api.zhihu.com/columns/c_1525782291741208576",
        "comment_permission": "all",
        "created": 1751877449,
        "updated": 1656554846,
        "image_url": "https://picx.zhimg.com/v2-5502ae7e1e498ae4ef9aa3edbca986e3_720w.jpg?source=172ae18b",
        "author": {
          "is_followed": false,
          "avatar_url_template": "https://pic1.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6.jpg?source=172ae18b",
          "uid": "1521893281407864832",
          "user_type": "people",
          "is_following": false,
          "url_token": "JarrettYe",
          "id": "3c9990a12cdbcd92e20b1387b160f0a3",
          "description": "Anki 高考践行者，教育英特纳雄耐尔一定会实现！\n我的个人主页：https://l-m-sherlock.github.io/",
          "name": "Jarrett Ye",
          "is_advertiser": false,
          "headline": "钻研人类记忆，探索复习算法。改善教育公平，践行自由学习。",
          "gender": 1,
          "url": "https://api.zhihu.com/people/3c9990a12cdbcd92e20b1387b160f0a3",
          "avatar_url": "https://picx.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6_l.jpg?source=172ae18b",
          "is_org": false,
          "type": "people",
          "badge_v2": {
            "title": "",
            "merged_badges": [],
            "detail_badges": [],
            "icon": "",
            "night_icon": ""
          }
        },
        "followers": 227,
        "type": "column",
        "column_type": "normal"
      }
    }
  ],
  "is_title_image_full_screen": false,
  "upvoted_followees": [],
  "commercial_info": {
    "is_commercial": false,
    "plugin": {}
  },
  "suggest_edit": {
    "status": false,
    "reason": "",
    "tip": "",
    "url": "",
    "title": ""
  },
  "reason": "",
  "annotation_action": [],
  "can_tip": false,
  "can_open_tipjar": true,
  "tipjarors_count": 0,
  "is_labeled": false,
  "has_publishing_draft": false,
  "is_favorited": false,
  "favlists_count": 2,
  "is_normal": true,
  "status": 0,
  "activity_topping_info": {
    "state": "untopped"
  },
  "share_text": "对于卡片生成任务，大型语言模型（LLM）经常需要额外的提示，来确定从何种角度制卡 - 来自知乎专栏「间隔重复 &amp; 注意力管理」，作者: Jarrett Ye https://zhuanlan.zhihu.com/p/644435780 （想看更多？下载 @知乎 App：http://weibo.com/p/100404711598 ）",
  "can_comment": {
    "status": true,
    "reason": ""
  },
  "linkbox": {
    "url": "",
    "category": "",
    "pic": "",
    "title": ""
  },
  "mcn_fp_show": -1,
  "is_visible": true,
  "is_liked": false,
  "liked_count": 2,
  "has_column": true,
  "republishers": [],
  "is_new_link_card": true,
  "emoji_reaction": {
    "like_count": 2,
    "like_has_set": false
  },
  "ab_param": {
    "qa_hidden_voteup": "",
    "rs_interest1": "",
    "zp_zhi_style": ""
  },
  "attached_info": "kgIkCgkyMzEzMzg2NzESCTY0NDQzNTc4MBgHIgpJTUFHRV9URVhU",
  "share_guide": {
    "has_positive_bubble": false,
    "has_time_bubble": false,
    "hit_share_guide_cluster": false
  },
  "settings": {
    "table_of_contents": {
      "enabled": false
    }
  },
  "can_reference": false,
  "reaction_instruction": {},
  "reaction": {
    "statistics": {
      "up_vote_count": 7,
      "down_vote_count": 0,
      "like_count": 2,
      "comment_count": 2,
      "share_count": 0,
      "play_count": 0,
      "interest_play_count": 0,
      "favorites": 2,
      "pv_count": 0,
      "bullet_count": 0,
      "applaud_count": 0,
      "question_follower_count": 0,
      "question_answer_count": 0,
      "plaincontent_vote_up_count": 0,
      "plaincontent_like_count": 0,
      "subscribe_count": 0,
      "republishers": []
    },
    "relation": {
      "is_author": true,
      "vote": "Neutral",
      "liked": false,
      "faved": false,
      "following": false,
      "subcribed": false,
      "is_navigator_vote": false,
      "current_user_is_navigator": false,
      "vote_next_step": ""
    },
    "image_reactions": {}
  },
  "interaction_bar_plugins": [
    {
      "type": "comment",
      "comment": {
        "enable": true,
        "placeholder": "发条带图评论"
      }
    }
  ],
  "bar_plugins_flip_time": 3000,
  "podcast_audio_enter": {
    "text": "听内容",
    "text_color": "MapBrand",
    "text_size": 13,
    "action_url": "zhihu://podcast/audio_player/0?contentId=644435780&contentType=article"
  },
  "endorsements": [
    {
      "elements": [
        {
          "type": "IMAGE",
          "image_key": "zhicon_icon_24_column_fill",
          "image_color": {
            "alpha": 1,
            "group": "GBL01A"
          },
          "width": 16,
          "height": 16
        },
        {
          "type": "TEXT",
          "content": "收录于 · 间隔重复 & 注意力管理",
          "font_size": 13,
          "font_color": {
            "alpha": 1,
            "group": "GBL01A"
          },
          "is_bold": false,
          "max_line": 1
        },
        {
          "type": "IMAGE",
          "image_key": "zhicon_icon_16_arrow_right",
          "image_color": {
            "alpha": 1,
            "group": "GBL01A"
          },
          "width": 12,
          "height": 12
        }
      ],
      "sub_elements": [],
      "sub_elements_type": "DESCRIPTION",
      "background_color": {
        "alpha": 0.08,
        "group": "GBL01A"
      },
      "action_url": "https://www.zhihu.com/column/c_1525782291741208576",
      "za": {
        "block_text": "Column",
        "type": "text",
        "text": "收录于 · 间隔重复 & 注意力管理"
      }
    }
  ],
  "allow_segment_interaction": 1,
  "is_navigator": false,
  "navigator_vote": false,
  "vote_next_step": "vote"
}