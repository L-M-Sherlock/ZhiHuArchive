{
  "id": "645670312",
  "title": "对于卡片生成任务，如果提供了充足的上下文，大型语言模型（LLM）可能会表现得更好",
  "type": "article",
  "article_type": "normal",
  "excerpt_title": "",
  "url": "https://api.zhihu.com/articles/645670312",
  "image_url": "",
  "title_image": "",
  "excerpt": "许多人试图创建系统， <a href=\"https://link.zhihu.com/?target=https%3A//notes.andymatuschak.org/z2DY7qsP5iHsiA5hxUHheV8hu7Xe96vdGyYX\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">使用机器学习从解释性文本中为简单的陈述性知识生成优质的间隔重复卡片</a>[1]，这些系统往往会对高亮内容进行处理。你选择一段文字，然后让模型根据所选的内容生成卡片。但是，除非所选的内容是一个孤立的、明确的陈述，否则模型通常需要…",
  "created": 1690213571,
  "updated": 1724732122,
  "author": {
    "is_followed": false,
    "avatar_url_template": "https://picx.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6.jpg?source=172ae18b",
    "uid": "1521893281407864832",
    "user_type": "people",
    "is_following": false,
    "url_token": "JarrettYe",
    "id": "3c9990a12cdbcd92e20b1387b160f0a3",
    "description": "Anki 高考践行者，教育英特纳雄耐尔一定会实现！\n我的个人主页：https://l-m-sherlock.github.io/",
    "name": "Jarrett Ye",
    "is_advertiser": false,
    "headline": "钻研人类记忆，探索复习算法。改善教育公平，践行自由学习。",
    "gender": 1,
    "url": "https://api.zhihu.com/people/3c9990a12cdbcd92e20b1387b160f0a3",
    "avatar_url": "https://pica.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6_l.jpg?source=172ae18b",
    "is_org": false,
    "type": "people",
    "badge": [],
    "badge_v2": {
      "title": "钻研人类记忆，探索复习算法。改善教育公平，践行自由学习。",
      "merged_badges": [],
      "detail_badges": [],
      "icon": "",
      "night_icon": ""
    },
    "exposed_medal": {
      "medal_id": "1463836052717301760",
      "medal_name": "知「势」之星",
      "avatar_url": "https://picx.zhimg.com/v2-e66f695db706a1c8c79b8097c1565da2_r.png?source=172ae18b",
      "mini_avatar_url": "https://picx.zhimg.com/v2-e66f695db706a1c8c79b8097c1565da2_l.png?source=172ae18b",
      "description": "「知势榜」上榜答主即可获得",
      "medal_avatar_frame": ""
    }
  },
  "comment_permission": "all",
  "copyright_permission": "need_review",
  "state": "published",
  "ip_info": "广东",
  "image_width": 0,
  "image_height": 0,
  "content": "<p data-pid=\"hg3y7MF7\">许多人试图创建系统，<a href=\"https://link.zhihu.com/?target=https%3A//notes.andymatuschak.org/z2DY7qsP5iHsiA5hxUHheV8hu7Xe96vdGyYX\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">使用机器学习从解释性文本中为简单的陈述性知识生成优质的间隔重复卡片</a><sup data-text=\"使用机器学习从解释性文本中生成优质的间隔重复卡片\" data-url=\"https://zhuanlan.zhihu.com/p/716570823\" data-draft-node=\"inline\" data-draft-type=\"reference\" data-numero=\"1\">[1]</sup>，这些系统往往会对高亮内容进行处理。你选择一段文字，然后让模型根据所选的内容生成卡片。但是，除非所选的内容是一个孤立的、明确的陈述，否则模型通常需要更多的上下文来理解如何生成优质卡片。比如，你如果从教科书中选择了一句话，模型就需要对教科书的层次、已经介绍过的内容，以及观点的框架等方面有所了解。为此，我发现在目标文本周围提供几千个上下文相关的词元往往会有所帮助。</p><p data-pid=\"AsH9iVAd\">从某种角度来看，这样的上下文信息就像是在告诉模型，什么样的卡片才符合用户的需求；这也和另一种观点相吻合<a href=\"https://link.zhihu.com/?target=https%3A//notes.andymatuschak.org/zomoPzCNzSi5GqtfTeVWgm7RjmiArjS8vvM5\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">对于卡片生成任务，大型语言模型（LLM）经常需要额外的提示来确定需要强化何种角度</a><sup data-text=\"对于卡片生成任务，大型语言模型（LLM）经常需要额外的提示来确定强化的视角\" data-url=\"https://zhuanlan.zhihu.com/p/644435780\" data-draft-node=\"inline\" data-draft-type=\"reference\" data-numero=\"2\">[2]</sup>。</p><h2>实例</h2><p data-pid=\"H-euSXPh\">&lt;context&gt;设想一个质量为 <img src=\"https://www.zhihu.com/equation?tex=m\" alt=\"m\" eeimg=\"1\"/> 的粒子，被限定在 <img src=\"https://www.zhihu.com/equation?tex=x\" alt=\"x\" eeimg=\"1\"/> 轴上运动，同时受到某个特定的力 <img src=\"https://www.zhihu.com/equation?tex=F%28x%2C+t%29\" alt=\"F(x, t)\" eeimg=\"1\"/> 作用（参见图 1.1）。经典力学的主要任务，就是求出粒子在任何特定时间的位置： <img src=\"https://www.zhihu.com/equation?tex=x%28t%29\" alt=\"x(t)\" eeimg=\"1\"/> 。一旦我们得知了这个，我们就能算出速度（ <img src=\"https://www.zhihu.com/equation?tex=v%3Dd+x+%2F+d+t\" alt=\"v=d x / d t\" eeimg=\"1\"/> ）、动量（ <img src=\"https://www.zhihu.com/equation?tex=p%3Dm+v\" alt=\"p=m v\" eeimg=\"1\"/> ）、动能（ <img src=\"https://www.zhihu.com/equation?tex=T%3D%281+%2F+2%29+m+v%5E2\" alt=\"T=(1 / 2) m v^2\" eeimg=\"1\"/> ）或者其它我们感兴趣的动力学变量。我们如何求出 <img src=\"https://www.zhihu.com/equation?tex=x%28t%29\" alt=\"x(t)\" eeimg=\"1\"/> 呢？我们应用牛顿第二定律： <img src=\"https://www.zhihu.com/equation?tex=F%3Dm+a\" alt=\"F=m a\" eeimg=\"1\"/> 。（对于保守系统——也就是我们只会考虑的那种，幸运的是，它们也是在微观层面上唯一存在的类型，力可以表达为势能函数的导数，也就是 <img src=\"https://www.zhihu.com/equation?tex=%7B+%7D%5E1+F%3D-%5Cpartial+V+%2F+%5Cpartial+x\" alt=\"{ }^1 F=-\\partial V / \\partial x\" eeimg=\"1\"/> ，于是牛顿定律就变成了 <img src=\"https://www.zhihu.com/equation?tex=m+d%5E2+x+%2F+d+t%5E2%3D-%5Cpartial+V+%2F+%5Cpartial+x\" alt=\"m d^2 x / d t^2=-\\partial V / \\partial x\" eeimg=\"1\"/> 。）这个结论，再配合适当的初始条件（通常是在 <img src=\"https://www.zhihu.com/equation?tex=t%3D0\" alt=\"t=0\" eeimg=\"1\"/> 时的位置和速度），就能确定 <img src=\"https://www.zhihu.com/equation?tex=x%28t%29\" alt=\"x(t)\" eeimg=\"1\"/> </p><p data-pid=\"i4aRxU64\">而量子力学处理同一问题的方式截然不同。在这种情况下，我们要找的是粒子的波函数， <img src=\"https://www.zhihu.com/equation?tex=%5CPsi%28x%2C+t%29\" alt=\"\\Psi(x, t)\" eeimg=\"1\"/> ，我们通过求解薛定谔方程得到它：</p><p data-pid=\"4DSOQS33\"><img src=\"https://www.zhihu.com/equation?tex=+i+%5Chbar+%5Cfrac%7B%5Cpartial+%5CPsi%7D%7B%5Cpartial+t%7D%3D-%5Cfrac%7B%5Chbar%5E2%7D%7B2+m%7D+%5Cfrac%7B%5Cpartial%5E2+%5CPsi%7D%7B%5Cpartial+x%5E2%7D%2BV+%5CPsi+\" alt=\" i \\hbar \\frac{\\partial \\Psi}{\\partial t}=-\\frac{\\hbar^2}{2 m} \\frac{\\partial^2 \\Psi}{\\partial x^2}+V \\Psi \" eeimg=\"1\"/> </p><p data-pid=\"l1MgQYn7\">其中， <img src=\"https://www.zhihu.com/equation?tex=i\" alt=\"i\" eeimg=\"1\"/> 是 -1 的平方根， <img src=\"https://www.zhihu.com/equation?tex=%5Chbar\" alt=\"\\hbar\" eeimg=\"1\"/> 是普朗克常数，或者更确切地说，是他的原始常数（ <img src=\"https://www.zhihu.com/equation?tex=h\" alt=\"h\" eeimg=\"1\"/> ）除以 <img src=\"https://www.zhihu.com/equation?tex=2+%5Cpi\" alt=\"2 \\pi\" eeimg=\"1\"/> ：</p><p data-pid=\"_gK-AVpK\"><img src=\"https://www.zhihu.com/equation?tex=+%5Chbar%3D%5Cfrac%7Bh%7D%7B2+%5Cpi%7D%3D1.054573+%5Ctimes+10%5E%7B-34%7D+%5Cmathrm%7B~J%7D+%5Cmathrm%7B~s%7D+\" alt=\" \\hbar=\\frac{h}{2 \\pi}=1.054573 \\times 10^{-34} \\mathrm{~J} \\mathrm{~s} \" eeimg=\"1\"/> </p><p data-pid=\"TtpC4RKW\">薛定谔方程在逻辑上与牛顿第二定律的作用相似：给定适当的初始条件（通常是 <img src=\"https://www.zhihu.com/equation?tex=%5CPsi%28x%2C+0%29\" alt=\"\\Psi(x, 0)\" eeimg=\"1\"/> ），薛定谔方程就能确定未来所有时间的 <img src=\"https://www.zhihu.com/equation?tex=%5CPsi%28x%2C+t%29\" alt=\"\\Psi(x, t)\" eeimg=\"1\"/> ，就像在经典力学中，牛顿定律决定了未来所有时间的 <img src=\"https://www.zhihu.com/equation?tex=x%28t%29\" alt=\"x(t)\" eeimg=\"1\"/> 。 <img src=\"https://www.zhihu.com/equation?tex=%5E2\" alt=\"^2\" eeimg=\"1\"/> &lt;/context&gt;</p><p data-pid=\"8L-9boIG\">&lt;target&gt;薛定谔方程在逻辑上与牛顿第二定律的作用相似&lt;/target&gt;</p><p data-pid=\"kTPOO7FF\">&lt;hint&gt;怎样&lt;/hint&gt;</p><p data-pid=\"FiwO2UWH\">有&lt;context&gt;：「<b>问题</b>：薛定谔方程在力学中作用，和牛顿第二定律有何相似之处？<b>答案</b>：只要有合适的初始条件，两者都可以确定系统在任何时间点的状态。」</p><p data-pid=\"guDOhVtE\">没有：「薛定谔方程如何与牛顿第二定律相似呢？<b>答案</b>：薛定谔方程描述了量子状态随环境的演变，就如同牛顿第二定律描述了物体受力后的加速度变化。」</p><p data-pid=\"YMOLaW2J\">前者更贴近原文的语境。</p><h2><br/>链接至本文（已汉化）</h2><ul><li data-pid=\"2c7QS6xy\"><a href=\"https://zhuanlan.zhihu.com/p/656760808\" class=\"internal\" target=\"_blank\">GPT-4 在指导下，通常能够从解释性文本中为陈述性知识生成可用的间隔重复卡片</a></li><li data-pid=\"k0BwCBN_\"><a href=\"https://zhuanlan.zhihu.com/p/716570823\" class=\"internal\" target=\"_blank\">叶峻峣：使用机器学习从解释性文本中生成优质的间隔重复卡片</a></li></ul><h2>声明</h2><p data-pid=\"a1kSLiu9\">此内容发布由 Andy Matuschak 许可。未经允许，不得转载或修改。保留所有权利。</p><p class=\"ztext-empty-paragraph\"><br/></p><blockquote data-pid=\"Uy-oUh0g\"><a href=\"https://link.zhihu.com/?target=http%3A//paratranz.cn/projects/3131\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Thoughts Memo</a> 汉化组译制<br/>感谢主要译者 GPT-4、校对 <span class=\"nolink\">Jarrett</span>Ye<br/>原文：<a href=\"https://link.zhihu.com/?target=https%3A//notes.andymatuschak.org/z5LQFLXHFLrb4nYAtLrB3JBzNyJng8fYHVJYN\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">In prompt generation, LLMs may perform better with ample context (andymatuschak.org)</a></blockquote>",
  "content_need_truncated": false,
  "force_login_when_click_read_more": false,
  "admin_closed_comment": false,
  "topics": [
    {
      "url": "https://api.zhihu.com/topics/27267395",
      "type": "topic",
      "id": "27267395",
      "name": "大语言模型"
    },
    {
      "url": "https://api.zhihu.com/topics/21338969",
      "type": "topic",
      "id": "21338969",
      "name": "间隔重复"
    },
    {
      "url": "https://api.zhihu.com/topics/21535352",
      "type": "topic",
      "id": "21535352",
      "name": "抽认卡"
    }
  ],
  "voteup_count": 6,
  "voting": 0,
  "heavy_up_status": "allow_heavy_up",
  "column": {
    "description": "",
    "can_manage": true,
    "intro": "间隔重复使记忆成为一种选择",
    "is_following": false,
    "url_token": "c_1525782291741208576",
    "id": "c_1525782291741208576",
    "articles_count": 182,
    "accept_submission": true,
    "title": "间隔重复 & 注意力管理",
    "url": "https://api.zhihu.com/columns/c_1525782291741208576",
    "comment_permission": "all",
    "created": 1751877449,
    "updated": 1656554846,
    "image_url": "https://picx.zhimg.com/v2-5502ae7e1e498ae4ef9aa3edbca986e3_720w.jpg?source=172ae18b",
    "author": {
      "is_followed": false,
      "avatar_url_template": "https://picx.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6.jpg?source=172ae18b",
      "uid": "1521893281407864832",
      "user_type": "people",
      "is_following": false,
      "url_token": "JarrettYe",
      "id": "3c9990a12cdbcd92e20b1387b160f0a3",
      "description": "Anki 高考践行者，教育英特纳雄耐尔一定会实现！\n我的个人主页：https://l-m-sherlock.github.io/",
      "name": "Jarrett Ye",
      "is_advertiser": false,
      "headline": "钻研人类记忆，探索复习算法。改善教育公平，践行自由学习。",
      "gender": 1,
      "url": "https://api.zhihu.com/people/3c9990a12cdbcd92e20b1387b160f0a3",
      "avatar_url": "https://picx.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6_l.jpg?source=172ae18b",
      "is_org": false,
      "type": "people",
      "badge_v2": {
        "title": "",
        "merged_badges": [],
        "detail_badges": [],
        "icon": "",
        "night_icon": ""
      }
    },
    "followers": 227,
    "type": "column",
    "column_type": "normal"
  },
  "comment_count": 0,
  "contributions": [
    {
      "id": 46009599,
      "state": "accepted",
      "type": "first_publish",
      "column": {
        "description": "",
        "can_manage": true,
        "intro": "间隔重复使记忆成为一种选择",
        "is_following": false,
        "url_token": "c_1525782291741208576",
        "id": "c_1525782291741208576",
        "articles_count": 182,
        "accept_submission": true,
        "title": "间隔重复 & 注意力管理",
        "url": "https://api.zhihu.com/columns/c_1525782291741208576",
        "comment_permission": "all",
        "created": 1751877449,
        "updated": 1656554846,
        "image_url": "https://picx.zhimg.com/v2-5502ae7e1e498ae4ef9aa3edbca986e3_720w.jpg?source=172ae18b",
        "author": {
          "is_followed": false,
          "avatar_url_template": "https://picx.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6.jpg?source=172ae18b",
          "uid": "1521893281407864832",
          "user_type": "people",
          "is_following": false,
          "url_token": "JarrettYe",
          "id": "3c9990a12cdbcd92e20b1387b160f0a3",
          "description": "Anki 高考践行者，教育英特纳雄耐尔一定会实现！\n我的个人主页：https://l-m-sherlock.github.io/",
          "name": "Jarrett Ye",
          "is_advertiser": false,
          "headline": "钻研人类记忆，探索复习算法。改善教育公平，践行自由学习。",
          "gender": 1,
          "url": "https://api.zhihu.com/people/3c9990a12cdbcd92e20b1387b160f0a3",
          "avatar_url": "https://picx.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6_l.jpg?source=172ae18b",
          "is_org": false,
          "type": "people",
          "badge_v2": {
            "title": "",
            "merged_badges": [],
            "detail_badges": [],
            "icon": "",
            "night_icon": ""
          }
        },
        "followers": 227,
        "type": "column",
        "column_type": "normal"
      }
    }
  ],
  "is_title_image_full_screen": false,
  "upvoted_followees": [],
  "commercial_info": {
    "is_commercial": false,
    "plugin": {}
  },
  "suggest_edit": {
    "status": false,
    "reason": "",
    "tip": "",
    "url": "",
    "title": ""
  },
  "reason": "",
  "annotation_action": [],
  "can_tip": false,
  "can_open_tipjar": true,
  "tipjarors_count": 0,
  "is_labeled": false,
  "has_publishing_draft": false,
  "is_favorited": false,
  "favlists_count": 1,
  "is_normal": true,
  "status": 0,
  "activity_topping_info": {
    "state": "untopped"
  },
  "share_text": "对于卡片生成任务，如果提供了充足的上下文，大型语言模型（LLM）可能会表现得更好 - 来自知乎专栏「间隔重复 &amp; 注意力管理」，作者: Jarrett Ye https://zhuanlan.zhihu.com/p/645670312 （想看更多？下载 @知乎 App：http://weibo.com/p/100404711598 ）",
  "can_comment": {
    "status": true,
    "reason": ""
  },
  "linkbox": {
    "url": "",
    "category": "",
    "pic": "",
    "title": ""
  },
  "mcn_fp_show": -1,
  "is_visible": true,
  "is_liked": false,
  "liked_count": 3,
  "has_column": true,
  "republishers": [],
  "is_new_link_card": true,
  "emoji_reaction": {
    "like_count": 3,
    "like_has_set": false
  },
  "ab_param": {
    "qa_hidden_voteup": "",
    "rs_interest1": "",
    "zp_zhi_style": ""
  },
  "attached_info": "kgIkCgkyMzE2MTI4MjASCTY0NTY3MDMxMhgHIgpJTUFHRV9URVhU",
  "share_guide": {
    "has_positive_bubble": false,
    "has_time_bubble": false,
    "hit_share_guide_cluster": false
  },
  "settings": {
    "table_of_contents": {
      "enabled": false
    }
  },
  "can_reference": false,
  "reaction_instruction": {},
  "reaction": {
    "statistics": {
      "up_vote_count": 6,
      "down_vote_count": 0,
      "like_count": 3,
      "comment_count": 0,
      "share_count": 0,
      "play_count": 0,
      "interest_play_count": 0,
      "favorites": 1,
      "pv_count": 0,
      "bullet_count": 0,
      "applaud_count": 0,
      "question_follower_count": 0,
      "question_answer_count": 0,
      "plaincontent_vote_up_count": 0,
      "plaincontent_like_count": 0,
      "subscribe_count": 0,
      "republishers": []
    },
    "relation": {
      "is_author": true,
      "vote": "Neutral",
      "liked": false,
      "faved": false,
      "following": false,
      "subcribed": false,
      "is_navigator_vote": false,
      "current_user_is_navigator": false,
      "vote_next_step": ""
    },
    "image_reactions": {}
  },
  "interaction_bar_plugins": [
    {
      "type": "comment",
      "comment": {
        "enable": true,
        "placeholder": "发条带图评论"
      }
    }
  ],
  "bar_plugins_flip_time": 3000,
  "podcast_audio_enter": {
    "text": "听内容",
    "text_color": "MapBrand",
    "text_size": 13,
    "action_url": "zhihu://podcast/audio_player/0?contentId=645670312&contentType=article"
  },
  "endorsements": [
    {
      "elements": [
        {
          "type": "IMAGE",
          "image_key": "zhicon_icon_24_column_fill",
          "image_color": {
            "alpha": 1,
            "group": "GBL01A"
          },
          "width": 16,
          "height": 16
        },
        {
          "type": "TEXT",
          "content": "收录于 · 间隔重复 & 注意力管理",
          "font_size": 13,
          "font_color": {
            "alpha": 1,
            "group": "GBL01A"
          },
          "is_bold": false,
          "max_line": 1
        },
        {
          "type": "IMAGE",
          "image_key": "zhicon_icon_16_arrow_right",
          "image_color": {
            "alpha": 1,
            "group": "GBL01A"
          },
          "width": 12,
          "height": 12
        }
      ],
      "sub_elements": [],
      "sub_elements_type": "DESCRIPTION",
      "background_color": {
        "alpha": 0.08,
        "group": "GBL01A"
      },
      "action_url": "https://www.zhihu.com/column/c_1525782291741208576",
      "za": {
        "block_text": "Column",
        "type": "text",
        "text": "收录于 · 间隔重复 & 注意力管理"
      }
    }
  ],
  "allow_segment_interaction": 1,
  "is_navigator": false,
  "navigator_vote": false,
  "vote_next_step": "vote"
}