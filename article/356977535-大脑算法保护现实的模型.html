大脑算法保护现实的模型
<p>原文：<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Brain_algorithms_protect_models_of_reality" class=" wrap external" target="_blank" rel="nofollow noreferrer">Brain algorithms protect models of reality - supermemo.guru</a></p><h3><b>Modelling reality</b></h3><h3><b>模拟现实</b></h3><p>Human brain has an immense power to spawn and protect <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Coherence" class=" wrap external" target="_blank" rel="nofollow noreferrer">coherent</a> <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Abstract_knowledge" class=" wrap external" target="_blank" rel="nofollow noreferrer">models of reality</a>. All our behavior is determined by this abstract <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Generalization" class=" wrap external" target="_blank" rel="nofollow noreferrer">generalization</a> rather than by the actual reality. At any given moment, our overall <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Model" class=" wrap external" target="_blank" rel="nofollow noreferrer">model</a> of reality is confronted with sensory input data, and the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Conceptual_computation" class=" wrap external" target="_blank" rel="nofollow noreferrer">map of activations in the brain</a>. The activations and sensory data are integrated using the model of reality to determine the next decision or the next action.</p><p>人类的大脑拥有巨大的力量，可以催生和保护现实的连贯模型。我们所有的行为都是由这种抽象的泛化而非实际的现实所决定的。在任何特定的时刻，我们的整体现实模型都会面对感官输入数据，以及大脑中的激活图。激活和感觉数据利用现实模型进行整合，以决定下一个决策或下一个行动。</p><p>To ensure efficient function of the brain and the body, the model of reality should be <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Coherence" class=" wrap external" target="_blank" rel="nofollow noreferrer">coherent</a> and <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Consistency" class=" wrap external" target="_blank" rel="nofollow noreferrer">consistent</a>. It is also helpful if it correctly reflects the reality. Incorrect modeling leads to errors, incl. death. A child may believe it can outrun a train. This may provoke risky behaviors. This may also lead to a prompt correction of the error in the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Model" class=" wrap external" target="_blank" rel="nofollow noreferrer">model</a>.</p><p>为了保证大脑和身体的有效功能，现实模型应该是连贯的、一致的。如果它能正确地反映现实，也是有帮助的。不正确的模型会导致错误，包括死亡。一个孩子可能会相信自己能跑得过火车。这可能会引发危险的行为。这也可能导致及时纠正模型中的错误。</p><h3><b>Two layers of model protection</b></h3><h3><b>保护模型的两个层面</b></h3><p>We have evolved a number of imprinted algorithms for protecting models stored in memory. Those mechanisms work at the neural level (e.g. confirmation bias), and at the social level (e.g. <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Education_counteracts_evolution" class=" wrap external" target="_blank" rel="nofollow noreferrer">resistance</a> in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Coercive_learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">coercive learning</a>). A common myth says that those protections are based on faulty algorithms. Cognitive biases, incl. the confirmation bias are considered errors of the mind. In reality, protection of models leads to <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Diversity" class=" wrap external" target="_blank" rel="nofollow noreferrer">diversity</a> of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Model" class=" wrap external" target="_blank" rel="nofollow noreferrer">models</a> in a population, which leads to a competition between models, and the evolution of models. The <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Crystallization_of_knowledge" class=" wrap external" target="_blank" rel="nofollow noreferrer">crystallization of collective knowledge</a> undergoes processes that are very similar to those that happen in individual brains (<a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/War_of_the_networks" class=" wrap external" target="_blank" rel="nofollow noreferrer">competition</a>, <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Interference" class=" wrap external" target="_blank" rel="nofollow noreferrer">interference</a>, <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Forgetting" class=" wrap external" target="_blank" rel="nofollow noreferrer">forgetting</a>, revaluation, crystallization, <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Stabilization" class=" wrap external" target="_blank" rel="nofollow noreferrer">stabilization</a>, etc.). The entire evolutionary process underlies human collective <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Intelligence" class=" wrap external" target="_blank" rel="nofollow noreferrer">intelligence</a>, and the progress of mankind.</p><p>我们已经演化出了一些保护存储在记忆中的模型的预置算法。这些机制在神经层面（如确认偏误）和社会层面（如强制学习中的抵抗）发挥作用。一个常见的迷思说，这些保护是基于错误的算法。认知偏误，包括确认偏误被认为是心灵的错误。实际上，对模型的保护会导致一个群体中模型的多样性，从而导致模型之间的竞争，以及模型的进化。集体知识的结晶经历了与个体大脑中发生的过程非常相似的过程（竞争、干扰、遗忘、重估、结晶、稳定等）。整个进化过程是人类集体智慧的基础，也是人类进步的基础。</p><p>The two essential layers of model protection ensure model stability:</p><ul><li><b>brain level</b>: <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Generalization" class=" wrap external" target="_blank" rel="nofollow noreferrer">generalization</a> is an inherent property of neural networks. We build models that tend to reject <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Consistency" class=" wrap external" target="_blank" rel="nofollow noreferrer">inconsistent information</a>. This result is a healthy phenomenon known as the confirmation bias</li><li><b>social level</b>: social interaction tends to stabilize in one of the two extreme states: either (1) the meeting of minds (to confirm models) or (2) intellectual combat (which favors collecting evidence to confirm models)</li></ul><p>模型保护的两个基本层保证了模型的稳定性：</p><ul><li>大脑层面：泛化是神经网络的固有属性。我们建立的模型倾向于拒绝不一致的信息。这种结果是一种健康的现象，称为确认偏误</li><li>社会层面：社会互动往往稳定在两种极端状态中的一种：（1）思想的交锋（确认模型）或（2）智力的较量（有利于收集证据确认模型）。</li></ul><p><a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Generalization" class=" wrap external" target="_blank" rel="nofollow noreferrer">Generalization</a> can be faulty, but it improves <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Fast_thinking" class=" wrap external" target="_blank" rel="nofollow noreferrer">fast thinking</a> and makes further generalizations easy. Bistable interaction between models at the social level, leads to tribalism (formation of clans and coalitions), accelerates generalization, favors <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Memory_coherence" class=" wrap external" target="_blank" rel="nofollow noreferrer">coherent</a> learning, and contributes to a clash of models that may, in extreme cases, lead to revaluation. In matters of high weight, on rare occasions, people change their minds under the pressure of the overwhelming evidence to the contrary.</p><p>泛化可能是错误的，但它能提高快速思维，使进一步的泛化变得容易。社会层面的模型之间的双稳态互动，导致部落主义（形成宗族和联盟），加速了泛化，有利于连贯学习，有助于模型之间的冲突，在极端情况下，可能导致价值重估。在权重很高的问题上，在极少数情况下，人们会在大量相反证据的压力下改变主意。</p><p>An individual point of view receives a natural protection at the neural and at the social level</p><p>个人的观点在神经和社会层面得到了天然的保护</p><h3><b>Pain of broken models</b></h3><h3><b>打破模型的痛苦</b></h3><p>Breaking up models is unpleasurable. If the model is strong, and its <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Knowledge_valuation_network" class=" wrap external" target="_blank" rel="nofollow noreferrer">valuation</a> is high, the pain may be significant. This results in an "emotional attachment" to personal beliefs. This seemingly irrational phenomenon is part of the model protection scheme.</p><p>打破模型是不愉快的。如果模型很强大，而且其估值很高，痛苦可能很大。这就导致了对个人信念的 "情感依赖"。这种看似非理性的现象是模型保护计划的一部分。</p><p>Breaking up a faulty model will often lead to a rich compensation when a new model can be established. This is why it is much easier to transition between models than to break up an existing model with nothing new in its place. The breakup of a strong model may lead to a painful realization: <i>"I have been wrong all along"</i> or <i>"I have wasted my youth/life on a wild goose chase"</i>. This is also a reason why a wrong model based on limited data is better than no model. A wrong model can serve as a skeleton of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Generalization" class=" wrap external" target="_blank" rel="nofollow noreferrer">generalization</a> upon which inconsistencies (errors) can be discovered. When a model is missing, coherent learning is inhibited, and the progress stalls. If there is a great deal of data that supports several alternative models, keeping all models in memory may be unavoidable, however, that approach is costly and error-prone. An early choice in favor of one of the models may accelerate progress (incl. falsification of the choice).</p><p>打破一个有问题的模型，当一个新的模型可以建立起来的时候，往往会得到丰富的补偿。这就是为什么在模型之间进行过渡要比打碎一个现有的模型而没有新的模型来代替要容易得多。一个强势模型的打破可能会导致一个痛苦的认识。"我一直都是错的 "或者 "我把我的青春/生命浪费在了疯狂的追逐上"。这也是为什么基于有限数据的错误模型比没有模型好的一个原因。一个错误的模型可以作为归纳的框架，在此基础上发现不一致的地方（错误）。当一个模型缺失时，连贯学习就会受到抑制，进度就会停滞。如果有大量的数据支持几个可供选择的模型，将所有模型保存在记忆中可能是不可避免的，然而，这种方法成本很高，而且容易出错。早期选择支持其中一个模型可能会加快进度（包括选择的证伪）。</p><p><b>A wrong model is better than none</b></p><p><b>错误的模型总比没有好</b></p><h3><b>Smart people are stubborn</b></h3><h3><b>聪明人是固执的</b></h3><p>The smarter the individual, the stronger the algorithmic processes of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Generalization" class=" wrap external" target="_blank" rel="nofollow noreferrer">generalization</a>, and the stronger the socially-driven protection mechanisms. It is much easier to persuade an individual whose knowledge is less extensive, less stable, and less <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Conceptualization" class=" wrap external" target="_blank" rel="nofollow noreferrer">crystallized</a>. Adult populations around the world may seem highly persuadable. The factors that weaken the mind are numerous: <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Separation_anxiety" class=" wrap external" target="_blank" rel="nofollow noreferrer">separation anxiety</a> in <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Daycare" class=" wrap external" target="_blank" rel="nofollow noreferrer">daycare</a>, limits on freedom at school, <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Learned_helplessness" class=" wrap external" target="_blank" rel="nofollow noreferrer">learned helplessness</a>, depression, rat race, bad health, etc. The two key forces that lead to the weakening are the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Schools_suppress_the_learn_drive" class=" wrap external" target="_blank" rel="nofollow noreferrer">suppressed learn drive</a> (less learning), and incoherent learning. Without the continuous flow of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Knowledge_and_creativity" class=" wrap external" target="_blank" rel="nofollow noreferrer">new knowledge</a>, memory structures wither due to <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Forgetting" class=" wrap external" target="_blank" rel="nofollow noreferrer">forgetting</a> and <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Interference" class=" wrap external" target="_blank" rel="nofollow noreferrer">interference</a>. Instead of lifelong learning, we may experience the loss of the joy of living.</p><p>越聪明的个体，泛化的算法过程越强，社会驱动的保护机制越强。对于一个知识面不广、不稳定、不结晶的个体，说服他要容易得多。世界各地的成年群体可能看起来非常容易被说服。削弱心智的因素有很多：托儿所的分离焦虑、学校的自由限制、习得性无助、抑郁症、老鼠赛跑、身体不好等。导致弱化的两股关键力量是被压抑的学习动力（少学）、不连贯的学习。没有新知识的不断涌入，记忆结构就会因为遗忘和干扰而枯萎。我们可能不会终身学习，反而会失去生活的乐趣。</p><p>In the name of healthier and happier populations, we need to protect the healthy force of the <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Learn_drive" class=" wrap external" target="_blank" rel="nofollow noreferrer">learn drive</a>, lifelong <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Free_learning" class=" wrap external" target="_blank" rel="nofollow noreferrer">free learning</a>, and develop tolerance to <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Diversity" class=" wrap external" target="_blank" rel="nofollow noreferrer">diversity</a> of opinion. Debating points of view is healthy, however, incessant critical bombardment of weaker models may lead to their break up, without a chance to put in new structures that could underlie the recovery. Tolerance facilitates coexistence. The clash of models is welcome. However, the optimum scenarios in a clash of models are no different than solo learning: it is always recommended to tackle <b>one issue at a time</b>. It is better to conclude one debate before commencing another.</p><p>为了更健康、更幸福的群体，我们需要保护健康的学习动力、终身自由学习的力量，并培养对意见多样性的宽容。争论观点是健康的，然而，对较弱的模型不停地批判性轰炸，可能会导致其瓦解，而没有机会投入新的结构，这可能是恢复的基础。宽容有利于共存。模型的冲突是受欢迎的。然而，在模型冲突中的最佳方案与单打独斗的学习没有什么不同：总是建议<b>一次解决一个问题</b>。最好是在结束一场辩论后再开始另一场辩论。</p><p>We need to celebrate strong <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Model" class=" wrap external" target="_blank" rel="nofollow noreferrer">models</a> (points of view), even if they differ from ours. When someone tells you "<i>you are the most stubborn person in the world! You are impervious to argument</i>", take it as a potential sign of your own high intelligence. Models do not need to be correct (see: <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Value_of_wrong_models" class=" wrap external" target="_blank" rel="nofollow noreferrer">Value of wrong models</a>). The myth of "the only correct model" we learn at school where only "one truth" is acceptable. That "one truth" often appears to be just a point of view, or a specific interpretation, e.g. of a historic fact. Diversity of models needs to be protected and cherished. Unfortunately, we do not seem to have a brain algorithm for protecting <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Diversity" class=" wrap external" target="_blank" rel="nofollow noreferrer">diversity</a>. Tolerance needs to be acquired by learning in the same way as skepticism (i.e. immunity to fake news). Possibly, it is the modern connected world that necessitates that one extra layer of protection for models. We have evolved in conditions of lesser social connectivity. <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Diversity" class=" wrap external" target="_blank" rel="nofollow noreferrer">Diversity</a> is precious, but in a connected world, it can turn out overwhelming.</p><p>我们需要庆祝强大的模型（观点），即使它们与我们的观点不同。当有人告诉你 "你是世界上最顽固的人! 你对争论是不透彻的"，把它当作自己高智商的潜在标志。模型不需要正确（见：错误模型的价值）。我们在学校学到的 "唯一正确的模型 "的迷思，在这里，只有 "一个真理 "是可以接受的。这 "一个真理 "看起来往往只是一种观点，或者是一种特定的解释，比如对历史事实的解释。模型的多样性需要保护和珍惜。不幸的是，我们似乎没有保护多样性的大脑算法。宽容需要通过学习获得，就像怀疑论一样（即对假新闻的免疫力）。有可能，是现代互联的世界需要对模型多一层保护。我们是在社会连接性较差的条件下进化的。多样性是珍贵的，但在一个互联的世界里，它可能会变成压倒性的。</p><p>With a bit of self-discipline and training, we can develop a degree of tolerance for <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Diversity" class=" wrap external" target="_blank" rel="nofollow noreferrer">diversity</a>. This may turn out helpful to methodically resolve contradictions between diverse models: one at a time. My favorite model to clash with is the model of "<i><a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Prussian_education_system" class=" wrap external" target="_blank" rel="nofollow noreferrer">good school</a></i>".</p><p>只要稍加自律和训练，我们就能对多样性形成一定程度的宽容。这也许会对有条不紊地解决多元化模型之间的矛盾有所帮助：一次一个。我最喜欢与之冲突的模型是 "好学校 "的模型。</p><p>We need to master the tolerance of <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Diversity" class=" wrap external" target="_blank" rel="nofollow noreferrer">diversity</a>. In the connected world, we might be missing a natural mechanism for the protection of diverse models</p><p>我们需要掌握对多样性的宽容。在互联互通的世界里，我们可能缺少了一个保护多样化模型的天然机制。</p><h3><b>I apologize for my incorrigibility</b></h3><h3><b>我为我的无药可救而道歉</b></h3><p>If you happen to read some of my text, you may have an impression that I am impervious to argument too. I am proud of it. When I <a href="http://link.zhihu.com/?target=https%3A//supermemopedia.com/wiki/Your_article_about_ADHD_is_outrageously_wrong_and_should_be_deleted" class=" wrap external" target="_blank" rel="nofollow noreferrer">get blasted</a>, I <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/I_have_ADHD_and_I_love_it" class=" wrap external" target="_blank" rel="nofollow noreferrer">double down</a>. Each time I hear of my stubborn stance, I look for good examples in which I was easily convinced with a coherent argument. Invariably, I hear back "<i>That's not a good example. This is obvious</i>". In other words, I do not reject obviously valid claims. I reject those that clash with my models, and I am happy my models are strong, even if they may occasionally turn out wrong. If you see my error, <a href="http://link.zhihu.com/?target=https%3A//supermemo.guru/wiki/Piotr_Wozniak" class=" wrap external" target="_blank" rel="nofollow noreferrer">let me know</a></p><p>如果你碰巧读过我的一些文字，你可能会有一种印象，那就是我对争论也无动于衷。我以此为荣。当我被抨击时，我会加倍努力。每次听到我的顽固立场，我都会找一些好的例子，在这些例子中，我很容易被一个连贯的论点所说服。总会听到这样的回音："这不是一个好例子。这是很明显的"。换句话说，我不拒绝明显有效的主张。我拒绝那些与我的模型相冲突的说法，我很高兴我的模型是强大的，即使它们可能偶尔会变成错误的。如果你看到我的错误，请告诉我。</p>