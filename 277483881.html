<!DOCTYPE html>
<html lang="zh">
<head>
<title>记忆的神经统计模型 | ZhiHu Archive</title>
<meta charset="UTF-8">
<meta property="og:type" content="website">
<meta property="og:title" content="记忆的神经统计模型 | ZhiHu Archive">
<meta property="og:site_name" content="ZhiHu Archive for Thoughts Memo">
<meta property="og:url" content="https://zhuanlan.zhihu.com/p/277483881">
<meta property="og:image" content="https://picx.zhimg.com/v2-0462e44efc13d7ab99f7c40fccf8969a_r.jpg?source=172ae18b">
<meta property="og:description" content="原文： Neurostatistical Model of Memory 概要记忆的神经统计模型描述了长期记忆形成的基本过程。在该模型中，记忆由四个核心属性来描述： 稳定性 、 连贯性 [1]、 可提取性 和 复杂性 。由来记忆的神经统计模型是基于从 不同间隔复习计划 的记忆效果中得出的长期记…">
<meta name="description" content="原文： Neurostatistical Model of Memory 概要记忆的神经统计模型描述了长期记忆形成的基本过程。在该模型中，记忆由四个核心属性来描述： 稳定性 、 连贯性 [1]、 可提取性 和 复杂性 。由来记忆的神经统计模型是基于从 不同间隔复习计划 的记忆效果中得出的长期记…">
<meta data-pagefind-meta="title" content="记忆的神经统计模型">
<meta data-pagefind-meta="image" content="https://picx.zhimg.com/v2-0462e44efc13d7ab99f7c40fccf8969a_r.jpg?source=172ae18b">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="记忆的神经统计模型 | ZhiHu Archive">
<meta name="twitter:description" content="原文： Neurostatistical Model of Memory 概要记忆的神经统计模型描述了长期记忆形成的基本过程。在该模型中，记忆由四个核心属性来描述： 稳定性 、 连贯性 [1]、 可提取性 和 复杂性 。由来记忆的神经统计模型是基于从 不同间隔复习计划 的记忆效果中得出的长期记…">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no">
<meta name="google-site-verification" content="U7ZAFUgGNK60mmMqaRygg5vy-k8pwbPbDFXNjDCu7Xk" />
<link rel="alternate" type="application/rss+xml" title="ZhiHu Archive for Thoughts Memo" href="https://l-m-sherlock.github.io/ZhiHuArchive/feed.xml">
<link rel="stylesheet" href="https://gcore.jsdelivr.net/npm/yue.css@0.4.0/yue.css">
<script>
const redirect = false;
if (redirect) {
window.location.replace("https://zhuanlan.zhihu.com/p/277483881");
}
</script>
<style>
.origin_image {
width: 100%;
}
figure {
margin: 1.4em 0;
}
figure img {
width: 100%;
}
img {
vertical-align: middle;
}
.author {
display: flex;
gap: 1em;
align-items: center;
}
#avatar {
width: 100px;
height: 100px;
}
.author > div {
flex: 1;
}
a {
color: #2563eb;
text-decoration: none;
border-bottom: 1px solid rgba(37, 99, 235, 0.3);
border-radius: 4px;
padding: 0 0.1em;
transition: color 0.2s ease, border-color 0.2s ease, background-color 0.2s ease;
}
a:hover,
a:focus-visible {
color: #1d4ed8;
border-bottom-color: rgba(29, 78, 216, 0.6);
background-color: rgba(37, 99, 235, 0.08);
}
a:focus-visible {
outline: none;
box-shadow: 0 0 0 2px rgba(37, 99, 235, 0.25);
}
a[data-draft-type="link-card"] {
display: block;
border-bottom: none;
padding: 0;
background: none;
}
.references {
font-size: 0.85em;
}
.formula-display {
display: block;
text-align: center;
}
</style>
</head>
<body style="max-width: 1000px; margin: 0 auto; padding: 0 1em 0 1em;" class="yue">
<p data-pagefind-ignore><a href="./">← 返回目录</a></p>
<hr>
<header>
<img class="origin_image" src="https://picx.zhimg.com/v2-0462e44efc13d7ab99f7c40fccf8969a_r.jpg?source=172ae18b"/>
<h1><a href="https://zhuanlan.zhihu.com/p/277483881" target="_blank" rel="noopener noreferrer">记忆的神经统计模型</a></h1>
<div class="author">
<img class="avatar" id="avatar" src="https://pic1.zhimg.com/v2-d571786b77078321f5f6ef92f4967877_l.jpg?source=172ae18b" />
<div>
<h2 rel="author">
<a href="https://www.zhihu.com/people/4c592f496dc33822b560b382907ff1d0" target="_blank" rel="noopener noreferrer">@Thoughts Memo</a>
</h2>
<p>学校≠教育≠技能；文凭溢价=80%信号传递+20%人力资本</p>
</div>
</div>
<time datetime="2020-11-07T05:22:25">发表于 2020年11月07日</time>
<p rel="stats"style="color: #999; font-size: 0.9em;">15 👍 / 3 💬</p>
</header>
<article data-pagefind-body>
<p data-pid="FAGL--69">原文：<a class="wrap external" href="https://supermemo.guru/wiki/Neurostatistical_Model_of_Memory" rel="nofollow noreferrer noopener" target="_blank">Neurostatistical Model of Memory</a></p><h2>概要</h2><p data-pid="mu3IraUX">记忆的神经统计模型描述了长期记忆形成的基本过程。在该模型中，记忆由四个核心属性来描述：<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer noopener" target="_blank">稳定性</a>、<a class="wrap external" href="https://supermemo.guru/wiki/Coherence" rel="nofollow noreferrer noopener" target="_blank">连贯性</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="1" data-text="一致性与连贯性" data-url="https://zhuanlan.zhihu.com/p/264327134">[1]</sup>、<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer noopener" target="_blank">可提取性</a>和<a class="wrap external" href="https://supermemo.guru/wiki/Complexity" rel="nofollow noreferrer noopener" target="_blank">复杂性</a>。</p><h2>由来</h2><p data-pid="gr01_14U">记忆的神经统计模型是基于从<a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer noopener" target="_blank">不同间隔复习计划</a>的记忆效果中得出的长期记忆的统计特性。它将<a class="wrap external" href="https://supermemo.guru/wiki/Two_component_model_of_memory" rel="nofollow noreferrer noopener" target="_blank">记忆的双组分模型</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="2" data-text="记忆的两个组成成分" data-url="https://zhuanlan.zhihu.com/p/179076885">[2]</sup>扩展到分子解释之外，涉及到记忆的长期属性变化的结构和神经方面。该模型提供了大脑作为<a class="wrap external" href="https://supermemo.guru/wiki/Concept_network" rel="nofollow noreferrer noopener" target="_blank">概念网络</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="3" data-text="概念网络" data-url="https://zhuanlan.zhihu.com/p/266541480">[3]</sup>发挥作用所需的基本功能成分。</p><p data-pid="s0_-n4N7"><b>记忆的神经统计模型解决了可塑性-稳定性的难题。</b></p><h2>新概念<br/></h2><p data-pid="r5Opy-sf">除了<a class="wrap external" href="https://supermemo.guru/wiki/Two_component_model_of_memory" rel="nofollow noreferrer noopener" target="_blank">记忆的双组分模型</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="2" data-text="记忆的两个组成成分" data-url="https://zhuanlan.zhihu.com/p/179076885">[2]</sup>的骨架思想外，该模型的新贡献是：</p><ul><li data-pid="LL_hTfXe">基于神经网络<a class="wrap external" href="https://supermemo.guru/wiki/Interference" rel="nofollow noreferrer noopener" target="_blank">干扰</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="4" data-text="干扰" data-url="https://zhuanlan.zhihu.com/p/269974053">[4]</sup>的<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer noopener" target="_blank">可提取性</a>统计模型。</li><li data-pid="Gvn872Om">基于 AMPA 受体的易位、树突棘的生长和睡眠中突触变化的<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer noopener" target="_blank">稳定性</a>模型（见：<a class="wrap external" href="https://supermemo.guru/wiki/Two-component_model_of_memory_stability" rel="nofollow noreferrer noopener" target="_blank">记忆稳定性的双组分模型</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="5" data-text="记忆稳定性的两个组成成分" data-url="https://zhuanlan.zhihu.com/p/268782211">[5]</sup>）。</li><li data-pid="gCqBK48l">基于清除树枝状丝状体的<a class="wrap external" href="https://supermemo.guru/wiki/Spacing_effect" rel="nofollow noreferrer noopener" target="_blank">间隔效应</a>假设模型（见：<a class="wrap external" href="https://supermemo.guru/wiki/Structural_and_molecular_mechanisms_of_the_spacing_effect" rel="nofollow noreferrer noopener" target="_blank">间隔效应的结构和分子机制</a>）。</li><li data-pid="S4QL6sWD">记忆<a class="wrap external" href="https://supermemo.guru/wiki/Coherence" rel="nofollow noreferrer noopener" target="_blank">连贯性</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="1" data-text="一致性与连贯性" data-url="https://zhuanlan.zhihu.com/p/264327134">[1]</sup>模型(包括<a class="wrap external" href="https://supermemo.guru/wiki/Memory_optimization_in_sleep" rel="nofollow noreferrer noopener" target="_blank">睡眠中的记忆巩固</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="6" data-text="睡眠中的记忆优化" data-url="https://zhuanlan.zhihu.com/p/266856783">[6]</sup>)</li><li data-pid="NrCsR1LX">记忆<a class="wrap external" href="https://supermemo.guru/wiki/Complexity" rel="nofollow noreferrer noopener" target="_blank">复杂性</a>模型</li></ul><h2>学习</h2><p data-pid="zF8VeDAf">根据该模型，学习将导致树突棘标记，插入 <a class="wrap external" href="https://supermemo.guru/wiki/AMPA_receptors_stabilize_the_dendritic_branch" rel="nofollow noreferrer noopener" target="_blank">AMPA 受体</a>，并消除未标记的棘。反向标记可能被用来消除干扰连接。然后，学习将导致树突棘的净损失。此外，<a class="wrap external" href="https://supermemo.guru/wiki/Spacing_effect" rel="nofollow noreferrer noopener" target="_blank">间隔效应</a>可能来自于需要从<a class="wrap external" href="https://supermemo.guru/wiki/Stabilization" rel="nofollow noreferrer noopener" target="_blank">稳定化</a>的部位清除树枝状丝状体。丝状突起的探索性生长将是对突触后活动减少的反应。</p><h2>贡献者</h2><p data-pid="b5b-JV3Y"><a class="wrap external" href="https://supermemo.guru/wiki/Piotr_Wozniak" rel="nofollow noreferrer noopener" target="_blank">Piotr Wozniak</a>，<a class="wrap external" href="https://supermemo.guru/wiki/George_Zonnios" rel="nofollow noreferrer noopener" target="_blank">George Zonnios</a>（间隔效应），<a class="wrap external" href="https://supermemo.guru/wiki/Darek_Murakowski" rel="nofollow noreferrer noopener" target="_blank">Darek Murakowski</a>，<a class="wrap external" href="https://supermemo.guru/wiki/Janusz_Murakowski" rel="nofollow noreferrer noopener" target="_blank">Janusz Murakowski</a>（记忆的双组分模型），<a class="wrap external" href="https://supermemo.guru/wiki/Edward_Gorzelanczyk" rel="nofollow noreferrer noopener" target="_blank">Edward Gorzelanczyk</a>（分子记忆）。</p><p></p>
<hr><section data-pagefind-ignore><h2>参考</h2>1. 一致性与连贯性 <a href="./264327134.html" target="_blank" rel="noopener noreferrer">./264327134.html</a><br>2. 记忆的两个组成成分 <a href="./179076885.html" target="_blank" rel="noopener noreferrer">./179076885.html</a><br>3. 概念网络 <a href="./266541480.html" target="_blank" rel="noopener noreferrer">./266541480.html</a><br>4. 干扰 <a href="./269974053.html" target="_blank" rel="noopener noreferrer">./269974053.html</a><br>5. 记忆稳定性的两个组成成分 <a href="./268782211.html" target="_blank" rel="noopener noreferrer">./268782211.html</a><br>6. 睡眠中的记忆优化 <a href="./266856783.html" target="_blank" rel="noopener noreferrer">./266856783.html</a></section>
<hr>
<div class="column" style="margin: 1em 0; padding: 0.5em 1em; border: 2px solid #999; border-radius: 5px;" data-pagefind-ignore>
<h2>专栏：间隔重复 & 注意力管理</h2>
<p></p>
</div>
<hr>
<p data-pagefind-ignore><a href="./">← 返回目录</a></p>
</article>
<footer>
<p style="color: #999; font-size: 0.85em; text-align: center; margin-top: 2em;">
本页面由 <a href="https://github.com/L-M-Sherlock/ZhiHuArchive" target="_blank" rel="noopener noreferrer">ZhiHuArchive</a> 渲染，模板参考 <a href="https://github.com/frostming/fxzhihu" target="_blank" rel="noopener noreferrer">FxZhihu</a>。
</p>
</footer>
<script src="https://giscus.app/client.js"
data-repo="L-M-Sherlock/ZhiHuArchive"
data-repo-id="MDEwOlJlcG9zaXRvcnkzNDk5NDE0MzM="
data-category="Announcements"
data-category-id="DIC_kwDOFNuuuc4Ck92x"
data-mapping="title"
data-strict="0"
data-reactions-enabled="1"
data-emit-metadata="0"
data-input-position="top"
data-theme="preferred_color_scheme"
data-lang="zh-CN"
data-loading="lazy"
crossorigin="anonymous"
async>
</script>
</body>
</html>