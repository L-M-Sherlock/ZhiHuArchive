<!DOCTYPE html>
<html lang="zh">
<head>
<title>GPT-4 在指导下，通常能够从解释性文本中为陈述性知识生成可用的间隔重复卡片 | ZhiHu Archive</title>
<meta charset="UTF-8">
<meta property="og:type" content="website">
<meta property="og:title" content="GPT-4 在指导下，通常能够从解释性文本中为陈述性知识生成可用的间隔重复卡片 | ZhiHu Archive">
<meta property="og:site_name" content="ZhiHu Archive for Thoughts Memo">
<meta property="og:url" content="https://zhuanlan.zhihu.com/p/656760808">
<meta property="og:image" content="">
<meta property="og:description" content="通过结合以下的洞见，我在 使用机器学习从解释性文本中生成优质的间隔重复卡片 [1]中用 GPT-4 取得了成功，通常都能一次搞定： 对于卡片生成任务，选择要强化的目标概念，和为这些目标概念编写卡片，是两个独立的问题 [2]。在这些例子里，我负责选择制卡对象（…">
<meta name="description" content="通过结合以下的洞见，我在 使用机器学习从解释性文本中生成优质的间隔重复卡片 [1]中用 GPT-4 取得了成功，通常都能一次搞定： 对于卡片生成任务，选择要强化的目标概念，和为这些目标概念编写卡片，是两个独立的问题 [2]。在这些例子里，我负责选择制卡对象（…">
<meta data-pagefind-meta="title" content="GPT-4 在指导下，通常能够从解释性文本中为陈述性知识生成可用的间隔重复卡片">
<meta data-pagefind-meta="image" content="">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="GPT-4 在指导下，通常能够从解释性文本中为陈述性知识生成可用的间隔重复卡片 | ZhiHu Archive">
<meta name="twitter:description" content="通过结合以下的洞见，我在 使用机器学习从解释性文本中生成优质的间隔重复卡片 [1]中用 GPT-4 取得了成功，通常都能一次搞定： 对于卡片生成任务，选择要强化的目标概念，和为这些目标概念编写卡片，是两个独立的问题 [2]。在这些例子里，我负责选择制卡对象（…">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no">
<meta name="google-site-verification" content="U7ZAFUgGNK60mmMqaRygg5vy-k8pwbPbDFXNjDCu7Xk" />
<link rel="alternate" type="application/rss+xml" title="ZhiHu Archive for Thoughts Memo" href="https://l-m-sherlock.github.io/ZhiHuArchive/feed.xml">
<link rel="stylesheet" href="https://gcore.jsdelivr.net/npm/yue.css@0.4.0/yue.css">
<script>
const redirect = false;
if (redirect) {
window.location.replace("https://zhuanlan.zhihu.com/p/656760808");
}
</script>
<style>
.origin_image {
width: 100%;
}
figure {
margin: 1.4em 0;
}
figure img {
width: 100%;
}
img {
vertical-align: middle;
}
.author {
display: flex;
gap: 1em;
align-items: center;
}
#avatar {
width: 100px;
height: 100px;
}
.author > div {
flex: 1;
}
a {
color: #2563eb;
text-decoration: none;
border-bottom: 1px solid rgba(37, 99, 235, 0.3);
border-radius: 4px;
padding: 0 0.1em;
transition: color 0.2s ease, border-color 0.2s ease, background-color 0.2s ease;
}
a:hover,
a:focus-visible {
color: #1d4ed8;
border-bottom-color: rgba(29, 78, 216, 0.6);
background-color: rgba(37, 99, 235, 0.08);
}
a:focus-visible {
outline: none;
box-shadow: 0 0 0 2px rgba(37, 99, 235, 0.25);
}
a[data-draft-type="link-card"] {
display: block;
border-bottom: none;
padding: 0;
background: none;
}
.references {
font-size: 0.85em;
}
.formula-display {
display: block;
text-align: center;
}
</style>
</head>
<body style="max-width: 1000px; margin: 0 auto; padding: 0 1em 0 1em;" class="yue">
<p data-pagefind-ignore><a href="./">← 返回目录</a></p>
<hr>
<header>
<img class="origin_image" src=""/>
<h1><a href="https://zhuanlan.zhihu.com/p/656760808" target="_blank" rel="noopener noreferrer">GPT-4 在指导下，通常能够从解释性文本中为陈述性知识生成可用的间隔重复卡片</a></h1>
<div class="author">
<img class="avatar" id="avatar" src="https://picx.zhimg.com/v2-531a5c925d857e1a3b944414bbd451c6_l.jpg?source=172ae18b" />
<div>
<h2 rel="author">
<a href="https://www.zhihu.com/people/3c9990a12cdbcd92e20b1387b160f0a3" target="_blank" rel="noopener noreferrer">@Jarrett Ye</a>
</h2>
<p>钻研人类记忆，探索复习算法。改善教育公平，践行自由学习。</p>
</div>
</div>
<time datetime="2023-09-17T07:03:20">发表于 2023年09月17日</time>
<p rel="stats"style="color: #999; font-size: 0.9em;">8 👍 / 0 💬</p>
</header>
<article data-pagefind-body>
<p data-pid="3WQJ_C2V">通过结合以下的洞见，我在<a class="wrap external" href="https://notes.andymatuschak.org/z2DY7qsP5iHsiA5hxUHheV8hu7Xe96vdGyYX" rel="nofollow noreferrer noopener" target="_blank">使用机器学习从解释性文本中生成优质的间隔重复卡片</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="1" data-text="使用机器学习从解释性文本中生成优质的间隔重复卡片" data-url="https://zhuanlan.zhihu.com/p/716570823">[1]</sup>中用 <a class="wrap external" href="https://notes.andymatuschak.org/z3Bab7JXEhospmJZJQnduTFFjrZHaHKMCJBQE" rel="nofollow noreferrer noopener" target="_blank">GPT-4</a> 取得了成功，通常都能一次搞定：</p><ul><li data-pid="VCUPKOo_"><a class="wrap external" href="https://notes.andymatuschak.org/z62s1nNLEfhGbDmpb8Z7dZiYyi3kaSziuLVXd" rel="nofollow noreferrer noopener" target="_blank">对于卡片生成任务，选择要强化的目标概念，和为这些目标概念编写卡片，是两个独立的问题</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="2" data-text="对于卡片生成任务，选择要强化的目标概念，和为这些目标概念编写卡片，是两个独立的问题" data-url="https://zhuanlan.zhihu.com/p/656354899">[2]</sup>。在这些例子里，我负责选择制卡对象（例如，通过指向更大篇幅中的短语），模型的任务是根据这些给定的目标，生成有用的卡片。<br/> <br/></li><li data-pid="OEa7GrDY"><a class="wrap external" href="https://notes.andymatuschak.org/zrqgkr9n3eCMNsAPDsRozt3HLd8nRT5nVASc" rel="nofollow noreferrer noopener" target="_blank">对于卡片生成任务，如果提供了编写卡片的原则，大型语言模型（LLM）的表现可能会有所提升</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="3" data-text="对于卡片生成任务，如果提供了编写卡片的原则，大型语言模型（LLM）的表现可能会有所提升" data-url="https://zhuanlan.zhihu.com/p/644435843">[3]</sup>；我提供了这些原则。<br/> <br/></li><li data-pid="E1zwDogN"><a class="wrap external" href="https://notes.andymatuschak.org/zomoPzCNzSi5GqtfTeVWgm7RjmiArjS8vvM5" rel="nofollow noreferrer noopener" target="_blank">对于卡片生成任务，大型语言模型（LLM）经常需要额外的提示，来确定从何种角度制卡</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="4" data-text="对于卡片生成任务，大型语言模型（LLM）经常需要额外的提示，来确定从何种角度制卡" data-url="https://zhuanlan.zhihu.com/p/644435780">[4]</sup>；我提供了这些提示。<br/> <br/></li><li data-pid="UGQa-Dmk"><a class="wrap external" href="https://notes.andymatuschak.org/z5LQFLXHFLrb4nYAtLrB3JBzNyJng8fYHVJYN" rel="nofollow noreferrer noopener" target="_blank">对于卡片生成任务，如果提供了充足的上下文，大型语言模型（LLM）可能会表现得更好</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="5" data-text="对于卡片生成任务，如果提供了充足的上下文，大型语言模型（LLM）可能会表现得更好" data-url="https://zhuanlan.zhihu.com/p/645670312">[5]</sup>；我提供了上下文。<br/> </li></ul><p data-pid="ArT1DZKV">这对于简单的描写来说，效果相当好，但对于更概念化的材料来说就不行了：<a class="wrap external" href="https://notes.andymatuschak.org/zmrbnm683nVZi9ut63vsr8BwYKEtATA6e4B3" rel="nofollow noreferrer noopener" target="_blank">对于卡片生成任务，大型语言模型（LLM）缺乏为复杂概念材料编写卡片的模式</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="6" data-text="对于卡片生成任务，大型语言模型（LLM）缺乏为复杂概念材料编写卡片的模式" data-url="https://zhuanlan.zhihu.com/p/656355546">[6]</sup></p><p data-pid="NgRN7l9n">一个提示词示例：<a class="wrap external" href="https://notes.andymatuschak.org/z4jtgUPVP5pABoDEjvz22hzYzAuRELqGg4BR6" rel="nofollow noreferrer noopener" target="_blank">20230614123022</a></p><h2>链接至本文（已汉化）</h2><ul><li data-pid="7JETHqhK"><a class="internal" href="./656355546.html" rel="noopener noreferrer" target="_blank">对于卡片生成任务，大型语言模型（LLM）缺乏为复杂概念材料编写卡片的模式</a></li><li data-pid="j4s4fmCI"><a class="internal" href="./716570823.html" rel="noopener noreferrer" target="_blank">使用机器学习从解释性文本中生成优质的间隔重复卡片</a></li></ul><h2>声明</h2><p data-pid="a1kSLiu9">此内容发布由 Andy Matuschak 许可。未经允许，不得转载或修改。保留所有权利。</p><p class="ztext-empty-paragraph"><br/></p><blockquote data-pid="ifrhYqEH"><a class="wrap external" href="http://paratranz.cn/projects/3131" rel="nofollow noreferrer noopener" target="_blank">Thoughts Memo</a> 汉化组译制<br/>感谢主要译者 <span class="nolink">Jarrett</span> Ye，校对<span class="nolink">偶然奇怪~ ☆</span><br/>原文：<a class="wrap external" href="https://notes.andymatuschak.org/z2VVmj24FLixtrijdAbkKty91JQruAaZGbHE6" rel="nofollow noreferrer noopener" target="_blank">GPT-4 can often generate usable spaced repetition prompts for declarative knowledge from explanatory text with guidance (andymatuschak.org)</a></blockquote>
<hr><section data-pagefind-ignore><h2>参考</h2>1. 使用机器学习从解释性文本中生成优质的间隔重复卡片 <a href="./716570823.html" target="_blank" rel="noopener noreferrer">./716570823.html</a><br>2. 对于卡片生成任务，选择要强化的目标概念，和为这些目标概念编写卡片，是两个独立的问题 <a href="./656354899.html" target="_blank" rel="noopener noreferrer">./656354899.html</a><br>3. 对于卡片生成任务，如果提供了编写卡片的原则，大型语言模型（LLM）的表现可能会有所提升 <a href="./644435843.html" target="_blank" rel="noopener noreferrer">./644435843.html</a><br>4. 对于卡片生成任务，大型语言模型（LLM）经常需要额外的提示，来确定从何种角度制卡 <a href="./644435780.html" target="_blank" rel="noopener noreferrer">./644435780.html</a><br>5. 对于卡片生成任务，如果提供了充足的上下文，大型语言模型（LLM）可能会表现得更好 <a href="./645670312.html" target="_blank" rel="noopener noreferrer">./645670312.html</a><br>6. 对于卡片生成任务，大型语言模型（LLM）缺乏为复杂概念材料编写卡片的模式 <a href="./656355546.html" target="_blank" rel="noopener noreferrer">./656355546.html</a></section>
<hr>
<div class="column" style="margin: 1em 0; padding: 0.5em 1em; border: 2px solid #999; border-radius: 5px;" data-pagefind-ignore>
<h2>专栏：间隔重复 & 注意力管理</h2>
<p></p>
</div>
<hr>
<p data-pagefind-ignore><a href="./">← 返回目录</a></p>
</article>
<footer>
<p style="color: #999; font-size: 0.85em; text-align: center; margin-top: 2em;">
本页面由 <a href="https://github.com/L-M-Sherlock/ZhiHuArchive" target="_blank" rel="noopener noreferrer">ZhiHuArchive</a> 渲染，模板参考 <a href="https://github.com/frostming/fxzhihu" target="_blank" rel="noopener noreferrer">FxZhihu</a>。
</p>
</footer>
<script src="https://giscus.app/client.js"
data-repo="L-M-Sherlock/ZhiHuArchive"
data-repo-id="MDEwOlJlcG9zaXRvcnkzNDk5NDE0MzM="
data-category="Announcements"
data-category-id="DIC_kwDOFNuuuc4Ck92x"
data-mapping="title"
data-strict="0"
data-reactions-enabled="1"
data-emit-metadata="0"
data-input-position="top"
data-theme="preferred_color_scheme"
data-lang="zh-CN"
data-loading="lazy"
crossorigin="anonymous"
async>
</script>
</body>
</html>