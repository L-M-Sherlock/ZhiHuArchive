<!DOCTYPE html>
<html lang="zh-CN">
<head>
<title>稳定化 - @Jarrett Ye</title>
<meta charset="UTF-8">
<meta property="og:type" content="website">
<meta property="og:title" content="稳定化 - @Jarrett Ye">
<meta property="og:site_name" content="ZhiHu Archive for Thoughts Memo">
<meta property="og:url" content="https://zhuanlan.zhihu.com/p/595158577">
<meta name="description" property="og:description" content="记忆稳定化（缩写为 SInc，即 stability increase）是指由记忆提取（例如，复习 [1]…">
<meta property="twitter:card" content="summary">
<meta name="twitter:title" property="og:title" itemprop="name" content="稳定化 - @Jarrett Ye">
<meta name="twitter:description" property="og:description" itemprop="description" content="记忆稳定化（缩写为 SInc，即 stability increase）是指由记忆提取（例如，复习 [1]…">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no">
<meta name="google-site-verification" content="U7ZAFUgGNK60mmMqaRygg5vy-k8pwbPbDFXNjDCu7Xk" />
<link rel="alternate" type="application/rss+xml" title="ZhiHu Archive for Thoughts Memo" href="https://l-m-sherlock.github.io/ZhiHuArchive/feed.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/yue.css@0.4.0/yue.css">
<script>
</script>
<style>
.origin_image {
width: 100%;
}
figure {
margin:1.4em 0;
}
figure img {
width: 100%;
}
img {
vertical-align: middle;
}
.author {
display: flex;
gap: 1em;
}
#avatar {
width: 100px;
height: 100px;
}
.author > div {
flex: 1;
}
a[data-draft-type="link-card"] {
   display: block;
}
</style>
</head>
<body style="max-width: 1000px; margin: 0 auto; padding: 0 1em 0 1em;" class="yue">
<p><a href="./">← 返回目录</a></p>
<hr>
<header>
<img class="origin_image" src=""/>
<h1><a href="https://zhuanlan.zhihu.com/p/595158577">稳定化</a></h1>
<div class="author">
<img class="avatar" id="avatar" src="https://pic1.zhimg.com/50/v2-7a23f5ee157d58c2494e8a642e59b7ae_l.jpg?source=b1748391" />
<div>
<h2 rel="author">
<a href="https://api.zhihu.com/people/3c9990a12cdbcd92e20b1387b160f0a3" target="_blank">@Jarrett Ye</a>
</h2>
<p> 钻研人类记忆，探索复习算法。改善教育公平，践行自由学习。 </p>
</div>
</div>
<time datetime="2022-12-29T04:46:47">发表于 2022年12月29日</time>
<p rel="stats"style="color: #999; font-size: 0.9em;">7 👍 / 3 💬</p>
</header>
<article>
<p data-pid="CWXFnA-G"><b>记忆稳定化</b>（缩写为 <b>SInc</b>，即 <b>stability increase</b>）是指由记忆提取（例如，<a class="wrap external" href="https://supermemo.guru/wiki/Review" rel="nofollow noreferrer" target="_blank">复习</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="1" data-text="重复" data-url="https://zhuanlan.zhihu.com/p/572444486">[1]</sup>）引起的<a class="wrap external" href="https://supermemo.guru/wiki/Memory_stability" rel="nofollow noreferrer" target="_blank">记忆稳定性</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="2" data-text="记忆稳定性" data-url="https://zhuanlan.zhihu.com/p/559298549">[2]</sup>增长。<b>稳定化</b>可能也是睡眠<a class="wrap external" href="https://supermemo.guru/wiki/Memory_optimization" rel="nofollow noreferrer" target="_blank">记忆优化</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="3" data-text="睡眠中的记忆优化" data-url="https://zhuanlan.zhihu.com/p/266856783">[3]</sup>的结果。</p><p data-pid="Kr2nJn3Z"><a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="2" data-text="记忆稳定性" data-url="https://zhuanlan.zhihu.com/p/559298549">[2]</sup>越高，<a class="wrap external" href="https://supermemo.guru/wiki/Review" rel="nofollow noreferrer" target="_blank">复习</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="1" data-text="重复" data-url="https://zhuanlan.zhihu.com/p/572444486">[1]</sup>时的<a class="wrap external" href="https://supermemo.guru/wiki/Stability_increase" rel="nofollow noreferrer" target="_blank">稳定性增长</a>越慢（参见：<a class="wrap external" href="https://supermemo.guru/wiki/Stabilization_decay" rel="nofollow noreferrer" target="_blank">稳定化衰减</a>）。顾名思义，记忆会在长期贮存中趋于「稳定」。</p><p data-pid="ul39wv4-">此外，提取记忆时的稳定性增长取决于<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="4" data-text="记忆可提取性" data-url="https://zhuanlan.zhihu.com/p/559819340">[4]</sup>和<a class="wrap external" href="https://supermemo.guru/wiki/Memory_complexity" rel="nofollow noreferrer" target="_blank">记忆复杂性</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="5" data-text="记忆复杂性" data-url="https://zhuanlan.zhihu.com/p/304800091">[5]</sup>。可提取性越低，稳定性的平均增长就越高。稳定性的增长期望通过<b>巩固曲线</b>描述，受记忆<a class="wrap external" href="https://supermemo.guru/wiki/Lapse" rel="nofollow noreferrer" target="_blank">遗忘</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="6" data-text="遗忘" data-url="https://zhuanlan.zhihu.com/p/558542113">[6]</sup>的概率调节，其在不同的<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>水平达到峰值（通常是<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>在 30-80% 之间）。</p><p data-pid="bLGvP4IC"><a class="wrap external" href="https://supermemo.guru/wiki/Complexity" rel="nofollow noreferrer" target="_blank">复杂性</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="5" data-text="记忆复杂性" data-url="https://zhuanlan.zhihu.com/p/304800091">[5]</sup>是记忆研究中的混淆因素。对于原子记忆，稳定性可以建模（例如，在 <a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer" target="_blank">SM-17 算法</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="7" data-text="2014：SM-17 算法" data-url="https://zhuanlan.zhihu.com/p/473482969">[7]</sup>中）。随着记忆复杂性不断提升，稳定性逐渐失去意义。例如，如果我们考虑记忆一本书，其稳定性增长是无法衡量的，因为一本书无法逐字逐句地被完整回忆。一本书的记忆印记是一组复杂的记忆组，其稳定性可能跨越从短期到<b><a class="wrap external" href="https://supermemo.guru/wiki/Permastore" rel="nofollow noreferrer" target="_blank">永久存储</a></b>的范围。</p><p data-pid="afwS1w_R">在 <a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer" target="_blank">SM-17 算法</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="7" data-text="2014：SM-17 算法" data-url="https://zhuanlan.zhihu.com/p/473482969">[7]</sup>中，稳定性增长矩阵（SInc[]）可视作 <a class="wrap external" href="https://supermemo.guru/wiki/Optimum_factor" rel="nofollow noreferrer" target="_blank">O-系数</a>矩阵（源自老版本的 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemos</a>）在<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="4" data-text="记忆可提取性" data-url="https://zhuanlan.zhihu.com/p/559819340">[4]</sup>维度的拓展。这一拓展让算法适用于各种重复规划至关重要（<a class="wrap external" href="https://supermemo.guru/wiki/Review" rel="nofollow noreferrer" target="_blank">复习</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="1" data-text="重复" data-url="https://zhuanlan.zhihu.com/p/572444486">[1]</sup>中的延迟对应较低的<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="4" data-text="记忆可提取性" data-url="https://zhuanlan.zhihu.com/p/559819340">[4]</sup>）。</p><p data-pid="YxLYOC75">另见：</p><ul><li data-pid="IaYQNjmH"><a class="wrap external" href="https://supermemo.guru/wiki/Two_component_model_of_long-term_memory" rel="nofollow noreferrer" target="_blank">长期记忆的双组分模型</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="8" data-text="记忆的双组分模型" data-url="https://zhuanlan.zhihu.com/p/579476637">[8]</sup><br/> </li><li data-pid="LKNcb-Su"><a class="wrap external" href="https://supermemo.guru/wiki/Search_for_a_universal_memory_formula" rel="nofollow noreferrer" target="_blank">寻找通用记忆公式</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="9" data-text="1990：记忆的通用公式" data-url="https://zhuanlan.zhihu.com/p/429504395">[9]</sup><br/> </li><li data-pid="T74EgOPK"><a class="wrap external" href="https://supermemo.guru/wiki/Stabilization_curve" rel="nofollow noreferrer" target="_blank">稳定化曲线</a><br/> </li><li data-pid="1LIPCg1t"><a class="wrap external" href="https://supermemo.guru/wiki/Stabilization_decay" rel="nofollow noreferrer" target="_blank">稳定化衰减</a><br/> </li><li data-pid="epHRIgVL"><a class="wrap external" href="https://supermemo.guru/wiki/Structural_and_molecular_mechanisms_of_the_spacing_effect" rel="nofollow noreferrer" target="_blank">间隔效应的结构和分子机理</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="10" data-text="间隔效应的结构与分子机理" data-url="https://zhuanlan.zhihu.com/p/288609114">[10]</sup><br/> </li><li data-pid="BCpcNHhO"><a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo_Algorithm:_30-year-long_labor" rel="nofollow noreferrer" target="_blank">SuperMemo 算法：长达 30 年的努力</a><br/> </li><li data-pid="sbm0yOUp"><a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer" target="_blank">算法 SM-17</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="7" data-text="2014：SM-17 算法" data-url="https://zhuanlan.zhihu.com/p/473482969">[7]</sup><br/> </li><li data-pid="kKIuHGOd"><a class="wrap external" href="https://supermemo.guru/wiki/Post-lapse_stability" rel="nofollow noreferrer" target="_blank">遗忘后的稳定</a><br/> </li></ul><blockquote data-pid="5Avy1Qcx">本<a class="wrap external" href="https://supermemo.guru/wiki/Glossary" rel="nofollow noreferrer" target="_blank">词汇表</a>条目用于解释 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo_Guru" rel="nofollow noreferrer" target="_blank">SuperMemo</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="11" data-text="什么是 SuperMemo" data-url="https://www.yuque.com/supermemo/wiki/supermemo">[11]</sup>，一位自 <a class="wrap external" href="https://supermemo.guru/wiki/History_of_spaced_repetition_(print)" rel="nofollow noreferrer" target="_blank">1987</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="12" data-text="0 目录《间隔重复的历史》" data-url="https://zhuanlan.zhihu.com/p/375379522">[12]</sup> 年以来的<a class="wrap external" href="https://supermemo.guru/wiki/Spaced_repetition" rel="nofollow noreferrer" target="_blank">间隔重复</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="13" data-text="间隔重复 (spaced repetition)" data-url="https://zhuanlan.zhihu.com/p/305651556">[13]</sup>软件先驱。</blockquote><figure data-size="normal"><img class="origin_image zh-lightbox-thumb" data-original="https://pica.zhimg.com/v2-e35d3179058fbe2da35535e6ed6a1ae8_r.jpg" data-original-token="v2-e35d3179058fbe2da35535e6ed6a1ae8" data-rawheight="313" data-rawwidth="500" data-size="normal" src="https://pica.zhimg.com/v2-e35d3179058fbe2da35535e6ed6a1ae8_b.jpg" width="500"/><figcaption>稳定性增长函数</figcaption></figure><p data-pid="JECu8WpW">图：<a class="wrap external" href="https://supermemo.guru/wiki/Stability_increase" rel="nofollow noreferrer" target="_blank">稳定性增长</a>函数由 <a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer" target="_blank">SM-17 算法</a>计算。该函数有三个参数：（1）复习时的<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>，以天为单位表示（左边），（2）复习时的<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>（右边）和（3）记忆<a class="wrap external" href="https://supermemo.guru/wiki/Complexity" rel="nofollow noreferrer" target="_blank">复杂性</a>，以<a class="wrap external" href="https://supermemo.guru/wiki/Item" rel="nofollow noreferrer" target="_blank">条目</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="14" data-text="条目" data-url="https://zhuanlan.zhihu.com/p/571700330">[14]</sup><a class="wrap external" href="https://supermemo.guru/wiki/Difficulty" rel="nofollow noreferrer" target="_blank">难度</a>表示（标签为 <b>Diff</b> 的滑块目前设置为 0.8）。图中，稳定性增长在 15 左右达到峰值（纵轴）。在一些<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>和<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>水平下，函数值低于 1.0，代表<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>下降（例如，由于集中学习而过早复习引发的<a class="wrap external" href="https://supermemo.guru/wiki/Spacing_effect" rel="nofollow noreferrer" target="_blank">间隔效应</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="15" data-text="间隔效应" data-url="https://zhuanlan.zhihu.com/p/279166945">[15]</sup>）。相对较<a class="wrap external" href="https://supermemo.guru/wiki/Difficulty" rel="nofollow noreferrer" target="_blank">难</a><a class="wrap external" href="https://supermemo.guru/wiki/Item" rel="nofollow noreferrer" target="_blank">条目</a>的 61,768 次重复被用于生成该曲线（Diff=0.8）。最长<a class="wrap external" href="https://supermemo.guru/wiki/Interval" rel="nofollow noreferrer" target="_blank">间隔</a>达到了 14 年（<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>为 5172）</p><figure data-size="normal"><img class="origin_image zh-lightbox-thumb" data-original="https://pic3.zhimg.com/v2-08a58cdbe2e84ec760ecb532d973174e_r.jpg" data-original-token="v2-08a58cdbe2e84ec760ecb532d973174e" data-rawheight="313" data-rawwidth="500" data-size="normal" src="https://pic3.zhimg.com/v2-08a58cdbe2e84ec760ecb532d973174e_b.jpg" width="500"/><figcaption>根据复习的记忆稳定化近似</figcaption></figure><p data-pid="jOsn7l-b">图：<a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 中的稳定化函数近似。数据点、绿色和红色圆点，对应了在选定<a class="wrap external" href="https://supermemo.guru/wiki/Difficulty" rel="nofollow noreferrer" target="_blank">难度</a>分位（Diff=0.5）下所有<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>和<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>对应的<a class="wrap external" href="https://supermemo.guru/wiki/Memory_stabilization" rel="nofollow noreferrer" target="_blank">记忆稳定化</a>（SInc）。蓝-红曲线表示由 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 使用<a class="wrap external" href="https://supermemo.guru/wiki/Stabilization_curve" rel="nofollow noreferrer" target="_blank">稳定化曲线</a>、<a class="wrap external" href="https://supermemo.guru/wiki/Stabilization_decay" rel="nofollow noreferrer" target="_blank">稳定化衰减</a>和根据<a class="wrap external" href="https://supermemo.guru/wiki/Item" rel="nofollow noreferrer" target="_blank">条目</a><a class="wrap external" href="https://supermemo.guru/wiki/Difficulty" rel="nofollow noreferrer" target="_blank">难度</a>更改这些函数的参数所找到的最佳拟合。生成该图使用了 54,449 个复习样本。右侧的绿色离群点表示来自新<a class="wrap external" href="https://supermemo.guru/wiki/Item" rel="nofollow noreferrer" target="_blank">条目</a>的「污染」，因为它们的<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>还未被准确估计。</p><figure data-size="normal"><img class="origin_image zh-lightbox-thumb" data-original="https://pic1.zhimg.com/v2-5afa06691e563eb4e456edca65bee49a_r.jpg" data-original-token="v2-5afa06691e563eb4e456edca65bee49a" data-rawheight="313" data-rawwidth="500" data-size="normal" src="https://pic1.zhimg.com/v2-5afa06691e563eb4e456edca65bee49a_b.jpg" width="500"/><figcaption>记忆巩固（期望稳定化）近似</figcaption></figure><p data-pid="8C4mQeqs">图：由 <a class="wrap external" href="https://supermemo.guru/wiki/Algorithm_SM-17" rel="nofollow noreferrer" target="_blank">SM-17 算法</a>近似的期望稳定性。该函数接受三个参数：（1）复习时的<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>，以天为单位（在左侧），（2）复习时的<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>（在右侧），和（3）记忆<a class="wrap external" href="https://supermemo.guru/wiki/Complexity" rel="nofollow noreferrer" target="_blank">复杂性</a>，以条目难度表示（标签为 <i>Diff</i> 的滑块目前设置在 0.1 处，即简单条目）。在图中，巩固（期望稳定性增长）的峰值为 5（纵轴）。不同于实际数据，该近似被设置为永不小于 1.0。这意味着该近似函数永远不会让复习时的<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>下降。10,130 次简单条目的重复被用于生成该图（Diff=0.1）。其中一个数据点展示了间隔达到 14 年的一组重复样本（<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>为 5172）。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><img class="origin_image zh-lightbox-thumb" data-original="https://pic3.zhimg.com/v2-ade3d3459a09d560ed604ddbb2def594_r.jpg" data-original-token="v2-ade3d3459a09d560ed604ddbb2def594" data-rawheight="258" data-rawwidth="500" data-size="normal" src="https://pic3.zhimg.com/v2-ade3d3459a09d560ed604ddbb2def594_b.jpg" width="500"/><figcaption>SuperMemo 中的记忆稳定化曲线</figcaption></figure><p data-pid="m7kjieTU">图：<a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 计算的<b><a class="wrap external" href="https://supermemo.guru/wiki/Stabilization_curve" rel="nofollow noreferrer" target="_blank">稳定化曲线</a></b>。横轴以<a class="wrap external" href="https://supermemo.guru/wiki/Memory_retrievability" rel="nofollow noreferrer" target="_blank">记忆可提取性</a>表示时间。纵轴表示稳定化，即记忆持久度的增长，以<a class="wrap external" href="https://supermemo.guru/wiki/Memory_stability" rel="nofollow noreferrer" target="_blank">记忆稳定性</a>增长表示。蓝色圆圈表示在给定<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>下复习的<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>增长程度。蓝色圆圈的大小取决于收集到的数据点数量。该图使用了 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 中<a class="wrap external" href="https://supermemo.guru/wiki/Difficulty" rel="nofollow noreferrer" target="_blank">难度</a>=0.53 且 <a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>=26 [天]的 31,721 条复习记录。稳定性增长从<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>=100% 对应的 1.36（SIncMin=1.36）到 R=0% 对应的 26.31（SIncMax=26.31）。<a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 中 R=90% 对应的最佳复习的稳定性增长为 1.86（Stab90 等价于旧版 SuperMemo 中的 <a class="wrap external" href="https://supermemo.guru/wiki/O-Factor" rel="nofollow noreferrer" target="_blank">O-系数</a>）。表示<a class="wrap external" href="https://supermemo.guru/wiki/Spacing_effect" rel="nofollow noreferrer" target="_blank">间隔效应</a>的增益系数等于 2.96，即相对较高，适应低<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>。使用公式可以准确计算此数据集中的稳定化（黄色曲线）： 26*e-2.96*R，<a class="wrap external" href="https://supermemo.guru/wiki/Deviation" rel="nofollow noreferrer" target="_blank">偏差</a>为 0.5069。巩固曲线以紫色展示，表明<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting_index" rel="nofollow noreferrer" target="_blank">遗忘指数</a>是所提供数据集的合理学习标准。当 R 接近 100% 时，本图的实际稳定化为 0.879，与 2074 次测量结果一致。这在图片中看不清楚，但可以通过 SuperMemo 中输出的稳定化矩阵进行调查。这意味着在<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>接近 100% 和 0% 的极端情况下，稳定化曲线公式可能不准确。这可以解释为没有任何记忆是可以完美提取或可验证的完全忘却（见：<a class="wrap external" href="https://supermemo.guru/wiki/We_never_forget" rel="nofollow noreferrer" target="_blank">我们永远不会忘记</a>）</p><figure data-size="normal"><img class="origin_image zh-lightbox-thumb" data-original="https://pic3.zhimg.com/v2-ec51b75fa9fd8c38c10f56021ea5d24e_r.jpg" data-original-token="v2-ec51b75fa9fd8c38c10f56021ea5d24e" data-rawheight="263" data-rawwidth="500" data-size="normal" src="https://pic3.zhimg.com/v2-ec51b75fa9fd8c38c10f56021ea5d24e_b.jpg" width="500"/><figcaption>SuperMemo 中的稳定化衰减</figcaption></figure><p data-pid="qLsXhmqp">图：<b><a class="wrap external" href="https://supermemo.guru/wiki/Stabilization_decay" rel="nofollow noreferrer" target="_blank">稳定化衰减</a></b>是<b><a class="wrap external" href="https://supermemo.guru/wiki/Memory_stabilization" rel="nofollow noreferrer" target="_blank">记忆稳定化</a></b>随着<b><a class="wrap external" href="https://supermemo.guru/wiki/Memory_stability" rel="nofollow noreferrer" target="_blank">记忆稳定性</a></b>提高而下降。取自 <a class="wrap external" href="https://supermemo.guru/wiki/SuperMemo" rel="nofollow noreferrer" target="_blank">SuperMemo</a> 的图片展示了<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>对<a class="wrap external" href="https://supermemo.guru/wiki/Difficulty" rel="nofollow noreferrer" target="_blank">难度</a>估计为 0.37 的<a class="wrap external" href="https://supermemo.guru/wiki/Item" rel="nofollow noreferrer" target="_blank">条目</a>的稳定化影响。绘制该图表使用了 25,686 条<a class="wrap external" href="https://supermemo.guru/wiki/repetition" rel="nofollow noreferrer" target="_blank">复习</a>记录。稳定化的<b>衰减率</b>为 -0.529。稳定性可能的最大增长（SIncMax）是 3.102（当<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a> =1 时）。蓝色圆圈表示数据点（S:SInc)，圆圈越大，<a class="wrap external" href="https://supermemo.guru/wiki/Repetition" rel="nofollow noreferrer" target="_blank">复习</a>记录的样本量越大。黄线是幂函数拟合，公式为：SInc=(3.102-1)*<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">S</a>-0.529+1。该拟合的<a class="wrap external" href="https://supermemo.guru/wiki/Deviation" rel="nofollow noreferrer" target="_blank">偏差</a>为 0.4235。</p><figure data-size="normal"><img class="content_image" data-original-token="v2-00140d107554720ce6d15369f8865881" data-rawheight="463" data-rawwidth="400" data-size="normal" src="https://pic2.zhimg.com/v2-00140d107554720ce6d15369f8865881_b.jpg" width="400"/><figcaption>复杂记忆的稳定化的不确定过程</figcaption></figure><p data-pid="vIg4EWLk">图：<b>复杂记忆的稳定化的不确定过程</b>。图中显示了以单个<a class="wrap external" href="https://supermemo.guru/wiki/Stabilization" rel="nofollow noreferrer" target="_blank">概念细胞</a>的单一树突输入模式为例的<a class="wrap external" href="https://supermemo.guru/wiki/Stabilization" rel="nofollow noreferrer" target="_blank">稳定化</a>、<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting" rel="nofollow noreferrer" target="_blank">遗忘</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="6" data-text="遗忘" data-url="https://zhuanlan.zhihu.com/p/558542113">[6]</sup>、<a class="wrap external" href="https://supermemo.guru/wiki/Generalization" rel="nofollow noreferrer" target="_blank">泛化</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="16" data-text="泛化与概念化" data-url="https://zhuanlan.zhihu.com/p/264989664">[16]</sup>和<a class="wrap external" href="https://supermemo.guru/wiki/Interference" rel="nofollow noreferrer" target="_blank">干扰</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="17" data-text="干扰" data-url="https://zhuanlan.zhihu.com/p/269974053">[17]</sup>的假想过程。神经元、树突和树突丝以橙色显示。图片没有显示树突丝转化为树突棘的过程，树突棘的形态随着时间的推移会发生变化<a class="wrap external" href="https://supermemo.guru/wiki/Stabilization" rel="nofollow noreferrer" target="_blank">稳定化</a>。方块代表参与识别输入模式的突触。每个方块显示了突触在<a class="wrap external" href="https://supermemo.guru/wiki/Two_component_model_of_long-term_memory" rel="nofollow noreferrer" target="_blank">长期记忆的双组分模型</a>方面的状态。红色的强度代表<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>。蓝色区域的大小代表<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>。在记住一个复杂的记忆模式后，<a class="wrap external" href="https://supermemo.guru/wiki/Concept_cell" rel="nofollow noreferrer" target="_blank">概念细胞</a>在收到来自红色方块的信号总和后能够识别该模式，这些信号代表高<a class="wrap external" href="https://supermemo.guru/wiki/Retrievability" rel="nofollow noreferrer" target="_blank">可提取性</a>和极低<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>的新记忆。每次细胞被重新激活，活跃的输入将经历<a class="wrap external" href="https://supermemo.guru/wiki/Stabilization" rel="nofollow noreferrer" target="_blank">稳定化</a>，这表现在输入方块中蓝色区域的增加。每次当概念细胞活跃时，信号没有到达输入端，其稳定性就会下降（泛化）。每次源轴突活跃而目标神经元未能发射，稳定性也会下降（竞争性干扰）。由于输入到概念细胞的信号模式不均匀，一些突触将被稳定下来，而另一些则会丢失。当一个突触失去其稳定性和可提取性，以及相关的树突棘被收回时，<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting" rel="nofollow noreferrer" target="_blank">遗忘</a>就会发生。当同一个<a class="wrap external" href="https://supermemo.guru/wiki/Concept_cell" rel="nofollow noreferrer" target="_blank">概念细胞</a>可以用一个更小但更稳定的输入模式重新激活时，<a class="wrap external" href="https://supermemo.guru/wiki/Generalization" rel="nofollow noreferrer" target="_blank">泛化</a>就会发生。当一个新的输入模式有助于忘记一些识别旧输入模式所必需的冗余输入时，就会发生追溯性<a class="wrap external" href="https://supermemo.guru/wiki/Interference" rel="nofollow noreferrer" target="_blank">干扰</a>。旧模式的<a class="wrap external" href="https://supermemo.guru/wiki/Stabilization" rel="nofollow noreferrer" target="_blank">稳定化</a>导致树突丝的流动性降低，从而防止新模式接管<a class="wrap external" href="https://supermemo.guru/wiki/Concept" rel="nofollow noreferrer" target="_blank">概念</a>（主动的<a class="wrap external" href="https://supermemo.guru/wiki/Interference" rel="nofollow noreferrer" target="_blank">干扰</a>）。在这个过程的每一端，一个稳定的、泛化性强的输入模式是激活<a class="wrap external" href="https://supermemo.guru/wiki/Concept_cell" rel="nofollow noreferrer" target="_blank">概念细胞</a>的充要条件。同一个细胞可以对不同的模式作出反应，只要它们是一致的、<a class="wrap external" href="https://supermemo.guru/wiki/Stabilization" rel="nofollow noreferrer" target="_blank">稳定的</a>。在<a class="wrap external" href="https://supermemo.guru/wiki/Spaced_repetition" rel="nofollow noreferrer" target="_blank">间隔重复</a>中，对<a class="wrap external" href="https://supermemo.guru/wiki/Knowledge_representation" rel="nofollow noreferrer" target="_blank">知识表征</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="18" data-text="20 条知识表述规则（20 周年版）" data-url="https://zhuanlan.zhihu.com/p/269997143">[18]</sup>的选择不当将导致激活模式的可重复性差，突触的<a class="wrap external" href="https://supermemo.guru/wiki/Stabilization" rel="nofollow noreferrer" target="_blank">稳定化</a>不均匀，以及<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting" rel="nofollow noreferrer" target="_blank">遗忘</a>。当输入模式无法激活足够多的突触，从而无法重新激活<a class="wrap external" href="https://supermemo.guru/wiki/Concept_cell" rel="nofollow noreferrer" target="_blank">概念细胞</a>时，就会发生对<a class="wrap external" href="https://supermemo.guru/wiki/Item" rel="nofollow noreferrer" target="_blank">项目</a>的遗忘。在<a class="wrap external" href="https://supermemo.guru/wiki/Repetition" rel="nofollow noreferrer" target="_blank">重复</a>时，根据上下文和<a class="wrap external" href="https://supermemo.guru/wiki/Conceptual_computation" rel="nofollow noreferrer" target="_blank">思路</a>，一个<a class="wrap external" href="https://supermemo.guru/wiki/Item" rel="nofollow noreferrer" target="_blank">项目</a>可能被提取或遗忘。<a class="wrap external" href="https://supermemo.guru/wiki/Repetition" rel="nofollow noreferrer" target="_blank">复习</a>的结果是不确定的</p><p class="ztext-empty-paragraph"><br/></p><blockquote data-pid="3Zd5eq7M"><a class="wrap external" href="http://paratranz.cn/projects/3131" rel="nofollow noreferrer" target="_blank">Thoughts Memo</a> 汉化组译制<br/>原文：<a class="wrap external" href="https://supermemo.guru/wiki/Stabilization" rel="nofollow noreferrer" target="_blank">Stabilization - supermemo.guru</a></blockquote>
<hr><section><h2>参考</h2>1. 重复 <a href="./572444486.html">./572444486.html</a><br>2. 记忆稳定性 <a href="./559298549.html">./559298549.html</a><br>3. 睡眠中的记忆优化 <a href="./266856783.html">./266856783.html</a><br>4. 记忆可提取性 <a href="./559819340.html">./559819340.html</a><br>5. 记忆复杂性 <a href="./304800091.html">./304800091.html</a><br>6. 遗忘 <a href="./558542113.html">./558542113.html</a><br>7. 2014：SM-17 算法 <a href="./473482969.html">./473482969.html</a><br>8. 记忆的双组分模型 <a href="./579476637.html">./579476637.html</a><br>9. 1990：记忆的通用公式 <a href="./429504395.html">./429504395.html</a><br>10. 间隔效应的结构与分子机理 <a href="./288609114.html">./288609114.html</a><br>11. 什么是 SuperMemo <a href="https://www.yuque.com/supermemo/wiki/supermemo">https://www.yuque.com/supermemo/wiki/supermemo</a><br>12. 0 目录《间隔重复的历史》 <a href="./375379522.html">./375379522.html</a><br>13. 间隔重复 (spaced repetition) <a href="./305651556.html">./305651556.html</a><br>14. 条目 <a href="./571700330.html">./571700330.html</a><br>15. 间隔效应 <a href="./279166945.html">./279166945.html</a><br>16. 泛化与概念化 <a href="./264989664.html">./264989664.html</a><br>17. 干扰 <a href="./269974053.html">./269974053.html</a><br>18. 20 条知识表述规则（20 周年版） <a href="./269997143.html">./269997143.html</a></section>
<hr>
<div class="column" style="margin: 1em 0; padding: 0.5em 1em; border: 2px solid #999; border-radius: 5px;">
<h2>专栏：认知基石 & 学校教育</h2>
</div>
<hr>
<p><a href="./">← 返回目录</a></p>
</article>
<script src="https://giscus.app/client.js"
data-repo="L-M-Sherlock/ZhiHuArchive"
data-repo-id="MDEwOlJlcG9zaXRvcnkzNDk5NDE0MzM="
data-category="Announcements"
data-category-id="DIC_kwDOFNuuuc4Ck92x"
data-mapping="title"
data-strict="0"
data-reactions-enabled="1"
data-emit-metadata="0"
data-input-position="top"
data-theme="preferred_color_scheme"
data-lang="zh-CN"
data-loading="lazy"
crossorigin="anonymous"
async>
</script>
</body>
</html>