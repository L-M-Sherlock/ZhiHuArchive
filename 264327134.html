<!DOCTYPE html>
<html lang="zh-CN">
<head>
<title>一致性与连贯性 - @Thoughts Memo</title>
<meta charset="UTF-8">
<meta property="og:type" content="website">
<meta property="og:title" content="一致性与连贯性 - @Thoughts Memo">
<meta property="og:site_name" content="ZhiHu Archive for Thoughts Memo">
<meta property="og:url" content="https://zhuanlan.zhihu.com/p/264327134">
<meta name="description" property="og:description" content="一致性（Consistency ）记忆一致性表示记忆中的知识的低矛盾性。不一致性可以通过干扰 …">
<meta property="twitter:card" content="summary">
<meta name="twitter:title" property="og:title" itemprop="name" content="一致性与连贯性 - @Thoughts Memo">
<meta name="twitter:description" property="og:description" itemprop="description" content="一致性（Consistency ）记忆一致性表示记忆中的知识的低矛盾性。不一致性可以通过干扰 …">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no">
<meta name="google-site-verification" content="U7ZAFUgGNK60mmMqaRygg5vy-k8pwbPbDFXNjDCu7Xk" />
<link rel="alternate" type="application/rss+xml" title="ZhiHu Archive for Thoughts Memo" href="https://l-m-sherlock.github.io/ZhiHuArchive/feed.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/yue.css@0.4.0/yue.css">
<script>
</script>
<style>
.origin_image {
width: 100%;
}
figure {
margin:1.4em 0;
}
figure img {
width: 100%;
}
img {
vertical-align: middle;
}
.author {
display: flex;
gap: 1em;
}
#avatar {
width: 100px;
height: 100px;
}
.author > div {
flex: 1;
}
a[data-draft-type="link-card"] {
   display: block;
}
</style>
</head>
<body style="max-width: 1000px; margin: 0 auto; padding: 0 1em 0 1em;" class="yue">
<p><a href="./">← 返回目录</a></p>
<hr>
<header>
<img class="origin_image" src="https://pic1.zhimg.com/v2-f446d3cb82de3ac1a980914e1b3a3ef1_720w.jpg?source=b1748391"/>
<h1><a href="https://zhuanlan.zhihu.com/p/264327134">一致性与连贯性</a></h1>
<div class="author">
<img class="avatar" id="avatar" src="https://pica.zhimg.com/50/v2-f958f2b875b0cf4d7ee853e4446ba2d1_l.jpg?source=b1748391" />
<div>
<h2 rel="author">
<a href="https://api.zhihu.com/people/4c592f496dc33822b560b382907ff1d0" target="_blank">@Thoughts Memo</a>
</h2>
<p> 学校≠教育≠技能；文凭溢价=80%信号传递+20%人力资本 </p>
</div>
</div>
<time datetime="2020-10-10T05:48:36">发表于 2020年10月10日</time>
<p rel="stats"style="color: #999; font-size: 0.9em;">49 👍 / 10 💬</p>
</header>
<article>
<h2>一致性（<a class="wrap external" href="https://supermemo.guru/wiki/Consistency" rel="nofollow noreferrer" target="_blank">Consistency</a>）</h2><p data-pid="npw80cUk"><b>记忆一致性</b>表示记忆中的知识的低矛盾性。不一致性可以通过<a class="wrap external" href="https://supermemo.guru/wiki/Interference" rel="nofollow noreferrer" target="_blank">干扰</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="1" data-text="干扰" data-url="https://zhuanlan.zhihu.com/p/269974053">[1]</sup>来消除。高<a class="wrap external" href="https://supermemo.guru/wiki/Coherence" rel="nofollow noreferrer" target="_blank">连贯性</a>有利于一致性。一致性的增加并不一定会导致<a class="wrap external" href="https://supermemo.guru/wiki/Value_of_wrong_models" rel="nofollow noreferrer" target="_blank">真实性</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="2" data-text="错误模型的价值" data-url="https://zhuanlan.zhihu.com/p/258435094">[2]</sup>的增加（事实正确性）。<a class="wrap external" href="https://supermemo.guru/wiki/Generalization" rel="nofollow noreferrer" target="_blank">泛化</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="3" data-text="泛化与概念化" data-url="https://zhuanlan.zhihu.com/p/264989664">[3]</sup>的定律倾向于有证据支持的知识，而知识本身可能来自不正确的一致<a class="wrap external" href="https://supermemo.guru/wiki/Model" rel="nofollow noreferrer" target="_blank">模型</a>。高一致性影响<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>仅仅是因为它最大限度地减少了<a class="wrap external" href="https://supermemo.guru/wiki/Interference" rel="nofollow noreferrer" target="_blank">干扰</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="4" data-text="干扰" data-url="https://zhuanlan.zhihu.com/p/269974053">[4]</sup>。根据<a class="wrap external" href="https://supermemo.guru/wiki/Neurostatistical_Model_of_Memory" rel="nofollow noreferrer" target="_blank">记忆的神经统计学模型</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="5" data-text="记忆的神经统计模型" data-url="https://zhuanlan.zhihu.com/p/277483881">[5]</sup>，影响记忆稳定性的主要是记忆<a class="wrap external" href="https://supermemo.guru/wiki/Coherence" rel="nofollow noreferrer" target="_blank">连贯性</a>（例如通过<a class="wrap external" href="https://supermemo.guru/wiki/Memory_optimization_in_sleep" rel="nofollow noreferrer" target="_blank">睡眠中的巩固</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="6" data-text="睡眠中的记忆优化" data-url="https://zhuanlan.zhihu.com/p/266856783">[6]</sup>）。</p><h2>连贯性（<a class="wrap external" href="https://supermemo.guru/wiki/Coherence" rel="nofollow noreferrer" target="_blank">Coherence</a>）</h2><p data-pid="PGvEgtxk"><b>定义</b></p><p data-pid="p0zYKopI"><b>记忆连贯性</b>或连通性是知识内部的有意义联系的程度。如果你把知识视为一个<a class="wrap external" href="https://supermemo.guru/wiki/Concept_map" rel="nofollow noreferrer" target="_blank">语义网络</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="7" data-text="概念网络" data-url="https://zhuanlan.zhihu.com/p/266541480">[7]</sup>（计算机科学） ，连贯性将反映网络近端节点之间连接的质量。像猫和狗这样的<a class="wrap external" href="https://supermemo.guru/wiki/Grandmother_cell" rel="nofollow noreferrer" target="_blank">概念</a>在语义上是相近的。相反，猫和代数通常是联系较远的。高度的知识连贯性通过<a class="wrap external" href="https://supermemo.guru/wiki/Memory_optimization_in_sleep" rel="nofollow noreferrer" target="_blank">睡眠中的巩固</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="6" data-text="睡眠中的记忆优化" data-url="https://zhuanlan.zhihu.com/p/266856783">[6]</sup>提高记忆。它减少了知识<a class="wrap external" href="https://supermemo.guru/wiki/Interference" rel="nofollow noreferrer" target="_blank">干扰</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="4" data-text="干扰" data-url="https://zhuanlan.zhihu.com/p/269974053">[4]</sup>，有利于记忆的<a class="wrap external" href="https://supermemo.guru/wiki/Consistency" rel="nofollow noreferrer" target="_blank">一致性</a>。</p><p data-pid="qI71kdU5"><b>自由学习</b></p><p data-pid="qsCsCfJ1"><b>连贯的</b>知识使人能够<a class="wrap external" href="https://supermemo.guru/wiki/Fast_thinking" rel="nofollow noreferrer" target="_blank">快速思考</a>。对<a class="internal" href="./52990549.html">学习内驱力</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="8" data-text="学习内驱力" data-url="https://zhuanlan.zhihu.com/p/52990549">[8]</sup>的依赖导致学习基于高连贯性，由于先验知识的瞬时评价。对<a class="wrap external" href="https://supermemo.guru/wiki/Schooling" rel="nofollow noreferrer" target="_blank">学校教育</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="9" data-text="被动的学校教育" data-url="https://zhuanlan.zhihu.com/p/359037513">[9]</sup>的依赖导致了<a class="wrap external" href="https://supermemo.guru/wiki/On_the_superiority_of_a_rat_over_a_schooled_human" rel="nofollow noreferrer" target="_blank">低连贯性的知识</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="10" data-text="论老鼠比受过学校教育的人更优越" data-url="https://zhuanlan.zhihu.com/p/272801606">[10]</sup>。<a class="wrap external" href="https://supermemo.guru/wiki/Free_learning" rel="nofollow noreferrer" target="_blank">自由学习</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="11" data-text="自由学习" data-url="https://zhuanlan.zhihu.com/p/272543239">[11]</sup>是确保高度连贯性的最简单和最廉价的方式。<a class="wrap external" href="https://supermemo.guru/wiki/Coercion_in_learning" rel="nofollow noreferrer" target="_blank">强迫学习</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="12" data-text="学习中的强迫" data-url="https://zhuanlan.zhihu.com/p/351872034">[12]</sup>导致学习连贯性低下，因为它违反了<a class="wrap external" href="https://supermemo.guru/wiki/Fundamental_law_of_learning" rel="nofollow noreferrer" target="_blank">学习的基本规律</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="13" data-text="学习的基本规律" data-url="https://zhuanlan.zhihu.com/p/273225977">[13]</sup>。对于一个高年级的学生来说，最好的<a class="wrap external" href="https://supermemo.guru/wiki/Free_learning" rel="nofollow noreferrer" target="_blank">自由学习</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="14" data-text="自由学习" data-url="https://zhuanlan.zhihu.com/p/272543239">[14]</sup>的方法就是<a class="wrap external" href="https://supermemo.guru/wiki/Incremental_reading" rel="nofollow noreferrer" target="_blank">渐进阅读</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="15" data-text="渐进阅读" data-url="https://www.yuque.com/supermemo/wiki/incremental_reading">[15]</sup>。</p><p data-pid="EwVK4Nrd">另请参见：<a class="wrap external" href="https://supermemo.guru/wiki/Optimality_of_the_learn_drive" rel="nofollow noreferrer" target="_blank">学习内驱力的优化</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="16" data-text="学习内驱力的优化" data-url="https://zhuanlan.zhihu.com/p/357209357">[16]</sup></p><p data-pid="BIP0AZPn"><b>睡眠与创造力</b></p><p data-pid="EY3_jiC4"><a class="wrap external" href="https://supermemo.guru/wiki/Concept_network" rel="nofollow noreferrer" target="_blank">概念网络</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="7" data-text="概念网络" data-url="https://zhuanlan.zhihu.com/p/266541480">[7]</sup>中的短<a class="wrap external" href="https://supermemo.guru/wiki/Semantic_distance" rel="nofollow noreferrer" target="_blank">语义距离</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="17" data-text="语义距离" data-url="https://zhuanlan.zhihu.com/p/436727078">[17]</sup>和网络拓扑中的<a class="wrap external" href="https://supermemo.guru/wiki/Axonal-dendritic_overlap_favors_coherence_and_creativity" rel="nofollow noreferrer" target="_blank">轴突-树突重叠</a>促进了连贯的学习。</p><p data-pid="W4WXE_tt">连贯的知识促进<a class="wrap external" href="https://supermemo.guru/wiki/Creativity" rel="nofollow noreferrer" target="_blank">创造力</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="18" data-text="创造力" data-url="https://zhuanlan.zhihu.com/p/450093869">[18]</sup>。一个稳定连贯的知识框架可以用来连接丰富的新知识片段，并在不同<a class="wrap external" href="https://supermemo.guru/wiki/Concept" rel="nofollow noreferrer" target="_blank">概念</a>之间形成局部和远程的联系。</p><p data-pid="-l0CUmR6">在<a class="wrap external" href="https://supermemo.guru/wiki/Neurostatistical_Model_of_Memory" rel="nofollow noreferrer" target="_blank">记忆的神经统计学模型</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="5" data-text="记忆的神经统计模型" data-url="https://zhuanlan.zhihu.com/p/277483881">[5]</sup>中，连贯性影响清醒和睡眠时记忆<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>的建立（见: <a class="wrap external" href="https://supermemo.guru/wiki/Two-component_model_of_memory_stability" rel="nofollow noreferrer" target="_blank">记忆稳定性的双成分模型</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="19" data-text="记忆稳定性的两个组成成分" data-url="https://zhuanlan.zhihu.com/p/268782211">[19]</sup>）。</p><h3>进一步</h3><ul><li data-pid="l6DF_luw"><a class="wrap external" href="https://supermemo.guru/wiki/Coherence_vs_interference_problem_of_teaching" rel="nofollow noreferrer" target="_blank">教学的连贯与干扰问题</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="20" data-text="教学的连贯与干扰问题" data-url="https://zhuanlan.zhihu.com/p/359061669">[20]</sup></li><li data-pid="NQ-S3NU6"><a class="wrap external" href="https://supermemo.guru/wiki/Brains_algorithms_protect_models_of_reality" rel="nofollow noreferrer" target="_blank">大脑天然地保护连贯性</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="21" data-text="大脑算法保护现实的模型" data-url="https://zhuanlan.zhihu.com/p/356977535">[21]</sup></li><li data-pid="0p1cbYFl"><a class="wrap external" href="https://supermemo.guru/wiki/Axonal-dendritic_overlap_favors_coherence_and_creativity" rel="nofollow noreferrer" target="_blank">轴突-树突重叠促进连贯性和创造力</a></li></ul><hr/><h2>记忆：连贯性 vs. 一致性</h2><figure data-size="normal"><img class="origin_image zh-lightbox-thumb" data-caption="" data-original="https://pic2.zhimg.com/v2-0b1735cdbc9bc903c7c218329f3aff51_r.jpg" data-original-token="v2-1174a5cdef7322a6ebf48dcc4a91fcbe" data-rawheight="373" data-rawwidth="550" data-size="normal" src="https://pic2.zhimg.com/v2-0b1735cdbc9bc903c7c218329f3aff51_b.jpg" width="550"/></figure><p data-pid="YktTJOSB">图：记忆的<b>连贯性</b>和<b>一致性</b>很容易混淆。连贯的记忆显示出高度的连通性。<a class="wrap external" href="https://supermemo.guru/wiki/Semantic_distance" rel="nofollow noreferrer" target="_blank">语义距离</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="17" data-text="语义距离" data-url="https://zhuanlan.zhihu.com/p/436727078">[17]</sup>短的有意义记忆具有高度的连贯性。记忆一致性表示<a class="wrap external" href="https://supermemo.guru/wiki/War_of_the_networks" rel="nofollow noreferrer" target="_blank">记忆冲突</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="22" data-text="神经网络战争" data-url="https://zhuanlan.zhihu.com/p/359658715">[22]</sup>程度低。在连贯的网络中，一致性得到了很好的保留，但是，推理可能会导致冲突，从而导致更改（例如，由于<a class="wrap external" href="https://supermemo.guru/wiki/Interference" rel="nofollow noreferrer" target="_blank">干扰</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="4" data-text="干扰" data-url="https://zhuanlan.zhihu.com/p/269974053">[4]</sup>而<a class="wrap external" href="https://supermemo.guru/wiki/Forgetting" rel="nofollow noreferrer" target="_blank">遗忘</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="23" data-text="遗忘" data-url="https://zhuanlan.zhihu.com/p/558542113">[23]</sup>）。 <a class="wrap external" href="https://supermemo.guru/wiki/Knowledge_darwinism" rel="nofollow noreferrer" target="_blank">知识进化论</a><sup data-draft-node="inline" data-draft-type="reference" data-numero="24" data-text="知识达尔文主义（知识进化论）" data-url="https://zhuanlan.zhihu.com/p/264940693">[24]</sup>逐渐提高了连贯性和一致性。既提高了知识<a class="wrap external" href="https://supermemo.guru/wiki/Stability" rel="nofollow noreferrer" target="_blank">稳定性</a>，又能产生高质量的长期记忆</p>
<hr><section><h2>参考</h2>1. 干扰 <a href="./269974053.html">./269974053.html</a><br>2. 错误模型的价值 <a href="./258435094.html">./258435094.html</a><br>3. 泛化与概念化 <a href="./264989664.html">./264989664.html</a><br>4. 干扰 <a href="./269974053.html">./269974053.html</a><br>5. 记忆的神经统计模型 <a href="./277483881.html">./277483881.html</a><br>6. 睡眠中的记忆优化 <a href="./266856783.html">./266856783.html</a><br>7. 概念网络 <a href="./266541480.html">./266541480.html</a><br>8. 学习内驱力 <a href="./52990549.html">./52990549.html</a><br>9. 被动的学校教育 <a href="./359037513.html">./359037513.html</a><br>10. 论老鼠比受过学校教育的人更优越 <a href="./272801606.html">./272801606.html</a><br>11. 自由学习 <a href="./272543239.html">./272543239.html</a><br>12. 学习中的强迫 <a href="./351872034.html">./351872034.html</a><br>13. 学习的基本规律 <a href="./273225977.html">./273225977.html</a><br>14. 自由学习 <a href="./272543239.html">./272543239.html</a><br>15. 渐进阅读 <a href="https://www.yuque.com/supermemo/wiki/incremental_reading">https://www.yuque.com/supermemo/wiki/incremental_reading</a><br>16. 学习内驱力的优化 <a href="./357209357.html">./357209357.html</a><br>17. 语义距离 <a href="./436727078.html">./436727078.html</a><br>18. 创造力 <a href="./450093869.html">./450093869.html</a><br>19. 记忆稳定性的两个组成成分 <a href="./268782211.html">./268782211.html</a><br>20. 教学的连贯与干扰问题 <a href="./359061669.html">./359061669.html</a><br>21. 大脑算法保护现实的模型 <a href="./356977535.html">./356977535.html</a><br>22. 神经网络战争 <a href="./359658715.html">./359658715.html</a><br>23. 遗忘 <a href="./558542113.html">./558542113.html</a><br>24. 知识达尔文主义（知识进化论） <a href="./264940693.html">./264940693.html</a></section>
<hr>
<div class="column" style="margin: 1em 0; padding: 0.5em 1em; border: 2px solid #999; border-radius: 5px;">
<h2>专栏：学校教育问题</h2>
</div>
<hr>
<p><a href="./">← 返回目录</a></p>
</article>
<script src="https://giscus.app/client.js"
data-repo="L-M-Sherlock/ZhiHuArchive"
data-repo-id="MDEwOlJlcG9zaXRvcnkzNDk5NDE0MzM="
data-category="Announcements"
data-category-id="DIC_kwDOFNuuuc4Ck92x"
data-mapping="title"
data-strict="0"
data-reactions-enabled="1"
data-emit-metadata="0"
data-input-position="top"
data-theme="preferred_color_scheme"
data-lang="zh-CN"
data-loading="lazy"
crossorigin="anonymous"
async>
</script>
</body>
</html>